{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe0 Home","text":"<p>\ud83d\udc4b \u00a1Bienvenido a DaviidAM Blog</p> <p>Hola y gracias por visitar mi rinc\u00f3n digital. Soy David, un apasionado de de la tecnolog\u00eda y el software. Este blog es mi espacio para documentar, explorar y compartir todo lo que voy aprendiendo en el camino.</p> <p>\ud83d\uddfa\ufe0f \u00bfQu\u00e9 puedes encontrar aqu\u00ed?</p> <ul> <li>Art\u00edculos de Aprendizaje: Profundiza en temas que me han llamado la atenci\u00f3n, desde conocimeinto b\u00e1sicos de diferentes lenguajes hasta temas de DevOps y deployments. Cada art\u00edculo est\u00e1 dise\u00f1ado para ofrecer una visi\u00f3n clara y \u00fatil sobre cada tema.</li> <li>Tutoriales y Gu\u00edas: \u00bfQuieres aprender algo nuevo? Aqu\u00ed encontrar\u00e1s tutoriales paso a paso y gu\u00edas pr\u00e1cticas para ayudarte a adquirir nuevas habilidades y conocimientos.</li> <li>Reflexiones Personales: A veces, me gusta compartir mis reflexiones sobre lo que estoy aprendiendo y c\u00f3mo esos conocimientos impactan mi vida diaria.</li> <li>Recursos Recomendados: Libros, cursos, herramientas y otros recursos que considero valiosos y que podr\u00edan ser de inter\u00e9s para ti tambi\u00e9n.</li> </ul>"},{"location":"#recursos","title":"Recursos","text":""},{"location":"#wip","title":"WIP","text":"<ul> <li>AWS SAA</li> <li>Terraform</li> <li>Python / Pandas</li> <li>Python / ML &amp; AI</li> </ul>"},{"location":"#todo","title":"ToDo","text":"<ul> <li>MySQL</li> <li>MongoDB</li> <li>Docker</li> <li>Kubernetes</li> <li>API</li> </ul>"},{"location":"AWS/0%20-%20SAA_exam/","title":"SAA Exam","text":"<p>Resumen de conocimientos necesarios para la certificaci\u00f3n AWS Solutions Architect Associate (AWS SAA).</p> <p>Nota: Principalmente este apartado estar\u00e1 en ingl\u00e9s ya que es el lenguaje en el que me estoy preparando el examen.</p>"},{"location":"AWS/0%20-%20SAA_exam/#sobre-el-examen","title":"Sobre el examen","text":"<p>El examen se compone de 65 preguntas tipo test, y el tiempo para completarlo es de 130 minutos. Cabe destacar que se divide en 4 bloques, cada uno con un peso distinto.</p> Domain % of Examination Domain 1: Design Resilient Architectures 30% Domain 2: Design High-Performing Architectures 28% Domain 3: Design Secure Applications and Architectures 24% Domain 4: Design Cost-Optimized Architectures 18%"},{"location":"AWS/0%20-%20SAA_exam/#chapters","title":"Chapters","text":"<ul> <li>Chapter 0 - AWS Well-Architected Framework</li> <li>Chapter 1 - Overview of Cloud Computing and Amazon Web Services</li> </ul>"},{"location":"AWS/00%20-%20well-architected_framework/","title":"AWS Well-Architected Framework","text":""},{"location":"AWS/00%20-%20well-architected_framework/#aws-pillars","title":"AWS Pillars","text":"Pillars Key points Security - Identity foundation. - Traceability. - Security at all layers. - Risk assessment and mitigation strategies. Operational Excelence - Deployed, Updated and Operated. Reliability - System recover after  disruptions. - System dynamically scale depending on demand. Performance Efficiency - Maximize performance by using resources efficiently. Cost Optimization - Constant review architectural design."},{"location":"AWS/01%20-%20cloud_computing/","title":"Chapter 1 - Overview of Cloud Computing and Amazon Web Services","text":"<p>The National Institute of Standards and Technology (NIST) defines cloud computing as:</p> <p>\"Ubiquitous, convenient, on-demand access to shared computing resources that can be rapidly provisioned and released with minimal management effort.\"</p> <p>Three basic characteristics of the cloud:</p> <ul> <li>On demand: Cloud computing enables you to use IT infrastructure as a resource that is always available on demand per your needs.</li> <li>Accessible from the Internet: All the resources that you deploy in the cloud are accessible from the Internet.</li> <li>Pay-as-you-go model: When you use cloud computing, you pay per your usage.</li> </ul> <p>Many reasons for using the cloud. For example, If you are a startup, you can just focus on the next big idea and forget about purchasing and managing the hardware.</p>"},{"location":"AWS/01%20-%20cloud_computing/#advantages-of-running-cloud-computing-on-aws","title":"Advantages of Running Cloud Computing on AWS","text":"Advantages Description Gaining agility You can provision all the resources you need almost instantly. Avoiding guessing about capacity Since the cloud is elastic, which means you can scale up and scale down based on your requirements at any time, you can provision only the resources that you need at any point of time. Moving from capital expenses to variable/flexible expenses It becomes difficult to get approval for new hardware each time you want to start a project. With an operational expense model, you have zero up-front costs. Benefiting from massive economics of scale A user of cloud computing benefits from the massive economies of scale since hundreds of thousands of customers are aggregated in the cloud. This in turns translates to low pay-as-you-go prices. Avoiding spending money on data centers With cloud computing you don\u2019t have any overhead to manage the data center, and you can focus more on what the business needs. Benefiting from the pace of innovation Customers can use all the new products and features instantly, whenever they  are released. The moment a new feature is available, it is automatically available to you. Going global in minutes With cloud computing, you don\u2019t have to wait for months or even days to operate from a different region. With just a few mouse clicks and a few minutes, you can be ready to operate from a different region. You can do it almost instantly."},{"location":"AWS/01%20-%20cloud_computing/#three-models-of-cloud-computing","title":"Three Models of Cloud Computing","text":"Cloud Computing Models Description Infrastructure as a Service (IaaS) Provides the foundation for a cloud IT environment that includes compute (server), networking, storage, and space in a data center. Platform as a Service (PaaS) Just want to focus on deploying and managing the applications. PaaS eliminates the job of managing the entire infrastructure layer. Soft-ware as a Service (SaaS) Way of delivering applications over the Internet. SaaS provider offers a complete product that is hosted and managed by the product vendor, you just need to think about how you are going to use the product."},{"location":"AWS/01%20-%20cloud_computing/#three-cloud-computing-deployment-models","title":"Three Cloud Computing Deployment Models","text":"Cloud Computing Deployment Models Description All-in cloud You design and deploy an application in a public cloud using a cloud service provider. Hybrid You host some of the applications in the cloud and some of the applications at your own premises. On-premise or private cloud When you deploy the resources in your own data center using virtualization or resource management tools."},{"location":"AWS/01%20-%20cloud_computing/#history-of-aws","title":"History of AWS","text":"<ul> <li>AWS was officially launched in 2006.</li> <li>AWS has more than 175 fully featured services.</li> </ul>"},{"location":"AWS/01%20-%20cloud_computing/#aws-global-infrastructure","title":"AWS Global Infrastructure","text":"<ul> <li>AWS works in 190 countries around the world.</li> <li>AWS serves these customers via its global infrastructure, which consists of regions, availability zones (AZs), and points of presence (POPs).</li> </ul>"},{"location":"AWS/01%20-%20cloud_computing/#regions","title":"Regions","text":"<ul> <li>AWS maintains 24 regions spanning five continents in the world, with three additional regions being planned.</li> <li>A region is a physical location in the world that comprises clusters of highly redundant data centers. The regions are separated geographically, which provides data sovereignty. You can think of a region as a distinct geographical location where AWS services are made available.</li> </ul> <p>Note: By default, data residing in a region never leaves a region unless explicitly moved by AWS customers.</p> <ul> <li>AWS also offers the GovCloud region in the United States, which is designed for government agencies to run their workloads in the cloud. Though it is designed for government agencies, other customers can also use this region.</li> </ul>"},{"location":"AWS/01%20-%20cloud_computing/#availability-zones-azs","title":"Availability zones (AZs)","text":"<ul> <li> <p>Within each region there are availability zones (AZs). An AZ consists of one to six data centers, with redundant power supplies and networking connectivity. As of this writing, there are 76 AZs.</p> </li> <li> <p>A single data center can be part of only one AZ. Each AZ is located in a different floodplain; power grids are designed in such a way that a natural calamity or disaster does not impact multiple AZs.</p> </li> <li> <p>The networking among the AZs in a particular region is designed in such a way that it offers inexpensive, low-latency, private, fiber-optic network connectivity to another AZ in the same region. The latency between the AZs within a region is less than a single digit.</p> </li> <li> <p>The biggest advantage of this is that you can design an application in such a way that it can run on multiple AZs, and since the data can be synchronously replicated within the AZs, in the case of a disaster taking one of the AZs down, there is no impact on your application.</p> </li> </ul>"},{"location":"AWS/01%20-%20cloud_computing/#local-zones","title":"Local zones","text":"<ul> <li> <p>Using this local zones, you can run a few specific AWS services closer to user populations where no AWS regions exist.</p> </li> <li> <p>The local zones are connected to the parent region via a high-bandwidth private network, thereby enabling seamless access to rest of the AWS series that is unavailable in these local areas.</p> </li> </ul> <p></p>"},{"location":"AWS/01%20-%20cloud_computing/#points-of-presence-pops-edge-locations","title":"Points of presence (POPs) - Edge locations","text":"<ul> <li> <p>These edge locations are in most of the major cities across the globe.</p> </li> <li> <p>At the time of this writing, there are 216 POPs.</p> </li> <li> <p>The edge locations are mainly used by content delivery networks to distribute content to nearby end users to reduce latency and provide fast performance.</p> </li> <li> <p>For example, when you watch a video from Amazon Video, the video will be cached in an edge location so that when another customer watches the same video, it will be served from an edge loca- tion for a quick turnaround time and better user experience.</p> </li> <li> <p>In addition to edge locations, AWS has recently added regional edge cache locations between the main servers and the edge locations. When an object is not accessed for a long time, it goes out of the cache, but because the regional edge cache maintains a larger cache, the object can be stored there for a longer amount of time.</p> </li> <li> <p>The POPs consist of both edge locations as well as the regional edge caches.</p> </li> </ul> <p>EXAM TIP: AWS has 24 regions and 76 AZs as of this writing. Since AWS keeps adding regions and AZs, please check the web site to get the latest numbers.</p>"},{"location":"AWS/01%20-%20cloud_computing/#aws-security-and-compliance","title":"AWS Security and Compliance","text":"<p>AWS follows the model of shared security, which means AWS is responsible for the secu- rity of the cloud, and customers are responsible for the security in the cloud.</p> <p>In the case of a managed service (for example, Amazon RDS, Amazon Redshift, Amazon DynamoDB, and so on), AWS is also responsible for the security configuration of it.</p> <p></p>"},{"location":"AWS/01%20-%20cloud_computing/#aws-products-and-services","title":"AWS Products and Services","text":"<p>Now, AWS has more than 175 services that include compute, storage, networking, database, analytics, application services, deployment, management, and mobile services.</p>"},{"location":"AWS/01%20-%20cloud_computing/#compute","title":"Compute","text":"<p>The compute services include both servers and serverless configuration.</p> Services Description Amazon Elastic Compute Cloud (EC2) It includes the virtual servers, called instances, in the cloud. Depending on the use case, the customer can choose from a variety of instance types. Amazon EC2 Auto Scaling It helps in automatically scaling the Amazon EC2 instances up and down as per the policies you define, it ensures that you are always running with the desired number of instances. No additional charge for using Amazon EC2 Auto Scaling. Amazon EC2 Auto Scaling integrates with Elastic Load Balancer AWS Lambda AWS Lambda enables you to run code without provisioning or managing any servers or infrastructure. You simply develop code for your application or back-end service and define the event triggers with the AWS Lambda service. AWS Lambda then takes care of provisioning the resources to run your code, produce the results, and tear down the code. You pay only for the compute time when the code is getting executed; there is no charge when the code is not running. Amazon EC2 Container Service (ECS) It allows you to run Docker containers on Amazon EC2 instances. There are no separate charges for Amazon ECS; you pay only for the AWS resources used. Amazon Elastic Kubernetes Service (EKS) It is a fully managed Kubernetes service that makes it easy for you to run your code on AWS without needing to install and operate your own Kubernetes control plane or worker nodes. AWS Fargate It is a serverless compute engine for containers that works with both Amazon ECS and Amazon EKS. It utomatically scale, load balance, and manage scheduling of your containers for availability. AWS Elastic Beanstalk It lets you run and manage web applications without worrying about the underlying infrastructure. There is no addi- tional charge for AWS Elastic Beanstalk; you pay only for the AWS resources needed to run your applications. Amazon Lightsail It  is the simplest way to get started with AWS for small businesses, devel- opers, students, and other users who need a simple virtual private server (VPS) solution. Amazon Lightsail provides storage, networking capacity, and compute capabilities to manage and deploy web sites and web applications in the cloud. It includes a virtualized compute server, DNS management, SSD-based storage, data transfer capa- bilities, and a static IP address for a low, predictable monthly price. AWS Batch It enables users to efficiently run hundreds of thousands of batch comput- ing jobs on AWS. IT dynamically provisions the optimal type and quantity of compute resources AWS Outposts It helps in extending AWS services to any data center. Using Outposts, you can run all the AWS services, APIs, and tools at your data center, at a partner data cen- ter, or at a colocation facility. It is an ideal platform to provide a hybrid experience. Outposts is the on-premise version of the AWS cloud."},{"location":"AWS/01%20-%20cloud_computing/#networking","title":"Networking","text":"<p>Networking is part of the AWS core services. AWS networking helps you to isolate your cloud infrastructure.</p> Services Description Amazon Virtual Private Cloud (VPC) Using this service, you can isolate cloud resources within your own private virtual network. You can say that an Amazon VPC is your own data center in the cloud. You have complete control over the networking in an Amazon VPC. You can bring your own IP addresses, you can define the subnets as you want, and you have full control over the route table and network gateways. Amazon Route 53 It is a Domain Name System (DNS) web service. It is highly available and scalable, and its SLA is 100 percent uptime. Amazon Route 53 is IPv4 as well as IPv6 compliant Elastic Load Balancing It allows you to automatically distribute the load across multiple Amazon EC2 instances. It can be integrated with Auto Scaling; as a result, you can auto- matically scale up and down your Amazon EC2 instance and dynamically grow and shrink your operation depending on the traffic. AWS Direct Connect Using this service, you can establish private, dedicated network connectivity from your data center to AWS. You can reduce bandwidth costs for high-volume data transfers and get consistent network performance. AWS App Mesh It helps monitor, control, debug, and trace communications between services. It's based on the open source Envoy service. AWS Global Accelerator It improves the availability and performance of your applications for global users. It provides a set of static IP addresses that are anycast from the AWS edge network, which provides a fixed entry point to your applications and eliminates the com- plexity of managing specific IP addresses for different AWS regions and AZs."},{"location":"AWS/01%20-%20cloud_computing/#security-and-compliance","title":"Security and Compliance","text":"<p>The security of the cloud is the highest priority for AWS.</p> Services Description AWS Identity and Access Management (IAM) It is used to create users, groups, and roles. It is also used to manage and control access to AWS services and resources. Amazon Inspector It is an automated security assessment service that helps you to identify the security vulnerabilities in your application when it is being deployed as well as when it is running in a production system. AWS Certificate Manager (ACM) It is used to manage Secure Sockets Layer (SSL) certifi- cates for use with AWS services. Using ACM, you can provision, manage, and deploy SSL/Transport Layer Security (TLS) certificates. AWS Directory Service It is an AWS managed directory service built on Microsoft Active Directory. It can be used to manage directories in the cloud. AWS Web Application Firewall (WAF) It is a web application firewall that detects mali- cious traffic targeted at the web applications. Using WAF, you can create various rules with which you can protect against common attacks such as SQL injection and scripting. AWS Shield It is a managed service that protects against distributed denial-of-service (DDoS) attacks targeted at the web applications. There are two tiers of AWS Shield: Standard and Advanced. AWS Shield Standard is free and protects against most com- monly occurring DDoS attacks against web applications. With AWS Shield Advanced, you get higher levels of protection targeting not only against web applications but also Elastic Load Balancer, Amazon CloudFront, and Amazon Route 53. Amazon GuardDuty It is a threat-detection service that continuously monitors your AWS accounts and workloads to protect them. It provides broad protection of your AWS accounts, workloads, and data by helping to identify threats such as attacker reconnais- sance, instance compromise, and account compromise. Amazon Macie It helps you protect your data in Amazon S3 by helping you classify what data you have, the business value of that data, and the behavior associated with access to that data. It uses machine learning. AWS Secrets Manager It is a secrets management service that helps you protect access to your applications, services, and IT resources. AWS SSO AWS Single Sign-On (SSO) is an AWS service that enables you to use your existing cre- dentials from Microsoft Active Directory to access your cloud-based applications, such as AWS accounts and business applications (Office 365, Salesforce, Box), by using SSO. AWS CloudHSM It provides you with a dedicated hardware security module (HSM) in the AWS cloud. It helps you to meet all the contractual and regulatory com- pliance requirements. The HSM is a tamper-resistant hardware, which provides secure key storage and cryptographic operations. AWS KMS IT  is a managed service that helps you create and control the keys used for cryptographic operations. AWS KMS presents a single control point from which to manage keys and define policies consistently across integrated AWS services and your own applications."},{"location":"AWS/01%20-%20cloud_computing/#storage-and-content-delivery","title":"Storage and Content Delivery","text":"Services Description Amazon Simple Shared Storage (S3) It was one of the first services launched by AWS in 2006. It is the storage for the Internet, which is also used as an object store. Amazon S3 lets you store and retrieve any amount of data, at any time, from anywhere on the Web. Amazon Glacier Low-cost cloud storage that is mainly used for data archiving and long-term backup purposes. Amazon Elastic Block Storage (EBS) It provides persistent block storage for EC2 instances. You can choose from either magnetic or solid-state drive (SSD) disks for Amazon EBS volumes. Amazon Elastic File System (EFS) It is a fully managed service that provides easy, scalable, shared file storage with Amazon EC2 instances in the AWS cloud. It provides a simple file system interface and can be accessed concurrently for up to thousands of Amazon EC2 instances. AWS Storage Gateway It is a service that helps to seamlessly integrate on-premise storage with AWS cloud storage. It is delivered as a virtual machine installed in an on-premise data center. You can connect it as a file server, or you can connect it as a local disk. You can also connect it as a virtual tape library. Import/Export Options It  is a service that helps to transfer a large amount of data into AWS using a physical storage appliance. By doing that, you can bypass the data transfer over the Internet. You can also use AWS Snowball in which case AWS ships a physical device to your premises. Amazon CloudFront It is the global content delivery network (CDN) service of AWS. Amazon CloudFront helps to accelerate the delivery of the static content of your web sites, including photos, videos, or any other web assets."},{"location":"AWS/01%20-%20cloud_computing/#database","title":"Database","text":"Services Description Amazon Relational Database Service (RDS) Relational database. It supports both commercial and open source database engines (MySQL, Oracle, SQL Server, PostgreSQL, Maria DB and Aurora). Amazon DynamoDB NoSQL database. It delivers consistent, single-digit-millisecond latency at any scale. It consists of SSD storage. Amazon Redshift Fully managed petabyte-scale data warehouse service. It stores the data in columnar format, thereby providing better I/O efficiency. The data is continuously backed up in Amazon S3. Amazon ElastiCache ervice that helps in deploying an in-memory cache or data store in the cloud. It supports two open source in-memory engines: Redis and Memcached. Amazon Aurora It's Amazon\u2019s relational database built for the cloud. It supports two open source RDBMS engines: MySQL and PostgreSQL. The database is constantly backed up to Amazon S3. Amazon Neptune Fully managed graph database service with which you can build and run applications that work with highly connected data sets. Amazon QLDB It's a purpose-built ledger database that provides a complete and crypto-graphically verifiable history of all changes made to your application data. Amazon DocumentDB Fully managed document database service for MongoDB, you can use the same MongoDB application code, drivers, and tools. Amazon Keyspaces Managed Apache Cassandra\u2013compatible database service, you can run your Cassandra workloads on AWS by using the same Cassandra Query Language (CQL) code."},{"location":"AWS/01%20-%20cloud_computing/#analytics","title":"Analytics","text":"Services Description Amazon Athena Serverless, interactive query service that enables users to easily analyze data in Amazon S3 using standard SQL. Amazon EMR Web service that enables users, businesses, enterprises, data analysts, researchers, and developers to easily and cost-effectively process enormous amounts of data. It utilizes a hosted Hadoop framework. Amazon Elasticsearch Service Fully managed web service that makes it easy to create, operate, deploy, and scale Elasticsearch clusters in the AWS cloud. Amazon CloudSearch Fully managed web service in the AWS cloud that offers a simple, cost-effective, easy-to-use way to manage and scale a search solution for your application or web site. AWS Data Pipeline Enables users to process, transform, and move data between different AWS compute and storage services, as well as on-premise data sources, at specified intervals reliably and efficiently. Amazon Kinesis Fully managed service that makes it easy to collect, analyze, and process real-time, streaming data. AWS Glue Fully managed, extract, transform, and load (ETL) service. It can discover your data automatically and profiles the data via its built-in Glue Data Catalog. It runs ETL jobs in an Apache Spark environment and loads the data into the target. AWS Glue Data Catalog is a central metadata repository; an ETL engine that can automatically generate Scala or Python code. Amazon MSK Managed service for managing Apache Kafka infrastructure and operations. AWS Lake Formation It makes it easy to set up a secure data lake in days. A data lake is a central data repository with a large variety of data. It contains both structured and unstructured data. Using a data lake, you can manage the full life cycle of your data. Amazon QuickSight Easy, fast, cloud-powered, fully managed business analytics service that makes it easy to build visualizations, perform ad hoc analysis, and quickly get meaningful insights from your data."},{"location":"AWS/01%20-%20cloud_computing/#application-services","title":"Application Services","text":"Services Description Amazon API Gateway Fully managed service that provides developers with an easy, simple, scalable, flexible, pay-as-you-go service that handles all aspects of building, deploying, and operating robust APIs for application back-end services such as code running on AWS Lambda, applications running on Amazon EC2, or any web application. AWS Step Functions Fully managed service that enables users to efficiently and securely coordinate various components of distributed applications and microservices using visual workflows. This service provides a graphical interface for users to visualize and arrange the components of their applications. Amazon Simple Workflow Service (SWF) Web-based cloud service that makes it easy to coordinate work across distributed application components. Amazon Elastic Transcoder Convert (or transcode) video and audio files from their source format into the output format of their choice."},{"location":"AWS/01%20-%20cloud_computing/#developer-tools","title":"Developer Tools","text":"Services Description AWS CodeCommit Host highly scalable private Git repositories securely. AWS CodePipeline Managed continuous integration and continuous delivery service for quick, reliable application and infrastructure updates. AWS CodeBuild Builds and compiles source code, runs tests, and produces software packages that are ready to deploy, eliminating the need to provision, manage, and scale build servers. AWS CodeDeploy Automates code deployments to any instance or servers, including Amazon EC2 instances and servers running on-premises."},{"location":"AWS/01%20-%20cloud_computing/#management-tools","title":"Management Tools","text":"Services Description AWS CloudFormation Automate resource provisioning using declarative templates and deploying resource stacks. It gives developers and systems administrators an easy way to create and manage a collection of related AWS resources, provisioning and updating them in an orderly and predictable fashion. AWS Service Catalog Create, manage, and distribute catalogs of approved products to end users, who can then access the products they need in a personalized portal. Administrators can control which users have access to each product to enforce compliance with organizational business policies. Administrators can also set up adopted roles so that end users only require IAM access to AWS Service Catalog to deploy approved resources. AWS OpsWorks Give you workflow automation for continuous deployment, automated testing for compliance and security, and a user interface that gives you visibility into your nodes and their status. The Chef server gives you full stack automation by handling operational tasks such as software and operating system configurations, package installations, database setups, and more. Amazon CloudWatch Monitoring service for AWS cloud resources and the applications you run on AWS. You can use Amazon CloudWatch to collect and track metrics, collect and monitor log files, and set alarms. AWS Config Provides you with an AWS resource inventory, configuration history, and configuration change notifications to enable security and governance. AWS CloudTrail Records AWS API calls and user activity in your account and delivers log files to you via Amazon S3."},{"location":"AWS/01%20-%20cloud_computing/#messaging","title":"Messaging","text":"Services Description Amazon Simple Notification Service (SNS) Highly scalable, flexible, and cost-effective web service that makes it easy to configure, operate, and send notifications from the cloud. Publish messages from an application and immediately deliver them to subscribers or other applications. Amazon Simple Email Service (SES) Send and receive e-mail using your own e-mail addresses and domains. Amazon Simple Queue Service (SQS) Managed web service that gives you access to message queues to store messages waiting to be processed. Build message queuing applications that can run on any computer."},{"location":"AWS/01%20-%20cloud_computing/#migration","title":"Migration","text":"Services Description AWS Application Discovery Service Migrate projects by automatically identifying applications running in on-premise data centers and mapping their associated dependencies and their performance profiles. AWS Database Migration Service Migrate databases to AWS reliably and securely. The source database remains fully operational during the migration, minimizing downtime. AWS Snowball Transport a petabyte-scale amount of data into and out of the AWS cloud. AWS Server Migration Service (SMS) It helps coordinate, automate, schedule, and track large-scale server migrations. Migrate thousands of on-premise workloads to AWS."},{"location":"AWS/01%20-%20cloud_computing/#artificial-intelligence","title":"Artificial Intelligence","text":"Services Description Amazon Lex Conversational chatbot interfaces using voice and text. Language-understanding capabilities and speech recognition. Amazon Polly Converts text into lifelike speech. Amazon Rekognition Image recognition. Amazon SageMaker Enables you to build, train, and deploy machine learning models very quickly. It provides managed instances of TensorFlow and Apache MXNet, where users can create their own machine learning algorithms."},{"location":"AWS/01%20-%20cloud_computing/#internet-of-things","title":"Internet of Things","text":"Services Description AWS IoT Platform AWS Greengrass Lets you run local compute, messaging, and data caching for connected IoT devices in an efficient and secure way. It enables devices to run AWS Lambda functions, keep data in sync, and communicate with other devices securely, even when Internet connectivity is not possible. AWS IoT Button Programmable button based on the Amazon Dash Button hardware. This simple Wi-Fi device is easy to configure and designed for developers to get started with AWS IoT, AWS Lambda, Amazon DynamoDB, Amazon SNS, and many other Amazon web services without writing device-specific code. You can code the button\u2019s logic in the cloud."},{"location":"AWS/01%20-%20cloud_computing/#mobile-services","title":"Mobile Services","text":"Services Description Amazon Cognito Lets you add users to sign up and sign in to your mobile and web apps fast and reliably. Authenticate users through social identity providers such as Twitter, Facebook, or Amazon, along with other SAML identity solutions, or by using a custom identity system. AWS Mobile Hub Provides an integrated experience for configuring, discovering, and accessing AWS cloud services for creating, testing, deploying, and monitoring usage of mobile applications. AWS Device Farm Test mobile apps on real mobile devices and tablets. Amazon Mobile Analytics Web service that enables you to measure the app usage and revenue."},{"location":"HTML/01%20-%20html/","title":"HTML","text":"<p>HTML (<code>Lenguaje de Marcado de Hipertexto</code>, del ingl\u00e9s <code>HyperText Markup Language</code>) es el componente m\u00e1s fundamental de la Web.</p> <p>En una p\u00e1gina web confluyen muchos elementos y tecnolog\u00edas diferentes: por ejemplo, para interactuar con la web se utiliza JavaScript (el m\u00e1s com\u00fan), y para modificar la apariencia del contenido se emplea CSS. Sin embargo, HTML se enfoca \u00fanicamente en definir/describir la estructura y el contenido que vemos en la web, es decir, en establecer elementos como t\u00edtulos, im\u00e1genes, p\u00e1rrafos, enlaces, y otros componentes b\u00e1sicos.</p>"},{"location":"HTML/01%20-%20html/#archivos-html","title":"Archivos HTML","text":"<p>Un archivo HTML es un archivo de texto que contiene el c\u00f3digo HTML. Los archivos html deben acabar con la extensi\u00f3n <code>.html</code>.</p> <p>Por defecto, es com\u00fan usar el nombre <code>index.html</code> para el archivo html que contiene la informaci\u00f3n de la p\u00e1gina principal de una p\u00e1gina web.</p>"},{"location":"HTML/01%20-%20html/#comentarios","title":"Comentarios","text":"<p>Los comentarios son texto que no se muestra en la p\u00e1gina web. Se definen con la etiqueta <code>&lt;!-- --&gt;</code>.</p> <pre><code>&lt;!-- Esto es un comentario --&gt;\n</code></pre>"},{"location":"HTML/01%20-%20html/#campos-mandatorios","title":"Campos mandatorios","text":"<p>Los campos mandatorios en HTML son unas etiquetas que tenemos que a\u00f1adir siempre que creamos un nuevo archivo html.</p>"},{"location":"HTML/01%20-%20html/#doctype","title":"DOCTYPE","text":"<p>El DOCTYPE es un texto que indica al navegador qu\u00e9 versi\u00f3n de HTML se est\u00e1 utilizando. Se definen con la etiqueta <code>&lt;!DOCTYPE html&gt;</code>.</p> <pre><code>&lt;!DOCTYPE html&gt;\n</code></pre>"},{"location":"HTML/01%20-%20html/#bloque-html","title":"Bloque html","text":"<p>El bloque html es el contenedor/etiqueta principal de un documento HTML. Se definen con la etiqueta <code>&lt;html&gt;</code>.</p> <pre><code>&lt;html&gt;\n\n&lt;/html&gt;\n</code></pre> <p>Este bloque principal html se divide en 2 partes:</p> <ul> <li><code>head</code>.</li> <li><code>body</code>.</li> </ul>"},{"location":"HTML/01%20-%20html/#head","title":"Head","text":"<p>El bloque head es el contenedor principal de un documento HTML que contiene informaci\u00f3n que no se ve en la p\u00e1gina web. Se definen con la etiqueta <code>&lt;head&gt;</code>. Dentro del bloque head se definen los t\u00edtulos, los enlaces a los archivos css, los enlaces a los archivos js, y los metadatos.</p> <pre><code>&lt;head&gt;\n\n&lt;/head&gt;\n</code></pre>"},{"location":"HTML/01%20-%20html/#body","title":"Body","text":"<p>El bloque body es el contenedor principal de un documento HTML que contiene la informaci\u00f3n que se ve en la p\u00e1gina web. Se definen con la etiqueta <code>&lt;body&gt;</code>. Dentro del bloque body se definen los elementos que se ven en la p\u00e1gina web como t\u00edtulos, p\u00e1rrafos, im\u00e1genes, enlaces, y otros componentes b\u00e1sicos.</p> <pre><code>&lt;body&gt;\n\n&lt;/body&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/","title":"Elementos HTML","text":"<p>HTML consta de m\u00e1s de 100 elementos, pero todos ellos se definen con etiquetas.</p> <pre><code>&lt;nombre_etiqueta&gt;Contenido de la etiqueta&lt;/nombre_etiqueta&gt;\n</code></pre> <ul> <li>Toda la l\u00ednea anterior ser\u00eda un elemento HTML. </li> <li>Mientras que <code>&lt;nombre_etiqueta&gt;</code> es la etiqueta HTML.<ul> <li>Dentro de las etiquetas podemos distinguir etiqueta de apertura y etiqueta de cierre. Estas etiquetas siempre deben coincidir dentro de un mismo elemento.</li> </ul> </li> </ul> <p>Existen 3 tipos de elementos dentro de HTML: * Elementos normales (o contenedores). * Elementos reemplazables. * Elementos vac\u00edos.</p> <p>Documentaci\u00f3n sobre elementos HTML: https://developer.mozilla.org/en-US/</p>"},{"location":"HTML/02%20-%20elements/#elementos-normales","title":"Elementos normales","text":"<p>Son aquellos que tienen una etiqueta de apertura y una de cierre, y pueden contener texto, otros elementos o ambos.</p>"},{"location":"HTML/02%20-%20elements/#titulos","title":"T\u00edtulos","text":""},{"location":"HTML/02%20-%20elements/#titulo-de-la-web","title":"T\u00edtulo de la web","text":"<p>Los t\u00edtulos son elementos HTML que permiten establecer un t\u00edtulo, se definen con la etiqueta <code>&lt;title&gt;</code> en el <code>head</code>. Este es el nombre que aparece en la pesta\u00f1a del navegador y en el buscador de google.</p> <pre><code>&lt;title&gt;Contenido de T\u00edtulo&lt;/title&gt;\n</code></pre> <p>Es importante para el SEO ya que es el nombre que aparece en el buscador de google.</p>"},{"location":"HTML/02%20-%20elements/#titulos-de-contenido","title":"T\u00edtulos de contenido","text":"<p>Los t\u00edtulos son elementos HTML que permiten dar un t\u00edtulo a un documento HTML. Estos t\u00edtulos van del h1 al h6, donde el h1 es el t\u00edtulo m\u00e1s importante y el h6 es el t\u00edtulo menos importante.</p> <pre><code>&lt;h1&gt;Contenido de h1&lt;/h1&gt;\n&lt;h2&gt;Contenido de h2&lt;/h2&gt;\n&lt;h3&gt;Contenido de h3&lt;/h3&gt;\n&lt;h4&gt;Contenido de h4&lt;/h4&gt;\n&lt;h5&gt;Contenido de h5&lt;/h5&gt;\n&lt;h6&gt;Contenido de h6&lt;/h6&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#parrafo","title":"P\u00e1rrafo","text":"<p>Los p\u00e1rrafos son elementos HTML que permiten establecer un p\u00e1rrafo de texto, se definen con la etiqueta <code>&lt;p&gt;</code>.</p> <pre><code>&lt;p&gt;Contenido de p\u00e1rrafo&lt;/p&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#modificadores-de-texto","title":"Modificadores de texto","text":""},{"location":"HTML/02%20-%20elements/#strong","title":"Strong","text":"<p>Enfatiza un texto, se definen con la etiqueta <code>&lt;strong&gt;</code>.</p> <pre><code>&lt;strong&gt;Contenido de strong&lt;/strong&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#enfasis","title":"\u00c9nfasis","text":"<p>Enfatiza un texto, se definen con la etiqueta <code>&lt;em&gt;</code>. <pre><code>&lt;em&gt;Contenido de em&lt;/em&gt;\n</code></pre></p>"},{"location":"HTML/02%20-%20elements/#small","title":"small","text":"<pre><code>&lt;small&gt;Contenido de small&lt;/small&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#lista-desordenada","title":"Lista desordenada","text":"<p>Las listas desordenadas son elementos HTML que permiten establecer una lista de elementos, se definen con la etiqueta <code>&lt;ul&gt;</code>. Cada elementos de la lista se representa con la etiqueta <code>&lt;li&gt;</code>.</p> <pre><code>&lt;ul&gt;\n    &lt;li&gt;Contenido de li 1&lt;/li&gt;\n    &lt;li&gt;Contenido de li 2&lt;/li&gt;\n    &lt;li&gt;Contenido de li 3&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre> <p>Nota: Hay casos en los que no hace falta la etiqueta de cierre. Como los <code>&lt;li&gt;</code>. Pero no es recomendable, luego en el navegador autom\u00e1ticamente se cierran.</p> <pre><code>&lt;ul&gt;\n    &lt;li&gt;Contenido de li 1\n    &lt;li&gt;Contenido de li 2\n    &lt;li&gt;Contenido de li 3\n&lt;/ul&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#lista-ordenadas","title":"Lista ordenadas","text":"<p>Las listas ordenadas son elementos HTML que permiten establecer una lista de elementos, se definen con la etiqueta <code>&lt;ol&gt;</code>. Cada elementos de la lista se representa con la etiqueta <code>&lt;li&gt;</code>.</p> <pre><code>&lt;ol&gt;\n    &lt;li&gt;Contenido de li 1&lt;/li&gt;\n    &lt;li&gt;Contenido de li 2&lt;/li&gt;\n    &lt;li&gt;Contenido de li 3&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#enumeracion","title":"Enumeraci\u00f3n","text":"<p>Dentro de las listas ordenadas podemos elegir c\u00f3mo queremos que se enumere con el atributo <code>type</code>.</p> <ul> <li>Ordenar num\u00e9rico: <code>type=\"1\"</code></li> <li>Ordenar alfab\u00e9tico en may\u00fasculas: <code>type=\"A\"</code></li> <li>Ordenar alfab\u00e9tico en min\u00fasculas: <code>type=\"a\"</code></li> <li>Ordenar en romanos en may\u00fasculas: <code>type=\"I\"</code></li> <li>Ordenar en romanos en min\u00fasculas: <code>type=\"i\"</code></li> </ul> <pre><code>&lt;ol type=\"I\"&gt;\n    &lt;li&gt;Contenido de li 1&lt;/li&gt;\n    &lt;li&gt;Contenido de li 2&lt;/li&gt;\n    &lt;li&gt;Contenido de li 3&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#inversion","title":"Inversi\u00f3n","text":"<p>Podemos indicar si queremos invertir el orden de la lista con el atributo <code>reversed</code>.</p> <pre><code>&lt;ol reversed&gt;\n    &lt;li&gt;Contenido de li 1&lt;/li&gt;\n    &lt;li&gt;Contenido de li 2&lt;/li&gt;\n    &lt;li&gt;Contenido de li 3&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#inicio","title":"Inicio","text":"<p>Podemos indicar el n\u00famero desde el que queremos que comience la lista con el atributo <code>start</code>.</p> <pre><code>&lt;ol start=\"5\"&gt;\n    &lt;li&gt;Contenido de li 1&lt;/li&gt;\n    &lt;li&gt;Contenido de li 2&lt;/li&gt;\n    &lt;li&gt;Contenido de li 3&lt;/li&gt;\n&lt;/ol&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#formularios","title":"Formularios","text":"<p>Los formularios son elementos HTML que permiten establecer un formulario, se definen con la etiqueta <code>&lt;form&gt;</code>.</p> <pre><code>&lt;form method=\"post\" action=\"/&lt;url donde se deben enviar los datos&gt;\"&gt;\n    &lt;fieldset&gt;\n        &lt;legend&gt;Informaci\u00f3n personal&lt;/legend&gt;\n        &lt;div&gt;\n            &lt;label for=\"name\"&gt;Nombre:&lt;/label&gt;\n            &lt;input type=\"text\" name=\"name\" id=\"name\" placeholder=\"Introduce tu nombre\" required pattern=\"[a-zA-Z ]+\"&gt;\n        &lt;/div&gt;\n        &lt;!-- Otra forma quitando el for del label, sin usar id ni el div --&gt;\n        &lt;label style=\"display: block;\"&gt;Apellidos:\n            &lt;input type=\"text\" name=\"apellidos\" placeholder=\"Introduce tus apellidos\"&gt;\n            &lt;input name=\"telefono\" type=\"number\" placeholder=\"Introduce tu tel\u00e9fono\" required pattern=\"[0-9]{9}\"&gt;\n        &lt;/label&gt;\n        &lt;div&gt;\n            &lt;datalist id=\"languages-list\"&gt;\n                &lt;option value=\"HTML\"&gt;\n                &lt;option value=\"CSS\"&gt;\n                &lt;option value=\"JavaScript\"&gt;\n            &lt;/datalist&gt;\n            &lt;label&gt;\n                &lt;input type=\"text\" name=\"language\" id=\"language\" list=\"languages-list\"&gt;\n            &lt;/label&gt;\n        &lt;/div&gt;\n    &lt;/fieldset&gt;\n    &lt;button type=\"submit\"&gt;Enviar&lt;/button&gt;\n&lt;/form&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#desplegables","title":"Desplegables","text":"<p>Los desplegables son elementos HTML que permiten establecer un desplegable, se definen con la etiqueta <code>&lt;details&gt;</code>.</p> <pre><code>&lt;details&gt;\n    &lt;summary&gt;Contenido desplegable&lt;/summary&gt;\n    &lt;p&gt;Contenido del desplegable&lt;/p&gt;\n&lt;/details&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#tablas","title":"Tablas","text":"<p>Las tablas son elementos HTML que permiten establecer una tabla, se definen con la etiqueta <code>&lt;table&gt;</code>.</p> <pre><code>&lt;table&gt;\n    &lt;thead&gt;\n        &lt;tr&gt;\n            &lt;th&gt;Contenido de th&lt;/th&gt;\n        &lt;/tr&gt;\n    &lt;/thead&gt;\n    &lt;tbody&gt;\n        &lt;tr&gt;\n            &lt;td&gt;Contenido de td&lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/tbody&gt;\n&lt;/table&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#script","title":"Script","text":"<p>Los scripts son elementos HTML que permiten establecer un script de javascript, se definen con la etiqueta <code>&lt;script&gt;</code>.</p> <pre><code>&lt;script&gt;\n    console.log(\"Contenido del script\");\n&lt;/script&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#dialog","title":"Dialog","text":"<p>Un dialog (Di\u00e1logo) es un elemento HTML que permite establecer un di\u00e1logo, se definen con la etiqueta <code>&lt;dialog&gt;</code>.</p> <p>Es una especia de modal, es decir, un cuadro de di\u00e1logo que se muestra en una ventana modal. Normalmente se debe abrir cuando se hace clic en un bot\u00f3n.</p> <pre><code>&lt;dialog open&gt;\n    &lt;h1&gt;Contenido del di\u00e1logo&lt;/h1&gt;\n    &lt;p&gt;Contenido del di\u00e1logo&lt;/p&gt;\n    &lt;button&gt;Bot\u00f3n&lt;/button&gt;\n&lt;/dialog&gt;\n</code></pre> <p>Ejemplo de usar dialog con javascript:</p> <pre><code>&lt;button id=\"show-dialog\"&gt;Abrir di\u00e1logo&lt;/button&gt;\n&lt;dialog id=\"custom-dialog\"&gt;\n    &lt;h1&gt;Contenido del di\u00e1logo&lt;/h1&gt;\n    &lt;p&gt;Contenido del di\u00e1logo&lt;/p&gt;\n    &lt;button id=\"close-dialog\"&gt;Cerrar di\u00e1logo&lt;/button&gt;\n&lt;/dialog&gt;\n\n&lt;script&gt;\n    window.show-dialog.addEventListener(\"click\", () =&gt; {\n        window.custom-dialog.showModal();\n    });\n    window.close-dialog.addEventListener(\"click\", () =&gt; {\n        window.custom-dialog.close();\n    });\n&lt;/script&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#elementos-reemplazables","title":"Elementos reemplazables","text":"<p>Son elementos cuyo contenido es reemplazado por recursos externos, como im\u00e1genes, videos, iframes, etc. No necesitan etiqueta de cierre.</p>"},{"location":"HTML/02%20-%20elements/#imagenes","title":"Im\u00e1genes","text":"<p>Las im\u00e1genes son elementos HTML que permiten establecer una imagen, se definen con la etiqueta <code>&lt;img&gt;</code>. </p> <pre><code>&lt;img src=\"ruta_de_la_imagen\" alt=\"Texto alternativo\"&gt;\n</code></pre> <p>Si a\u00f1adimos la imagen dentro de un anchor es posible descargar la imagen. S\u00f3lo funciona con recursos que tengas dentro de tu dominio.</p> <pre><code>&lt;a download href=\"ruta_de_la_imagen\"&gt;\n    &lt;img\n        src=\"ruta_de_la_imagen\"\n        alt=\"Texto alternativo\"\n    &gt;\n&lt;/a&gt;\n</code></pre> <p>Posibles atributos de la etiqueta img:</p> <ul> <li><code>src</code>: ruta de la imagen</li> <li><code>alt</code>: texto alternativo</li> <li><code>width</code>: ancho de la imagen</li> <li><code>height</code>: alto de la imagen</li> <li><code>title</code>: t\u00edtulo de la imagen</li> <li><code>loading</code>: indica c\u00f3mo se debe cargar la imagen<ul> <li><code>loading=\"lazy\"</code>: indica que la imagen se debe cargar de forma diferida.</li> <li><code>loading=\"eager\"</code>: indica que la imagen se debe cargar de forma inmediata.</li> <li><code>loading=\"auto\"</code>: indica que la imagen se debe cargar de forma autom\u00e1tica.</li> </ul> </li> <li><code>style</code>: indica el estilo de la imagen. Ejemplos:</li> <li><code>style=\"width: 100%\"</code>: indica que la imagen se debe ajustar al ancho de su contenedor.</li> <li><code>style=\"height: 100%\"</code>: indica que la imagen se debe ajustar al alto de su contenedor.</li> <li><code>style=\"aspect-ratio: 16 / 9\"</code>: indica que la imagen se debe ajustar al aspecto de su contenedor.</li> </ul>"},{"location":"HTML/02%20-%20elements/#videos","title":"Videos","text":"<p>Los videos son elementos HTML que permiten establecer un video, se definen con la etiqueta <code>&lt;video&gt;</code>.</p> <pre><code>&lt;video {atributos...} src=\"ruta_del_video\"&gt;&lt;/video&gt;\n</code></pre> <p>Posibles atributos de la etiqueta video:</p> <ul> <li><code>controls</code>: muestra los controles del video</li> <li><code>autoplay</code>: reproduce el video autom\u00e1ticamente</li> <li><code>loop</code>: repite el video</li> <li><code>muted</code>: silencia el video</li> <li><code>poster</code>: muestra una imagen mientras se carga el video</li> </ul>"},{"location":"HTML/02%20-%20elements/#audios","title":"Audios","text":"<p>Los audios son elementos HTML que permiten establecer un audio, se definen con la etiqueta <code>&lt;audio&gt;</code>.</p> <pre><code>&lt;audio {atributos...} src=\"ruta_del_audio\"&gt;&lt;/audio&gt;\n</code></pre> <p>Posibles atributos de la etiqueta audio:</p> <ul> <li><code>controls</code>: muestra los controles del audio</li> <li><code>autoplay</code>: reproduce el audio autom\u00e1ticamente</li> <li><code>loop</code>: repite el audio</li> <li><code>muted</code>: silencia el audio</li> </ul>"},{"location":"HTML/02%20-%20elements/#iframes","title":"Iframes","text":"<p>Un iframe (Inline Frame) es un elemento HTML que permite insertar un documento HTML dentro de otro. El contenido del iframe se carga de forma independiente al documento que lo contiene. Se definen con la etiqueta <code>&lt;iframe&gt;</code>.</p> <pre><code>&lt;iframe src=\"ruta_del_iframe\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Posibles atributos de la etiqueta iframe:</p> <ul> <li><code>width</code>: ancho del iframe</li> <li><code>height</code>: alto del iframe</li> <li><code>title</code>: t\u00edtulo del iframe</li> <li><code>allow</code>: indica qu\u00e9 funcionalidades se permiten al iframe.</li> </ul>"},{"location":"HTML/02%20-%20elements/#input","title":"Input","text":"<p>Los inputs son elementos HTML que permiten al usuario escribir informaci\u00f3n, se definen con la etiqueta <code>&lt;input&gt;</code>.</p> <pre><code>&lt;input type=\"text\" name=\"name\" id=\"name\"&gt;\n</code></pre> <p>Se puede cambiar el atributo <code>type</code> para crear diferentes tipos de campos:</p> <ul> <li><code>text</code>: campo de texto</li> <li><code>password</code>: campo para contrase\u00f1as</li> <li><code>email</code>: campo para correos electr\u00f3nicos</li> <li><code>number</code>: campo para n\u00fameros</li> <li><code>datetime-local</code>: campo para fechas y horas</li> <li><code>checkbox</code>: casilla de verificaci\u00f3n</li> </ul>"},{"location":"HTML/02%20-%20elements/#enlaces","title":"Enlaces","text":"<p>Los enlaces son elementos HTML que permiten establecer un enlace, se definen con la etiqueta <code>&lt;a&gt;</code>. Suele ir dentro de nav.</p> <pre><code>&lt;a href=\"https://www.google.com\"&gt;Contenido de enlace&lt;/a&gt;\n</code></pre> <p>Por defecto los enlaces se abren en la misma pesta\u00f1a. Si queremos que el enlace se abra en una nueva pesta\u00f1a, debemos a\u00f1adir el atributo <code>target=\"_blank\"</code>. Tambi\u00e9n es recomendable eliminar la referencia de origen con <code>rel=\"noopener noreferrer\"</code>.</p> <ul> <li><code>noopener</code>: impide que el enlace abra en una pesta\u00f1a nueva. De esta forma, el nuevo enlace no puede acceder a la ventana actual.</li> <li><code>noreferrer</code>: impide que el enlace abra en una pesta\u00f1a nueva y, adem\u00e1s, no envia el referer (informaci\u00f3n sobre la p\u00e1gina actual). De esta forma, el nuevo enlace no puede acceder a la ventana actual ni tener informaci\u00f3n sobre la p\u00e1gina que lo llama. En navegadores modernos no es necesario a\u00f1adirlo ya que por defecto lo hace.</li> </ul> <pre><code>&lt;a href=\"https://www.google.com\" target=\"_blank\" rel=\"noopener noreferrer\"&gt;Contenido de enlace&lt;/a&gt;\n</code></pre> <p>Tambi\u00e9n es posible hacer enlaces internos dentro de la misma web, pero para ello debemos definir con un identificador dichos puntos.</p> <pre><code>&lt;a href=\"#section_1\"&gt;Contenido de enlace&lt;/a&gt;\n\n...\n\n&lt;section id=\"section_1\"&gt;\n    &lt;h2&gt;Encabezado de section&lt;/h2&gt;\n    &lt;p&gt;Contenido de section&lt;/p&gt;\n&lt;/section&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#elementos-semanticos","title":"Elementos sem\u00e1nticos","text":"<p>Este grupo de elementos son muy importantes para conseguir un archivo HTML con buena sem\u00e1ntica, es decir, con una buena estructura para generar la p\u00e1gina web.</p>"},{"location":"HTML/02%20-%20elements/#aside","title":"aside","text":"<p>El elemento <code>&lt;aside&gt;</code> es un elemento HTML que se utiliza para definir contenido tangencialmente relacionado con el contenido principal de la p\u00e1gina web. Se utiliza para definir contenido que no sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web.</p> <pre><code>&lt;aside&gt;\n    &lt;h2&gt;Encabezado de aside&lt;/h2&gt;\n    &lt;p&gt;Contenido de aside&lt;/p&gt;\n&lt;/aside&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#section","title":"section","text":"<p>El elemento <code>&lt;section&gt;</code> es un elemento HTML que se utiliza para definir una secci\u00f3n de contenido en una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web.</p> <pre><code>&lt;section&gt;\n    &lt;h2&gt;Encabezado de section&lt;/h2&gt;\n    &lt;p&gt;Contenido de section&lt;/p&gt;\n&lt;/section&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#nav","title":"nav","text":"<p>El elemento <code>&lt;nav&gt;</code> es un elemento HTML que se utiliza para definir una secci\u00f3n de navegaci\u00f3n en una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web.</p> <pre><code>&lt;nav&gt;\n    &lt;h2&gt;Encabezado de nav&lt;/h2&gt;\n    &lt;p&gt;Contenido de nav&lt;/p&gt;\n&lt;/nav&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#footer","title":"footer","text":"<p>El elemento <code>&lt;footer&gt;</code> es un elemento HTML que se utiliza para definir el pie de p\u00e1gina de una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web.</p> <pre><code>&lt;footer&gt;\n    &lt;h2&gt;Encabezado de footer&lt;/h2&gt;\n    &lt;p&gt;Contenido de footer&lt;/p&gt;\n&lt;/footer&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#main","title":"main","text":"<p>El elemento <code>&lt;main&gt;</code> es un elemento HTML que se utiliza para definir el contenido principal de una p\u00e1gina web, s\u00f3lo puede haber un main por p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web. Es el contenido que hace la p\u00e1gina web \u00fanica.</p> <pre><code>&lt;main&gt;\n    &lt;h2&gt;Encabezado de main&lt;/h2&gt;\n    &lt;p&gt;Contenido de main&lt;/p&gt;\n&lt;/main&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#article","title":"article","text":"<p>El elemento <code>&lt;article&gt;</code> es un elemento HTML que se utiliza para definir un art\u00edculo en una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web.</p> <pre><code>&lt;article&gt;\n    &lt;h2&gt;Encabezado de article&lt;/h2&gt;\n    &lt;p&gt;Contenido de article&lt;/p&gt;\n&lt;/article&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#span","title":"span","text":"<p>El elemento <code>&lt;span&gt;</code> es un elemento HTML que se utiliza para definir un elemento en una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web. Se usa para separar estilo de una parte de la web cuando no afecta a la sem\u00e1ntica de la p\u00e1gina.</p> <pre><code>&lt;span&gt;Contenido de span&lt;/span&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#div","title":"div","text":"<p>El elemento <code>&lt;div&gt;</code> es un elemento HTML que se utiliza para definir un elemento en una p\u00e1gina web. Se utiliza para definir contenido que sea fundamental para la comprensi\u00f3n principal de la p\u00e1gina web. Se usa para agrupar elementos que no afectan a la sem\u00e1ntica de la p\u00e1gina.</p> <pre><code>&lt;div&gt;\n    &lt;h2&gt;Encabezado de div&lt;/h2&gt;\n    &lt;p&gt;Contenido de div&lt;/p&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#elementos-vacios","title":"Elementos vac\u00edos","text":"<p>Un elemento vac\u00edo en HTML es aquel que no tiene contenido y no requiere etiqueta de cierre</p>"},{"location":"HTML/02%20-%20elements/#metadatos","title":"Metadatos","text":"<p>Los metadatos son elementos HTML que permiten establecer metadatos, se definen con la etiqueta <code>&lt;meta&gt;</code>. Usando la etiqueta metadatos se pueden definir muchos metadatos de la p\u00e1gina web. No todos los metadatos son elementos vac\u00edos, pero s\u00ed la mayor\u00eda.</p> <pre><code>&lt;!-- Especifica la codificaci\u00f3n --&gt;\n&lt;meta charset=\"UTF-8\"&gt;\n&lt;!-- Define la descripci\u00f3n de la p\u00e1gina --&gt;\n&lt;meta name=\"description\" content=\"Descripci\u00f3n de la p\u00e1gina\"&gt;\n&lt;!-- Ajusta el ancho de la p\u00e1gina al tama\u00f1o del dispositivo --&gt;\n&lt;meta name=\"viewport\" content=\"width=device-width\"&gt;\n&lt;!-- Propiedades para open graph (Para SEO) --&gt;\n&lt;meta property=\"og:title\" content=\"T\u00edtulo de la p\u00e1gina en open graph\"&gt;\n&lt;meta property=\"og:description\" content=\"Descripci\u00f3n de la p\u00e1gina en open graph\"&gt;\n&lt;meta property=\"og:image\" content=\"Ruta de la imagen en open graph\"&gt;\n&lt;!-- Propiedades para redireccionar por idiomas (Para SEO) --&gt;\n&lt;link rel=\"alternate\" href=\"https://www.&lt;same_url&gt;/en\" hreflang=\"en-GB\"&gt;\n&lt;link rel=\"alternate\" href=\"https://www.&lt;same_url&gt;/es\" hreflang=\"es-ES\"&gt;\n&lt;!-- Propiedad para redireccionar a la principal (Para SEO, Ej sin www) --&gt;\n&lt;link rel=\"canonical\" href=\"https://&lt;same_url&gt;\"&gt;\n&lt;!-- Estilos en l\u00ednea --&gt;\n&lt;style&gt;\n    body {\n        background-color: blue;\n        /* background-color: #09f; */\n    }\n&lt;/style&gt;\n&lt;!-- M\u00e1s posible metadatos ... --&gt;\n</code></pre> <p><code>description</code> es importante para el SEO ya que es la descripci\u00f3n que suele aparecer (no siempre) en los resultados de b\u00fasqueda de google.</p>"},{"location":"HTML/02%20-%20elements/#link","title":"Link","text":"<p>Los link son elementos HTML que permiten establecer un enlace, se definen con la etiqueta <code>&lt;link&gt;</code>. Es la etiqueta que se usa para definir el <code>favicon</code>, es decir, el icono que aparece en la pesta\u00f1a del navegador.</p> <pre><code>&lt;link rel=\"icon\" type=\"image/jpg\" href=\"/docs/HTML/im-logo-1.jpg\"&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#salto-de-linea","title":"Salto de l\u00ednea","text":"<p>Los saltos de l\u00ednea son elementos HTML que permiten establecer un salto de l\u00ednea, se definen con la etiqueta <code>&lt;br&gt;</code>.</p> <pre><code>&lt;br&gt;\n</code></pre>"},{"location":"HTML/02%20-%20elements/#atributos","title":"Atributos","text":"<p>Los atributos son pares de clave valor que se agregan a las etiquetas HTML para proporcionar m\u00e1s informaci\u00f3n sobre el elemento. Se definen escribiendo el nombre del atributo seguido del valor entre comillas.</p> <p>Existen dos tipos de atributos:</p>"},{"location":"HTML/02%20-%20elements/#atributos-globales","title":"Atributos globales","text":"<p>Los atributos globales son aquellos que se pueden utilizar en cualquier elemento HTML. Algunos de los atributos globales son:</p> <ul> <li><code>class</code>: Indica una o varias clases CSS que se aplican al elemento. Tambi\u00e9n sirve para identificar elementos, pero este id se puede   repetir.</li> <li><code>id</code>: Indica el identificador \u00fanico del elemento. Este id se puede repetir.</li> <li><code>style</code>: Indica el estilo CSS que se aplica al elemento.</li> <li><code>title</code>: Indica el t\u00edtulo del elemento.</li> <li><code>role</code>: Indica el rol del elemento. Se utiliza para mejorar la accesibilidad de la p\u00e1gina web.</li> </ul>"},{"location":"HTML/02%20-%20elements/#atributos-especificos","title":"Atributos espec\u00edficos","text":"<p>Los atributos espec\u00edficos son aquellos que solo se pueden utilizar en determinados elementos HTML. Algunos de los atributos espec\u00edficos son:</p> <ul> <li><code>src</code> en <code>&lt;img&gt;</code>: Indica la ruta de la imagen a mostrar.</li> <li><code>href</code> en <code>&lt;a&gt;</code>: Indica la ruta del enlace.</li> <li><code>type</code> en <code>&lt;input&gt;</code>: Indica el tipo de campo de formulario.</li> <li><code>alt</code> en <code>&lt;img&gt;</code>: Indica el texto alternativo de la imagen en caso de no poderse mostrar.</li> <li><code>hidden</code> en <code>&lt;img&gt;</code>: Indica que la imagen no se muestra.</li> </ul>"},{"location":"HTML/02%20-%20elements/#tipos-de-href","title":"Tipos de href","text":"<p>Dentro de href se pueden definir varios tipos de enlaces:</p> <ul> <li> <p>Enlaces internos: Enlaces que apuntan a una p\u00e1gina dentro de la misma web.</p> <pre><code>&lt;a href=\"/\"&gt;Inicio&lt;/a&gt;\n</code></pre> </li> <li> <p>Enlaces externos: Enlaces que apuntan a una p\u00e1gina fuera de la misma web.</p> <pre><code>&lt;a href=\"https://www.google.com\"&gt;Google&lt;/a&gt;\n</code></pre> </li> <li> <p>Enlaces de correo: Enlaces que apuntan a un correo electr\u00f3nico.</p> <pre><code>&lt;a href=\"mailto:info@example.com\"&gt;info@example.com&lt;/a&gt;\n</code></pre> </li> <li> <p>Enlaces de tel\u00e9fono: Enlaces que apuntan a un n\u00famero de tel\u00e9fono.</p> <pre><code>&lt;a href=\"tel:+34913333333\"&gt;+34 913 33 33 33&lt;/a&gt;\n</code></pre> </li> <li> <p>Enlace a whatsapp: Enlaces que apuntan a whatsapp.</p> <pre><code>&lt;a href=\"whatsapp://send?text=Hola&amp;phone=+34666666666\"&gt;WhatsApp&lt;/a&gt;\n</code></pre> </li> <li> <p>Enlaces de mapa: Enlaces que apuntan a un mapa.</p> <pre><code>&lt;a href=\"https://www.openstreetmap.org/#map=18/40.4085/-3.69196\"&gt;Madrid&lt;/a&gt;\n</code></pre> </li> </ul>"},{"location":"Kafka/01%20-%20Overview/","title":"Introducci\u00f3n","text":""},{"location":"Kafka/01%20-%20Overview/#que-es-kafka-y-como-funciona","title":"\u00bfQu\u00e9 es Kafka y c\u00f3mo funciona?","text":"<p>Apache Kafka es una plataforma de c\u00f3digo abierto para la transmisi\u00f3n de datos, que funciona como una cola de mensajes tradicional de tipo pub-sub, permitiendo la publicaci\u00f3n y suscripci\u00f3n a flujos de mensajes.</p> <p>Lo que lo diferencia de las colas de mensajes tradicionales es que el principal prop\u00f3sito de Kafka es optimizar la transmisi\u00f3n y el procesamiento de los flujos de datos intercambiados. Espec\u00edficamente, podemos decir que Kafka act\u00faa como intermediario entre el emisor y el receptor al ofrecer una funci\u00f3n de mensajer\u00eda; mediante este m\u00e9todo, la plataforma tambi\u00e9n es capaz de resolver el problema de los datos o mensajes que no se almacenan temporalmente cuando el receptor no est\u00e1 disponible (por ejemplo, problemas de red).</p> <p>Adem\u00e1s, una cola de Kafka bien configurada evita que el emisor sobrecargue al receptor. Esto ocurre cuando la informaci\u00f3n necesita ser enviada m\u00e1s r\u00e1pidamente mediante conexi\u00f3n directa, para ser recibida y procesada. Kafka se considera una plataforma adecuada incluso si el sistema de destino recibe el mensaje pero colapsa durante el proceso, donde el error es notificado; en casos normales, a pesar del colapso, uno podr\u00eda creer que el procesamiento fue exitoso.</p> <p>Kafka combina tres caracter\u00edsticas clave:</p> <ul> <li>Publicar (escribir) y suscribirse (leer) a flujos de eventos, incluyendo la importaci\u00f3n/exportaci\u00f3n continua de datos desde otros sistemas.</li> <li>Almacenar flujos de eventos de manera duradera y confiable durante el tiempo que desees.</li> <li>Procesar flujos de eventos a medida que ocurren o de forma retrospectiva.</li> </ul> <p>Y toda esta funcionalidad se proporciona de manera distribuida, altamente escalable, el\u00e1stica, tolerante a fallos y segura. Kafka puede desplegarse en hardware bare-metal, m\u00e1quinas virtuales y contenedores, tanto en instalaciones locales como en la nube.</p>"},{"location":"Kafka/01%20-%20Overview/#cuales-son-los-conceptos-fundamentales-de-kafka","title":"\u00bfCu\u00e1les son los conceptos fundamentales de Kafka?","text":"<p>En general, Kafka acepta flujos de eventos escritos por los productores de datos. Kafka almacena los datos de forma cronol\u00f3gica en particiones entre brokers (servidores); varios brokers forman un cl\u00faster. Kafka agrupa estos datos en categor\u00edas llamadas topics; los consumidores de datos obtienen los datos suscribi\u00e9ndose a los topics deseados. Cuando lees o escribes datos en Kafka, lo haces en forma de eventos. Conceptualmente, un evento tiene una clave, valor, marca de tiempo y encabezados de metadatos opcionales.</p>"},{"location":"Kafka/01%20-%20Overview/#que-es-un-evento","title":"\u00bfQu\u00e9 es un evento?","text":"<p>Un evento es un mensaje con datos que describen el evento. Por ejemplo, cuando un nuevo usuario se registra en un sitio web, el sistema crea un evento de registro, que puede incluir el nombre del usuario, correo electr\u00f3nico, contrase\u00f1a, ubicaci\u00f3n, etc.</p> <p>Los eventos se organizan y se almacenan de manera duradera en topics. Simplificando mucho, un topic es similar a una carpeta en un sistema de archivos, y los eventos son los archivos en esa carpeta. Los topics en Kafka siempre son multi-productor y multi-suscriptor: un topic puede tener cero, uno o muchos productores que escriben eventos en \u00e9l, as\u00ed como cero, uno o muchos consumidores que se suscriben a estos eventos.</p> <p>Los eventos en un topic se pueden leer tantas veces como sea necesario, a diferencia de los sistemas de mensajer\u00eda tradicionales, los eventos no se eliminan despu\u00e9s de ser consumidos. En su lugar, se define cu\u00e1nto tiempo debe retener Kafka tus eventos a trav\u00e9s de una configuraci\u00f3n por topic, despu\u00e9s de lo cual los eventos antiguos ser\u00e1n descartados. El rendimiento de Kafka es efectivamente constante con respecto al tama\u00f1o de los datos, por lo que almacenar datos durante mucho tiempo es perfectamente aceptable.</p>"},{"location":"Kafka/01%20-%20Overview/#que-es-un-broker-y-un-cluster","title":"\u00bfQu\u00e9 es un broker y un cl\u00faster?","text":"<p>Kafka se ejecuta en clusters (esto es una colecci\u00f3n de computadoras). Cada cl\u00faster est\u00e1 compuesto por m\u00faltiples servidores, generalmente llamados brokers. Este modo convierte a Kafka en un sistema distribuido porque los datos se distribuyen entre m\u00faltiples brokers.</p>"},{"location":"Kafka/01%20-%20Overview/#quienes-son-los-consumidores-y-productores-y-que-hacen","title":"\u00bfQui\u00e9nes son los consumidores y productores, y qu\u00e9 hacen?","text":"<p>Un productor es cualquier entidad que crea datos o produce informaci\u00f3n o eventos. Por ejemplo, el componente del sitio web responsable de los registros de usuarios produce un evento de \"nuevo usuario registrado\" o un sensor meteorol\u00f3gico produce eventos de \"clima\" con informaci\u00f3n sobre temperatura, humedad, etc.</p> <p>Los consumidores, por otro lado, son aquellos que \"consumen\" los datos escritos por los productores. Generalmente act\u00faan como consumidores de datos, almacenando o analizando los datos que reciben de Kafka. Por lo tanto, Kafka se encuentra entre productores y consumidores.</p>"},{"location":"Kafka/01%20-%20Overview/#que-es-un-topic","title":"\u00bfQu\u00e9 es un topic?","text":"<p>Los eventos se organizan y se almacenan de manera duradera en topics. Los productores publican estos eventos en los topics de Kafka mientras que los consumidores se suscriben a los topics para acceder a los datos deseados. Tomando nuevamente el ejemplo del registro, la informaci\u00f3n sobre el \"nuevo usuario\" se publica (a trav\u00e9s de Kafka) en el topic de \"registro\". Los suscriptores, a su vez, consumen eventos del topic de \"registro\" y lo utilizan junto con otros datos como base para la prestaci\u00f3n de sus productos o servicios.</p> <p>Una partici\u00f3n es donde los datos se almacenan en Kafka y sirve para dividir la informaci\u00f3n recibida en funci\u00f3n del topic correspondiente.</p> <p>Los topics est\u00e1n particionados, lo que significa que un topic se distribuye en varios \"buckets\" ubicados en diferentes brokers de Kafka. Esta distribuci\u00f3n de tus datos es muy importante para la escalabilidad porque permite que las aplicaciones cliente tanto lean como escriban datos desde/hacia muchos brokers al mismo tiempo. Cuando se publica un nuevo evento en un topic, en realidad se a\u00f1ade a una de las particiones del topic. Los eventos con la misma clave de evento se escriben en la misma partici\u00f3n, y Kafka garantiza que cualquier consumidor de una partici\u00f3n dada siempre leer\u00e1 los eventos de esa partici\u00f3n en exactamente el mismo orden en que fueron escritos.</p> <p>Los consumidores trabajan como parte de un grupo de consumidores, que es uno o m\u00e1s consumidores que trabajan juntos para consumir un topic. El grupo asegura que cada partici\u00f3n sea consumida solo por un miembro. Un mensaje de la cola del topic no se elimina hasta que todos los grupos de consumidores lo hayan consumido (otra forma de eliminar un mensaje de la cola del topic es si el mensaje ha caducado por tama\u00f1o de la cola o por tiempo).</p> <p>Para hacer que tus datos sean tolerantes a fallos y altamente disponibles, cada topic puede ser replicado, incluso a trav\u00e9s de regiones geogr\u00e1ficas o centros de datos, de modo que siempre haya m\u00faltiples brokers que tengan una copia de los datos en caso de que algo salga mal, si deseas hacer mantenimiento en los brokers, etc.</p> <p>El diagrama que se muestra aqu\u00ed representa lo que hace Kafka:</p> <pre><code>flowchart TD\nproducer[Producer] --&gt; kafka_broker\nkafka_broker --&gt; consumer[Consumer]\n    subgraph kafka_broker\n        subgraph \"Topic A\"\n            valueA1[Partition]\n            valueA2[Partition]\n            valueA3[Partition]\n        end\n        subgraph \"Topic B\"\n            valueB1[Partition]\n            valueB2[Partition]\n            valueB3[Partition]\n        end\n        subgraph \"Topic C\"\n            valueC1[Partition]\n            valueC2[Partition]\n            valueC3[Partition]\n        end\n    end</code></pre> <p>El siguiente diagrama muestra como funciona un consumidor de kafka:</p> <pre><code>flowchart LR\nsubgraph kafka_broker\n    subgraph Topic X - Partition 0\n        valueP0A1[Value A1]\n        valueP0A2[Value A2]\n        valueP0A.[...]\n        valueP0An[Value An]\n    end\n    subgraph Topic X - Partition 1\n        valueP1A1[Value B1]\n        valueP1A2[Value B2]\n        valueP1A.[...]\n        valueP1An[Value Bn]\n    end\nend\nsubgraph consumer_group_1\n    consumer1_g1[\"Consumer 1\"]\n    consumer1_g1 --&gt; note1_g1[[Consuming messages from partition 0 and 1]]\nend\nsubgraph consumer_group_2\n    consumer1_g2[\"Consumer 1\"]\n    consumer1_g2 --&gt; note1_g2[[Consuming messages from partition 0]]\n    consumer2_g2[\"Consumer 2\"]\n    consumer2_g2 --&gt; note2_g2[[Consuming messages from partition 1]]\nend\n\nproducer[Producer] --&gt; kafka_broker\nkafka_broker --&gt; consumer_group_1\nkafka_broker --&gt; consumer_group_2</code></pre> <p>El siguiente diagrama muestra como funciona un brocker de kafka:</p> <pre><code>flowchart LR\nsubgraph \"Kafka Cluster\"\n    subgraph \"Kafka Broker 1\"\n        B1_P0[Topic X - Partition 0 - Leader]\n        B1_P1[Topic X - Partition 1 - Backup 2]\n        B1_P2[Topic X - Partition 2 - Backup 1]\n    end\n    subgraph \"Kafka Broker 2\"\n        B2_P0[Topic X - Partition 0 - Backup 1]\n        B2_P1[Topic X - Partition 1 - Leader]\n        B2_P2[Topic X - Partition 2 - Backup 2]\n    end\n    subgraph \"Kafka Broker 3\"\n        B3_P0[Topic X - Partition 0 - Backup 2]\n        B3_P1[Topic X - Partition 1 - Backup 1]\n        B3_P2[Topic X - Partition 2 - Leader]\n    end\nend\n</code></pre>"},{"location":"Kafka/01%20-%20Overview/#pagina-oficial","title":"P\u00e1gina oficial","text":"<p>Para obtener informaci\u00f3n m\u00e1s espec\u00edfica, puedes ir a la p\u00e1gina oficial haciendo clic en este enlace: Documentaci\u00f3n oficial de Kafka Apache</p>"},{"location":"Kafka/python_kafka_examples/","title":"Ejemplos con Python","text":""},{"location":"Kafka/python_kafka_examples/#requisitos-previos","title":"Requisitos previos","text":"<ol> <li>Instalar Kafka: Aseg\u00farate de tener Kafka instalado y en funcionamiento en tu entorno.</li> <li>Instalar la librer\u00eda confluent_kafka: Puedes instalarla mediante pip:</li> </ol> <pre><code>pip install confluent_kafka\n</code></pre>"},{"location":"Kafka/python_kafka_examples/#kafka-producer","title":"Kafka producer","text":"<p>El productor env\u00eda mensajes a un topic espec\u00edfico en Kafka. A continuaci\u00f3n, se muestra un ejemplo simple de c\u00f3mo crear un productor en Python:</p> producer.py<pre><code>from confluent_kafka import Producer\n\n# Configuraci\u00f3n del productor\nconf = {\n    'bootstrap.servers': 'localhost:9092'  # Direcci\u00f3n del broker de Kafka\n}\n\n# Crear el productor\nproducer = Producer(conf)\n\n# Funci\u00f3n para confirmar la entrega de los mensajes\ndef delivery_report(err, msg):\n    if err is not None:\n        print(f'Error en la entrega: {err}')\n    else:\n        print(f'Mensaje entregado a {msg.topic()} [{msg.partition()}]')\n\n# Enviar un mensaje\ntopic = 'mi_topic'\nproducer.produce(topic, key='mi_clave', value='Hola, Kafka!', callback=delivery_report)\n\n# Esperar a que se env\u00eden todos los mensajes\nproducer.flush()\n</code></pre> <p>Explicaci\u00f3n:</p> <ul> <li>bootstrap.servers: Especifica la direcci\u00f3n del broker de Kafka.</li> <li>producer.produce: Envia un mensaje al topic especificado. La funci\u00f3n delivery_report es una callback que maneja la confirmaci\u00f3n de la entrega.</li> <li>producer.flush: Asegura que todos los mensajes se hayan enviado antes de cerrar el productor.</li> </ul>"},{"location":"Kafka/python_kafka_examples/#kafka-consumer","title":"Kafka consumer","text":"<p>El consumidor se suscribe a un topic y recibe mensajes. A continuaci\u00f3n se muestra c\u00f3mo crear un consumidor en Python:</p> consumer.py<pre><code>from confluent_kafka import Consumer, KafkaException\n\n# Configuraci\u00f3n del consumidor\nconf = {\n    'bootstrap.servers': 'localhost:9092',  # Direcci\u00f3n del broker de Kafka\n    'group.id': 'mi_grupo',                 # ID del grupo de consumidores\n    'auto.offset.reset': 'earliest'         # Leer mensajes desde el principio si no hay offset guardado\n}\n\n# Crear el consumidor\nconsumer = Consumer(conf)\n\n# Suscribirse al topic\ntopic = 'mi_topic'\nconsumer.subscribe([topic])\n\n# Leer mensajes\ntry:\n    while True:\n        msg = consumer.poll(timeout=1.0)\n        if msg is None:\n            continue\n        if msg.error():\n            raise KafkaException(msg.error())\n        print(f'Recibido: {msg.value().decode(\"utf-8\")} de {msg.topic()} [{msg.partition()}] en offset {msg.offset()}')\n\nexcept KeyboardInterrupt:\n    pass\n\nfinally:\n    # Cerrar el consumidor\n    consumer.close()\n</code></pre> <p>Explicaci\u00f3n:</p> <ul> <li>group.id: Define el ID del grupo de consumidores, lo cual permite que m\u00faltiples consumidores compartan la carga.</li> <li>auto.offset.reset: Configura desde d\u00f3nde comenzar a leer mensajes si no se ha guardado un offset previo.</li> <li>consumer.poll: Espera mensajes del topic y los procesa. Se usa un bucle para leer mensajes de manera continua.</li> </ul>"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/","title":"Machine learning","text":"<p>El Machine Learning es una disciplina del campo de la Inteligencia Artificial que, a trav\u00e9s de algoritmos, dota a los ordenadores de la capacidad de identificar patrones en datos masivos y elaborar predicciones (an\u00e1lisis predictivo) - sin necesidad de definirles d\u00f3nde tienen que mirar de forma expl\u00edcita.</p> <p>Hay dos tipos principales de machine learning:</p> <ul> <li>Aprendizaje supervisado.</li> <li>Aprendizaje no supervisado.</li> </ul>"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#aprendizaje-supervisado","title":"Aprendizaje supervisado","text":"<p>Los algoritmos de aprendizaje supervisado con entrenados usando ejemplos etiquetados (labeled examples) donde dada una entrada sabemos la salida deseada.</p> <p>La red recibe una serie de datos de entradas con su correspondiente salida deseada, entonces el algoritmo aprende al comparar su salida actual con la salida deseada y calculando el error. Luego se usa ese error para ajustar el modelo en consecuencia.</p> <pre><code>flowchart LR\ndata_collection[Collecci\u00f3n de datos]\ndata_clean[Limpieza de datos]\ntest_data[Datos para testeo]\nmodel_train[Generaci\u00f3n y entrenamiento del modelo]\nmodel_test[Modelo de testeo]\nmodel_deploy[Modelo final]\n\ndata_collection --&gt; data_clean\ndata_clean -- 1 --&gt; model_train\ndata_clean -- 1 --&gt; test_data\ntest_data --&gt; model_test\nmodel_train -- 2/4/6/... --&gt; model_test\nmodel_test -- 3/5/7/... --&gt; model_train\nmodel_test --&gt; model_deploy</code></pre>"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#tipos-de-datos","title":"Tipos de datos","text":"Tipos de datos Description Datos de entrenamiento Se usan para entrenar los par\u00e1metros del modelo. Datos de validaci\u00f3n Se usan para determinar el rendimiento obtenido tras el entrenamiento y determinar si hay que realizar cambio en el modelo, como a\u00f1adir m\u00e1s neuronas, a\u00f1adir m\u00e1s capaz, cambiar la arquitectura de la red, etc. Para un entrenamiento simple, este conjunto de datos es opcional, pero es muy recomendable. Datos de testeo Se usa para calcular el rendimiento final del modelo. En este conjunto se contiene datos que el modelo nunca antes ha visto durante el entrenamiento."},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#tipos-de-ajuste","title":"Tipos de ajuste","text":"Tipos de ajuste Description Overfitting (Sobreajuste) Se produce cuando el modelo se ajusta mucho al ruido de los datos, lo que da un bajo error con los conjuntos de entrenamiento pero un gran error en las pruebas de testeo y validaci\u00f3n. Underfitting (Subajuste) Se produce cuando el modelo no se ajusta lo suficiente (normalmente por ser demasiado simple). <p>Un buen modelo debe comenzar con un gran error e ir reduciendo el error a medida que avanza el tiempo que lleva entrenando (tiempo de entrenamiento - en EEUU se llama \"epics\" - en UK se llama \"epochs\"), puede ser que el error nunca llegue a cero, pero se mantendr\u00e1 estable en un valor cercano a cero.</p>"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#evaluacion-del-rendimiento","title":"Evaluaci\u00f3n del rendimiento","text":"M\u00e9tricas de clasificaci\u00f3n Description Accuracy (precisi\u00f3n) N\u00famero de predicciones correctas del modelo dividido entre el total n\u00famero de predicciones. Para esta medida es importante tener las muestras de testeo balanceadas (misma cantidad de datos de cada posible respuesta). Recall (recuerdo) Capacidad del modelo para encontrar todos los casos relevantes dentro de un conjunto de datos. N\u00famero de positivos verdaderos (true positives) dividido entre el n\u00famero de positivos verdaderos y falsos negativos (false negatives). Precision (precisi\u00f3n) Capacidad de un modelo para identificar  s\u00f3lo los puntos de datos relevantes. N\u00famero de positivos verdaderos (true positives) dividido entre el n\u00famero de positivos verdaderos y falsos positivos (false positives). F1-Score Es tambi\u00e9n llamado como la media arm\u00f3nica y es una combinaci\u00f3n entre precisi\u00f3n (precision) y recuerdo (recall). \\(F = 2*((precision*recall)/(precision+recall))\\)"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#clasificacion-de-errores","title":"Clasificaci\u00f3n de errores","text":"<p>Confusion matrix encapsula todos los True/False positives and True/False negatives.</p> <p></p>"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#regresion-de-errores","title":"Regresi\u00f3n de errores","text":"<p>Para calcular la regresi\u00f3n, las m\u00e9tricas m\u00e1s comunes a usar son:</p> M\u00e9tricas de regresi\u00f3n Traducci\u00f3n al espa\u00f1ol F\u00f3rmula Mean absolute error (MAE) Error absoluto medio \\(\\dfrac{1}{n}\\sum_{i}^{n} = abs(y_i-y_i')\\) Mean squared error (MSE) Eror cuadr\u00e1tico medio \\(\\dfrac{1}{n}\\sum_{i}^{n} = abs(y_i-y_i')^2\\) Root mean square error (RMSE) Ra\u00edz del error cuadr\u00e1tico medio \\(\\sqrt{\\dfrac{1}{n}\\sum_{i}^{n} = abs(y_i-y_i')^2}\\)"},{"location":"Machine%20Learning/Deep%20Learning/01-concepts/#aprendizaje-no-supervisado","title":"Aprendizaje no supervisado","text":"<p>Esto sucede cuando no sabemos todas las etiquetas posibles. Pare entender sobre el aprendizaje no supervisado antes tenemos que saber sobre los siguientes puntos.</p> <ul> <li>Clustering (Agupaci\u00f3n).</li> <li>Agrupar conjuntamente grupo de valores/datos/puntos que no est\u00e1n dentro de una etiqueta.</li> <li>Anomaly Detection (Deteci\u00f3n de anomal\u00edas).</li> <li>Detectar valores at\u00edpicos en un conjunto de datos.</li> <li>Dimensionality Reduction (Reduci\u00f3n de anomal\u00edas).</li> <li>T\u00e9cnica de procesamiento de datos que reduce el n\u00famero de caracter\u00edsticas de un conjunto de datos</li> </ul>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/","title":"Artificial Neural Networks (ANNs)","text":""},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#modelo-del-perceptron-perceptron-model","title":"Modelo del perceptron (Perceptron model)","text":"<pre><code>flowchart LR\nsubgraph inputs\nx1[x1]\nx2[x2]\nend\n\nfx((\"f(X)\"))\n\nsubgraph Output\ny[y]\nend\n\nx1 -- w1+b--&gt; fx\nx2 -- w2+b --&gt; fx\nfx --&gt; y</code></pre> <p>w: weight  b: bias</p> <p>\\(\\hat{y} = \\sum_{i=1}^{n} x_iw_i + b_i\\)</p> <p>y si a\u00f1adimos que \\(B = b1+b2+...+bn\\)</p> <p>\\(\\hat{y} = B + \\sum_{i=1}^{n} x_iw_i\\)</p>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#redes-neuronales-neural-networks","title":"Redes neuronales (Neural networks)","text":"<p>Las redes neuronales se generan al unir varios modelos de perceptr\u00f3n en lo que se llama modelo del perceptr\u00f3n multicapa (<code>multi-layer perceptron model</code>).</p> <p>Las salidas de una capa de perceptrones, se usa como entrada para la siguinte capa de perceptrones.</p> <p>Los perceptrones tambi\u00e9n se llaman neuronas.</p> <pre><code>flowchart LR\nsubgraph layer 1 - Input layer\nl1p1((L1P1))\nl1p2((L1P2))\nl1pn((L1Pn))\nend\n\nsubgraph layer 2\nl2p1((L2P1))\nl2p2((L2P2))\nl2pn((L2Pn))\nend\n\nsubgraph layer n\nlnp1((LnP1))\nlnp2((LnP2))\nlnpn((LnPn))\nend\n\nsubgraph Output - Output layer\no[output]\nend\n\nl1p1 --&gt; l2p1\nl1p1 --&gt; l2p2\nl1p1 --&gt; l2pn\n\nl1p2 ==&gt; l2p1\nl1p2 ==&gt; l2p2\nl1p2 ==&gt; l2pn\n\nl1pn -.-&gt; l2p1\nl1pn -.-&gt; l2p2\nl1pn -.-&gt; l2pn\n\nl2p1 --&gt; lnp1\nl2p1 --&gt; lnp2\nl2p1 --&gt; lnpn\n\nl2p2 ==&gt; lnp1\nl2p2 ==&gt; lnp2\nl2p2 ==&gt; lnpn\n\nl2pn -.-&gt; lnp1\nl2pn -.-&gt; lnp2\nl2pn -.-&gt; lnpn\n\nlnp1 --&gt; o\nlnp2 ==&gt; o\nlnpn -.-&gt; o\n</code></pre> <p><code>L: layer</code></p> <p><code>P: perceptron</code></p> <ul> <li>La primera capa se llama capa de entrada (input layer).</li> <li>La \u00faltima capa se llama capa de salida (output layer). Esta \u00faltima capa puede tener una o m\u00e1s neuronas.</li> <li>Las capas entre la capa de entrada y salida se llaman capas escondidas (hidden layers).</li> </ul> <p>Se considera que una red es una redes neuronal profunda (<code>deep neural networks</code>) cuando contiene 2 o m\u00f1as capas escondidas.</p>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#funciones-de-activacion-activation-functions","title":"Funciones de activaci\u00f3n (activation functions)","text":"<p>Estas funciones se usan para limitar la salida de cada neurona.</p> <p>\\(Z = W*x + b\\)</p> Activation function Traducci\u00f3n al espa\u00f1ol Descripci\u00f3n Step function Funci\u00f3n paso Salida es 0 si Z&lt;=0, o salida es 1 si Z&gt;0 Sigmoid function Funci\u00f3n sigmoide Parecida a la step function (mismos l\u00edmites) pero m\u00e1s suave. \\(f(z) = \\dfrac{1}{(1+e^{-z})}\\) Hyperbolic Tangent - tanh(z) Tangente hiperb\u00f3lica Como la funci\u00f3n sigmoide, pero en lugar de entre 0 y 1 es entre -1 y 1 Rectified Linear Unit - ReLU Relu Salida es 0 si Z&lt;=0, o salida es Z si Z&gt;0. \\(f(z) = \\max(0,z)\\) <p>To see more activation functions, see link below.</p> <p>https://en.wikipedia.org/wiki/Activation_function</p>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#clasificacion-multiclase","title":"Clasificaci\u00f3n multiclase","text":"<p>Principalmente hay dos tipos de clasificaci\u00f3n multiclase.</p> <ul> <li>Clases no exclusivas. Cuando un dato puede ser asignados a varias clases o categer\u00edas.</li> <li>Clases mutuamente exclusivas. Cuando s\u00f3lo se puede asignar a un dato una clase o categor\u00eda.</li> </ul> <p>La mejor forma de organizar multiples clases es tener un nodo de salida por clase o categor\u00eda.</p>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#funcion-de-coste-y-descenso-del-gradiente","title":"Funci\u00f3n de coste y descenso del gradiente","text":"<p>La funci\u00f3n de coste, tambi\u00e9n llamada como funci\u00f3n de p\u00e9rdida, es la media de la diferencia entre la salida de nuestra red neuronal y el valor real.</p> <p>Una de las funciones de coste m\u00e1s comunes es la funci\u00f3n de coste cuadr\u00e1tica.</p> <p>\\(C = \\dfrac{1}{2n}\\sum_{x} abs(y(x)-a^L(x))^2\\)</p> <p>y(x): Valores reales  a(x): Valores de predicciones  L: suele ser la \u00faltima capa.  $a^L(x): $ Salida de la funci\u00f3n de activaci\u00f3n de la capa L.</p> <p>Se puede pensar en la funci\u00f3n de coste, como una func\u00f3n que depende de 4 elementos principalmante.</p> <p>\\(C(W,B, S^r, E^r)\\)</p> <p>\\(W\\): Pesos de la red.  \\(B\\): Todos los bias de la red  \\(S^r\\): Entrada de una muestra de entrenamiento.  \\(E^r\\): Salida deseada de esa muestra de entrenamiento.</p> <p>Lo normal ser\u00eda utilizar la combinaci\u00f3n de elementos que genera el error m\u00e1s bajo, pero calcular esto es muy complejo.</p> <p>Si cogemos como ejemplo que la funci\u00f3n de coste genera una par\u00e1bola invertida, hay un m\u00ednimo en un punto, que ser\u00eda el gradiente (representa la pendiente de la recta tangente a la gr\u00e1fica de una funci\u00f3n - es parecido a la derivada) igual a cero, pero calcular justo el error en ese punto es complicado cuando trabajamos con m\u00e1s de una dimensi\u00f3n, y al mismo tiempo coger una muestra para ver si es un m\u00ednimo depende frecuencia de muestreo, esta frecuencia se denomina como tasa de aprendizaje (learning rate).</p> <p></p> <p>La t\u00e9cnica descenso del gradiente adaptativo intenta solucionar el problema de la tasa de aprendizaje, usando una frecuencia alta cuando el error es muy grande, y una frecuencia menor cuando el gradiente se acerca a cero.</p> <p>Video donde se explica el descenso del gradiente</p> <p>Dentro de la t\u00e9cnica del descenso del gradiente adaptativo, uno de los m\u00e9todos m\u00e1s eficiente y com\u00fan para encontrar estos m\u00ednimos es usar el m\u00e9todo Adam (\"A method for Stochastic Optimization\").</p> <p>Para problemas de clasificaci\u00f3n, normalmente se usa la funci\u00f3n de coste de entrop\u00eda cruzada(cross entropy).</p>"},{"location":"Machine%20Learning/Deep%20Learning/02-ANNs/#retropropagacion-backpropagation","title":"Retropropagaci\u00f3n (Backpropagation)","text":"<p>La retropropagaci\u00f3n es la t\u00e9cnica que se usa para ajustar los pesos y bias (sesgos) de las diferentes neuronas en cada capa.</p> <p>Se comienza desde la \u00faltima capa <code>L</code> hacia la izquierda, <code>L-1</code>, <code>L-2</code>, ... <code>L-n</code>.</p> <p>Enfocandonos en las \u00faltimas dos capas (<code>L</code> y <code>L-1</code>).</p> <p>\\(z = wx+b\\)</p> <p>y la funci\u00f3n de activaci\u00f3n</p> <p>\\(a = \\sigma(Z)\\)</p> <p>Significa que tenemos</p> <p>\\(z^L = w^La^{L-1}+b^L\\)</p> <p>\\(z^L\\): Salida de la capa L  \\(w^L\\): Pesos de la capa L  \\(a^{L-1}\\): Funci\u00f3n de activaci\u00f3n de la capa anterior = Salida de la capa anterior  \\(b^L\\): Bias/Sesgos de la capa L</p> <p>Si contamos todas las capas.</p> <p>\\(a^L = \\sigma(Z^L)\\)</p> <p>La funci\u00f3n de coste quedar\u00eda:</p> <p>\\(C_0(...) = (a^L-y)^2\\)</p> <p>\\(y\\): Salida real</p> <p>La idea de retroproagaci\u00f3n es ir calculando el error en cada capa y usando el gradiente/derivada intentar minimizar dicho error. En un lenguaje m\u00e1s cotidiano, calcular con las derivadas parciales como se ve afectada la funci\u00f3n de coste cuando se modifica uno de los par\u00e1metros de las neuronas.</p> <p>\\(\\frac{\\delta C}{\\delta w}\\)</p> <p>Cuando nos referimos s\u00f3lo a la \u00faltima capa:</p> <p>\\(\\frac{\\delta C}{\\delta w^L} =\\frac{\\delta C}{\\delta a^L}\\frac{\\delta a^L}{\\delta z^L}\\frac{\\delta z^L}{\\delta w^L}\\)</p> <p>Link explicando las funciones matem\u00e1ticas (en ingl\u00e9s)</p> <p>Video es espa\u00f1ol sobre backpropagation</p> <p>Video es espa\u00f1ol sobre matem\u00e1ticas de backpropagation</p>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/","title":"Redes neuronales convolucionales - Convolutional Neural Networks (CNNs)","text":"<p>Las redes neuronales convolucionales es un tipo de red muy \u00fatil para trabajar con im\u00e1genes.</p> <p>Antes de seguir con este punto es importante tener algunos conocimientos de redes neuronales con keras (librer\u00eda de python), puedes ver Keras para tener m\u00e1s informaci\u00f3n.</p>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#las-imagenes-son-matrices","title":"Las im\u00e1genes son matrices","text":"<p>Una imagen es simplemente una o varias matrices con valores entre 0 y 255 que representa el valor de cada p\u00edxel.</p> <p>Si hablamos de una imagen en blanco y negro s\u00f3lo trabajaremos con una matriz.</p> <p>Pero hablamos de una imagen a color, esta se compone por 3 matrices, cada una para un color primario (rojo, verde y azul = RGB). Estos canales de colores es una matriz en escala de grises que indica el valor (0-255) de cada color para cada pixel de la imagen.</p> <p>Por lo que las caracter\u00edsticas de una imagen a color (1280, 720,3) ser\u00edan las siguientes:</p> <ul> <li>1280  P\u00edxeles de ancho.</li> <li>720  P\u00edxeles de alto.</li> <li>3  Canales de colores (RGB).</li> </ul>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#pre-procesamiento-de-imagenes","title":"Pre-procesamiento de im\u00e1genes","text":""},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#filtro-de-imagenes","title":"Filtro de im\u00e1genes","text":"<p>Filtrar una imagen es aplicar una \"imagen kernel\", que es una pequ\u00f1a matriz, a toda la matriz de la imagen.</p> <p>Hay filtros bastante comunes como el filtro de difusi\u00f3n que difumina la imagen. Esto se consigue con la siguiente matr\u00edz.</p> \\[ Blur Filter = \\begin{pmatrix}   0.0625 &amp; 0.125 &amp; 0.0625 \\\\   0.125 &amp; 0.25 &amp; 0.125 \\\\   0.0625 &amp; 0.125 &amp; 0.0625 \\end{pmatrix} \\]"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#aplicar-filtros-a-una-imagen","title":"Aplicar filtros a una imagen","text":"<p>Cuando aplicamos un filtro, digamos como ejemplo que queremos aplicar un filtro que consiste en una matriz 3x3, la imagen final tendr\u00e1 un tama\u00f1o reducido tras el filtrado, ya que estamos cogiendo 9 p\u00edxeles que al aplicarle el filtro s\u00f3lo genera 1 pixel de salida.</p> <p>Ver esta web donde se explica con un ejemplo real c\u00f3mo afecta el filtrado a una imagen.</p>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#kernels-convolucionales","title":"Kernels convolucionales","text":"<p>Dentro del contexto de CNNs, estos \"filtros\" son llamados kernels convolucionales, y la acci\u00f3n de pasar una imagen a trav\u00e9s de ellos se llama convoluci\u00f3n.</p> <p>Es importante destacar que al aplicar filtros a la matriz de una imagen, podemos perder informaci\u00f3n en los bordes de la misma, ya que en dichos bordes no se puede aplicar el filtro. Por lo tanto, es bastante com\u00fan en el \u00e1mbito de las redes convolucionales extender la imagen original rode\u00e1ndola con ceros para no perder dicha informaci\u00f3n en los bordes de la imagen original. Esta acci\u00f3n se llama \"padding\".</p>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#capas-convolucionales","title":"Capas convolucionales","text":"<p>Dentro de las redes convolucionales no todos las neuronas de una capa est\u00e1n conectadas con todas las neuronas de la siguinete capa. Con esto conseguimos un proceso similar al filtrado de una imagen.</p> <pre><code>flowchart LR\nsubgraph layer 1 - Input layer\nl1p1((L1P1))\nl1p2((L1P2))\nl1p3((L1P3))\nl1p4((L1P4))\nend\n\nsubgraph layer 2\nl2p1((L2P1))\nl2p2((L2P2))\nend\n\nsubgraph layer n\nlnpn((LnPn))\nend\n\nl1p1 --&gt; l2p1\nl1p2 --&gt; l2p1\n\nl1p3 --&gt; l2p2\nl1p4 --&gt; l2p2\n\n\nl2p1 -.-&gt; lnpn\nl2p2 -.-&gt; lnpn</code></pre>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#capas-de-agrupamiento-pooling-layers","title":"Capas de agrupamiento (Pooling layers)","text":"<p>Estas capas aceptan capas convolucionales como entrada, en esta capa podemos aplicar l\u00f3gical para simplificar el tama\u00f1o de la red (reducir n\u00famero de par\u00e1metros), por ejemplo agrupando en ventanas 2x2 y cogiendo el valor m\u00e1ximo o la media.</p> <pre><code>flowchart LR\ninput[Input]\nconv[Conv]\npool[Pool]\n\ninput --&gt; conv --&gt; pool</code></pre> <p>Otra t\u00e9nica muy utilizada dentro de CNN es usar \"Dropout\" layers, que como se explic\u00f3 anteriormente son capas en las que desactivamos un porcentaje del n\u00famero total de neuronas de forma aleatoria.</p>"},{"location":"Machine%20Learning/Deep%20Learning/03-CNN/#arquitectura-final-de-una-red-convolucional","title":"Arquitectura final de una red convolucional","text":"<p>Hay muchas combinaciones posibles para crear una red convolucional, y la \u00fanica forma de encotrar la m\u00e1s correcta es probando varias conbinaciones y usar los resultados obtenidos en un intento para mejorar el siguiente intento.</p> <p>Lo que si tienen en com\u00fan todas las redes convolucionales es que todas tienen como pen\u00faltima capa una capa especial llamada \"Fully connected layer (FC)\" que implemente una funci\u00f3n para poder conectar la salida de la capa anterior a la capa de salida (\u00faltima capa), esta capa de salida tendr\u00e1 el mismo n\u00famero de neuronas como n\u00famero de clases.</p> <pre><code>flowchart LR\ninput[Input]\nconv[Conv]\npool[Pool]\nfc[FC]\nout[Out]\n\ninput --&gt; conv --&gt; pool --&gt; fc --&gt; out</code></pre>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/","title":"Redes neuronales recurrentes - Recurrent Neural Networks (RNNs)","text":"<p>Las redes neuronales recurrentes es un tipo de red muy \u00fatil para trabajar con secuencias de datos.</p> <p>Antes de seguir con este punto es importante tener algunos conocimientos de redes neuronales con keras (librer\u00eda de python), puedes ver Keras para tener m\u00e1s informaci\u00f3n.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#teoria-basica","title":"Teor\u00eda b\u00e1sica","text":"<p>La idea de las redes neuronales recurrentes es intentar predecir el siguiente valor de una secuencia de datos, por ejemplo, si tenemos una secuencia de datos de precios de acciones, podemos usar una red neuronal recurrente para predecir el precio de la acci\u00f3n en el siguiente momento.</p> <p>La diferencia principal con este tipo de redes neuranales es que se usa la salida de una iteraci\u00f3n como realimentaci\u00f3n de la entrada para la siguiente iteraci\u00f3n.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#ejemplos-de-secuencias","title":"Ejemplos de secuencias","text":""},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#de-secuencia-a-secuencia-many-to-many","title":"De secuencia a secuencia (many to many)","text":"<p>En este caso, la entrada y la salida son secuencias de datos.</p> <p>Ejemplo: * Dada una secuencia de 5 palabras de entrada, la red neuronal predice las siguientes 5 palabras.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#de-secuencia-a-un-valor-many-to-vector","title":"De secuencia a un valor (many to vector)","text":"<p>En este caso, la entrada es una secuencia de datos y la salida es un valor.</p> <p>Ejemplo: * Dada una secuencia de 5 palabras de entrada, la red neuronal predice la siguiente palabra.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#de-un-valor-a-secuencia-vector-to-many","title":"De un valor a secuencia (vector to many)","text":"<p>En este caso, la entrada es un valor y la salida es una secuencia de datos.</p> <p>Ejemplo: * Dada una salabra de entrada, la red neuronal predice las siguientes 5 palabras.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#limitaciones","title":"Limitaciones","text":"<ul> <li> <p>La mayor limitaci\u00f3n de este tipo de redes neuronales es que s\u00f3lo puede \"recordar\" los valores de la iteraci\u00f3n anterior. Por lo tanto, conforme avanza la secuencia, la red neuronal pierde la informaci\u00f3n de los valores iniciales. Esto se resuelve con la red neuronal Long Short Term Memory (LSTM) o Gated Recurrent Unit (GRU).</p> </li> <li> <p>Otra gran desventaja de este tipo de redes durante el entrenamiento es el  \"desvanecimiento del gradiente\" (vanishing gradient).</p> </li> </ul>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#desvanecimiento-del-gradiente","title":"Desvanecimiento del gradiente","text":"<p>El problema del \"desvanecimiento del gradiente\" (vanishing gradient) ocurre porque, durante el entrenamiento de redes neuronales profundas o recurrentes, los valores de los gradientes (que indican cu\u00e1nto deben ajustarse los pesos) se hacen cada vez m\u00e1s peque\u00f1os a medida que retroceden por las capas de la red. Esto sucede especialmente cuando se usan ciertas funciones de activaci\u00f3n (como la sigmoide o tanh) y muchas capas o pasos temporales.</p> <p>Cuando el gradiente se vuelve muy peque\u00f1o, la red \"deja de aprender\" en las capas m\u00e1s profundas o en los pasos iniciales de la secuencia, porque los ajustes en los pesos son casi nulos. Por eso, la red tiene dificultades para recordar informaci\u00f3n de largo plazo.</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#long-short-term-memory-lstm","title":"Long Short Term Memory (LSTM)","text":"<p>El Long Short Term Memory (LSTM) es una red neuronal recurrente que puede \"recordar\" informaci\u00f3n de largo plazo.</p> <p>La LSTM consta de 4 bloques principales:</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-1-forget-gate","title":"Bloque 1: forget gate","text":"<p>El forget gate decide qu\u00e9 informaci\u00f3n se debe eliminar de la celda interna.</p> \\[f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-2-input-gate","title":"Bloque 2: input gate","text":"<p>El input gate decide qu\u00e9 informaci\u00f3n se debe agregar a la celda interna.</p> \\[i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-3-cell-state","title":"Bloque 3: cell state","text":"<p>El cell state es la celda interna de la LSTM.</p> \\[C_t = f_t * C_{t-1} + i_t * tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-4-output-gate","title":"Bloque 4: output gate","text":"<p>El output gate decide qu\u00e9 informaci\u00f3n se debe mostrar.</p> \\[o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#gated-recurrent-unit-gru","title":"Gated Recurrent Unit (GRU)","text":"<p>El Gated Recurrent Unit (GRU) es una red neuronal recurrente que puede \"recordar\" informaci\u00f3n de largo plazo.</p> <p>La GRU consta de 3 bloques principales:</p>"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-1-reset-gate","title":"Bloque 1: reset gate","text":"<p>El reset gate decide qu\u00e9 informaci\u00f3n se debe olvidar de la celda interna.</p> \\[r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t] + b_r)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-2-update-gate","title":"Bloque 2: update gate","text":"<p>El update gate decide qu\u00e9 informaci\u00f3n se debe agregar a la celda interna.</p> \\[z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t] + b_z)\\]"},{"location":"Machine%20Learning/Deep%20Learning/04-RNN/#bloque-3-hidden-state","title":"Bloque 3: hidden state","text":"<p>El hidden state es la celda interna de la GRU.</p> \\[h_t = (1 - z_t) * h_{t-1} + z_t * tanh(W_h \\cdot [r_t * h_{t-1}, x_t] + b_h)\\]"},{"location":"Machine%20Learning/Deep%20Learning/05-NLP/","title":"Procesamiento de lenguaje natural - Natural Language Processing (NLP)","text":"<p>Las redes para procesamiento de lenguaje natural son un tipo de red que se encarga de procesar y entender el lenguaje natural.</p> <p>Antes de seguir con este punto es importante tener algunos conocimientos de redes neuronales con keras (librer\u00eda de python), puedes ver Keras para tener m\u00e1s informaci\u00f3n.</p> <p>Este tipo de redes neuronales, despu\u00e9s de ser entrenadas, pueden predecir qu\u00e9 palabra o car\u00e1cter es m\u00e1s probable que venga despu\u00e9s de una secuencia de valores de entrada.</p>"},{"location":"Machine%20Learning/Deep%20Learning/06-Autoencoders/","title":"Autoencoders","text":"<p>Los autoencoders son una arquitectura de red neuronal dise\u00f1ada para aprender una representaci\u00f3n comprimida (codificaci\u00f3n) de los datos de entrada, generalmente con el objetivo de reducci\u00f3n de dimensionalidad o eliminaci\u00f3n de ruido. Est\u00e1n formados por dos partes principales: el codificador (encoder), que transforma los datos originales en una representaci\u00f3n de menor dimensi\u00f3n, y el decodificador (decoder), que intenta reconstruir los datos originales a partir de dicha representaci\u00f3n comprimida.</p> <p>Cuando usamos autoencoders nos referimos a redes semi supervisadas, ya que es el autoencoder el responsable de predecir la categor\u00eda de la salida.</p>"},{"location":"Machine%20Learning/Deep%20Learning/06-Autoencoders/#conceptos-basicos","title":"Conceptos b\u00e1sicos","text":"<p>Los autoencoders es un tipo de red neuronal simple muy similar al modelo perceptron multicapa (MLP), pero con la diferencia de que tiene una capa de salida que es la misma que la capa de entrada (mismo n\u00famero de neuronas).</p> <p></p>"},{"location":"Machine%20Learning/Deep%20Learning/06-Autoencoders/#beneficios-de-usar-autoencoders","title":"Beneficios de usar autoencoders","text":"<ul> <li>Reducci\u00f3n de dimensionalidad: Permiten transformar datos complejos y de alta dimensi\u00f3n en representaciones m\u00e1s compactas, facilitando el an\u00e1lisis y la visualizaci\u00f3n.</li> <li>Eliminaci\u00f3n de ruido: Son capaces de aprender las caracter\u00edsticas esenciales de los datos, descartando informaci\u00f3n irrelevante o ruido, lo que mejora la calidad de los datos procesados.</li> <li>Pre-entrenamiento para otras tareas: Las representaciones aprendidas pueden ser utilizadas como caracter\u00edsticas de entrada para otros modelos, mejorando su rendimiento, especialmente cuando los datos etiquetados son escasos.</li> <li>Compresi\u00f3n de datos: Ayudan a almacenar informaci\u00f3n de manera eficiente, \u00fatil en contextos donde el espacio de almacenamiento es limitado.</li> <li>Detecci\u00f3n de anomal\u00edas: Al aprender la estructura normal de los datos, los autoencoders pueden identificar patrones at\u00edpicos o an\u00f3malos cuando la reconstrucci\u00f3n falla.</li> <li>Visualizaci\u00f3n de datos: Permiten visualizar datos complejos en un espacio de menor dimensi\u00f3n, lo que facilita su an\u00e1lisis y comprensi\u00f3n.</li> </ul> <p>En resumen, los autoencoders son herramientas vers\u00e1tiles en machine learning, ya que permiten extraer informaci\u00f3n relevante, mejorar la calidad de los datos y optimizar recursos en distintas aplicaciones.</p>"},{"location":"Python/Keras/01%20-%20intro/","title":"Keras","text":"<p>Keras es una biblioteca de Python utilizada como API para crear redes neuronales de TensorFlow f\u00e1cilmente.</p> <p>Keras ya viene instalado dentro de Tensorflow por lo que no hay que instalarla manualmente.</p>"},{"location":"Python/Keras/01%20-%20intro/#preparar-los-datos","title":"Preparar los datos","text":"<pre><code>import pandas as pd\nimport numpy and np\n\nimport seaborn as sns # Para visualizar datos\n\n# Leer tabla de un archivo csv\ndf = pd.read_csv('.../x.csv')\n\n# Tabla con una lista de precios dependiendo de dos caracter\u00edsticas.\ndf.head # Muestra una parte de la tabla\n\n# Mostrar gr\u00e1ficos con los datos de cada columna de la tabla\nsns.pairplot(df)\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#otras-acciones-de-preprocesamiento-de-datos","title":"Otras acciones de preprocesamiento de datos","text":""},{"location":"Python/Keras/01%20-%20intro/#elimnar-columnas","title":"Elimnar columnas","text":"<p>Eliminar columnas que no nos sean de utilidad.</p> <pre><code># Hay columnas como el id que generalmente no nos sirve.\ndf = df.drop('id', axis=1)\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#crear-nuevas-columnas","title":"Crear nuevas columnas","text":"<p>Si tenemos una columna con fechas (\"date\") podemos usar dicha columna para crear otras columnas m\u00e1s \u00fatiles, como a\u00f1o y mes.</p> <pre><code># Para las fechas es importante pasarlo a un formato entendible por la red.\ndf['date'] = pd.to_datetime(df['date'])\n\n# Funci\u00f3n lambda para crear nuevas columnas.\ndf['year'] = df['date'].apply(lambda date: date.year)\ndf['month'] = df['date'].apply(lambda date: date.month)\n\n# Otra forma para crear nuevas columnas.\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#correlacion","title":"Correlaci\u00f3n","text":"<p>Podemos correlacionar las columnas entre s\u00ed y ver como impacta un cambio en una columna con el resto de columnas. Ejemplo de correlaci\u00f3n entre precio de una casa respecto caracter\u00edsticas de la casa.</p> <pre><code># Ejemplo: Precio tiene una alta correlaci\u00f3n con los metros cuadrados\ndf.corr()['price'].sort_values()\n'''\nzipcode         -0.053402\nlong             0.022036\ncondition        0.036056\nyr_built         0.053953\nsqft_lot15       0.082845\nsqft_lot         0.089876\nyr_renovated     0.126424\nfloors           0.256804\nwaterfront       0.266398\nlat              0.306692\nbedrooms         0.308787\nsqft_basement    0.323799\nview             0.397370\nbathrooms        0.525906\nsqft_living15    0.585241\nsqft_above       0.605368\ngrade            0.667951\nsqft_living      0.701917  &lt;&lt;&lt;&lt; Alta correlaci\u00f3n\nprice            1.000000  &lt;&lt;&lt;&lt; Referencia\nName: price, dtype: float64\n'''\n\n# Mostrar correlaci\u00f3n en un mapa de calor\nplt.figure(figsize=(12,7))\nsns.heatmap(df.corr(),annot=True,cmap='viridis')\nplt.ylim(10, 0)\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#visualizar-datos","title":"Visualizar datos","text":"<p>Mostrar datos antes del entrenamiento por tener un entendimiento m\u00e1s visual.</p> <pre><code># Mostrar ambos datos con alta correlaci\u00f3n para ver que es bastabte lineal\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='price',y='sqft_living',data=df)\n\n# Mostrar distribuci\u00f3n de precios por habitaciones\nsns.boxplot(x='bedrooms',y='price',data=df)\n\n# Gr\u00e1fica de precios por ubicaci\u00f3n\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='long',y='lat',data=df,hue='price')\n# Nota: Hay herramientas externas que te muestran estos valores sobre un mapa real.\n\n# Hay veces en las que merece la pena quitar valores extremos, para tener un resultado m\u00e1s real\nlen(df)*(0.01) # Salida: 215.97 &gt;&gt; Equivale al 1% de los valores de la tabla\n# Ordenamos y quitamos el 1% de las casas m\u00e1s caras\nnon_top_1_perc = df.sort_values('price',ascending=False).iloc[216:]\n# Mostrar datos\nplt.figure(figsize=(12,8))\nsns.scatterplot(x='long',y='lat',\n                data=non_top_1_perc,hue='price',\n                palette='RdYlGn',edgecolor=None,alpha=0.2)\n\n# Gr\u00e1fica de precio por habitaciones\nplt.figure(figsize=(12,4))\nsubgrade_order = sorted(df['bedrooms'].unique())\nsns.countplot(x='price',data=df,order = subgrade_order,palette='coolwarm' )\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#agrupar-valores","title":"Agrupar valores","text":"<pre><code># Se pueden agrupar valores\ndf.groupby('month').mean()['price'].plot()\n\n# Describir caracter\u00edsticas principales\ndf.groupby('month')['price'].describe()\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#ver-valores-unicos","title":"Ver valores \u00fanicos","text":"<pre><code>df['zipcode'].unique()\n\n# si los queremos ordenados\nsorted(df['zipcode'].unique())\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#contar-valores-que-se-repiten","title":"Contar valores que se repiten","text":"<pre><code># Ver valores que se repiten\ndf['zipcode'].value_counts()\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#extraer-datos-de-entrenameinto-y-testeo","title":"Extraer datos de entrenameinto y testeo","text":"<p>Es importante sacar una cantidad de valores de la tabla para entrenar y testear la red neuronal.</p> <pre><code>from sklearn.model_selection import train_test_split\n\n# Extraemos los datos de entrada\nX = df[['feature1', 'feature2']].values\n# \".value\" porque por como funciona Tensorflow, el tipo tiene que ser numpy array\n# \"X\" en mayus porque es un vector de varias dimensiones (n-dimensiones).\n\n# Predicciones\ny = df['price'].values\n# \".value\" porque por como funciona Tensorflow, el tipo tiene que ser numpy array\n# \"y\" minus porque es un vector de una dimensi\u00f3n\n\n\n# Separar datos entre entrenameinto y testeo\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n# test_size: Porcentaje de valores que van a ser para testeo\n# random_state: Semilla que se usa para generar un valor random para coger los valores. Si se quiere coger los mismos grupos de datos en el futuro hay que mantener este n\u00famero.\n\n# Comprobar tama\u00f1o de los grupos\nX_train.shape # (700, 2) --&gt; 70% del total\nX_test.shape # (300, 2) --&gt; 30% del total\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#categorizar-datos","title":"Categorizar datos","text":"<p>En el \u00e1mbito de las redes neuronales, a veces es conveniente categorizar la salida en lugar de tenerla como un valor esperado (por ejemplo, [0, 1, 2, 3, 4, 5, ...]). Es preferible representar la salida en categor\u00edas, lo que facilita ajustar el n\u00famero de neuronas en la capa de salida. Por ejemplo, el n\u00famero 1 se representar\u00eda como [0, 1, 0, 0, ...], el n\u00famero 2 se representar\u00eda como [0, 0, 2, 0, ...], etc.</p> <pre><code>from tensorflow.keras.utils import to_categorical\n\n# ...\n# num_classes indica el n\u00famero de categor\u00edas que queremos distinguir\ny_cat_test = to_categorical(y_test,num_classes=10)\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#escalar-valores","title":"Escalar valores","text":"<p>Es importante normalizar y esclar los datos para que la red neuronal puede trabajar sin problemas.</p> <pre><code>from sklearn.preprocessing import MinMaxScaler\n\n# Normalizamos los datos\nscaler = MinMaxScaler() # Este scaler va a normalizar los datos entre 0 y 1.\n\n# Calculamos cuales son los par\u00e1metros necesarios para normalizar los datos de entrenamiento.\n# Esto se hace s\u00f3lo en el conjunto de entrenamiento para no falsear el grupo de testeo.\nscaler.fit(X_train) \nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#crear-y-entrenar-modelo","title":"Crear y entrenar modelo","text":"<p>Crear el modelo usando keras que se encuentra dentro de la librer\u00eda de tensorflow.</p> <pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Creamos el modelo pas\u00e1ndole una lista de las capas que queremos tener.\n# Dense layer es una capa que cada neurona conecta con cada neurona de la siguiente capa.\n# units: n\u00famero de neuronas por capa (4 en este ejemplo)\n# activation function: relu\nmodel = Sequential([Dense(units=4, activation='relu')])\n# si queremos crear un modelo con dos capas, simplemente a\u00f1adimos dos capas Dense a la lista.\nmodel = Sequential([Dense(units=4, activation='relu'),\n                    Dense(units=2, activation='relu'),\n                    Dense(units=1)]) # \u00daltima capa no necesita funci\u00f3n de activaci\u00f3n\n\n# Otra forma de crear un modelo\nmodel = Sequential()\nmodel.add(Dense(units=4, activation='relu'))\nmodel.add(Dense(units=4, activation='relu'))\nmodel.add(Dense(units=4, activation='relu'))\nmodel.add(Dense(units=4, activation='relu'))\nmodel.add(Dense(units=1)) # S\u00f3lo un nodo en la capa final porque s\u00f3lo queremos un output\n\n# Compilar el modelo\nmodel.compile(\n        optimizer='rmsprop', # modelo para calcular el gradiente descendiente\n        loss='mse', # depende de qu\u00e9 queramos conseguir: multi-class clasification, binary classification or regression problem // See docstring from compiler function.      \n)\n\n# Entrenar modelo\nmodel.fit(\n    x=X_train, # Datos de entrada\n    y=y_train, # Salida esperada\n    epochs=250 # Cuantas veces se va a usar cada dato de entrada para entrenar el modelo\n)\n\n# Mostrar como el error ha ido disminuyendo\nloss_df = pd.DataFrame(model.history.history)\nloss_df.plot()\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#modificaciones-en-el-entrenamiento","title":"Modificaciones en el entrenamiento","text":"<p>Hay veces donde tras entrenar un modelo vamos a ver que estamos haciendo algo mal, ya que el error con las muestras de testeo no siempre disminiyen.</p> <p></p> <p>Como se puede ver en la gr\u00e1fica, el error var\u00eda mucho entre el error del entrenamiento y el error de validaci\u00f3n, este es un claro ejemplo de \"overfitting\", donde el modelo se ajusta mucho a las muestras de entrenamiento pero no a las de testeo.</p> <p>Para solucionar esto es importante usar callback para detener el entrenamiento cuando se est\u00e9 sufriendo de \"overfitting\".</p> <p>Tenemos varias formas de reducir este problema.</p>"},{"location":"Python/Keras/01%20-%20intro/#detener-entrenamiento","title":"Detener entrenamiento","text":"<pre><code>from tensorflow.keras.callbacks import EarlyStopping\n\n# Creamos el modelo\nmodel = Sequential()\nmodel.add(Dense(units=30,activation='relu'))\nmodel.add(Dense(units=15,activation='relu'))\nmodel.add(Dense(units=1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\n\n# Definimos callback para detener el entrenamiento\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n# patience se usa para esperar 25 epochs desde que se encuentra un punto min para evitar muestras con ruido.\n\n# Creamos modelo con el callback early stop\nmodel.fit(x=X_train, \n          y=y_train, \n          epochs=600,\n          validation_data=(X_test, y_test), verbose=1,\n          callbacks=[early_stop]\n          )\n\nmodel_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#eliminar-capas","title":"Eliminar capas","text":"<pre><code>from tensorflow.keras.layers import Dropout\n\n# Creamos el modelo\nmodel = Sequential()\nmodel.add(Dense(units=30,activation='relu'))\nmodel.add(Dropout(0.5)) # De forma aleatoria quitamos o dejamos el 50% de las neuronas de esta capa\nmodel.add(Dense(units=15,activation='relu'))\nmodel.add(Dropout(0.5))# De forma aleatoria quitamos o dejamos el 50% de las neuronas de esta capa\nmodel.add(Dense(units=1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\n\n# Definimos callback para detener el entrenamiento\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n# patience se usa para esperar 25 epochs desde que se encuentra un punto min para evitar muestras con ruido.\n\n# Creamos modelo con el callback early stop\nmodel.fit(x=X_train, \n          y=y_train, \n          epochs=600,\n          validation_data=(X_test, y_test), verbose=1,\n          callbacks=[early_stop]\n          )\n\nmodel_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#evaluar-el-modelo","title":"Evaluar el modelo","text":"<p>El siguiente paso es testear el modelo con pruebas que nunca ha visto antes, es decir, las muestras de testeo.</p> <pre><code># Evaluar modelo entrenado\nmodel.evaluate(X_test, y_test, verbose=0)\n# Salida: 24.9722... Significa la p\u00e9rdida, el error cuadr\u00e1tico medio (mse).\n\n# Precedir salidas\ntest_predictions = model.predict(X_test)\n\n# Preparar datos para crear gr\u00e1fica entre valores reales y predicciones\ntest_predictions = pd.Series(test_predictions.reshape(300,))\npred_df = pd.DataFrame(y_test, columns['Test True Y'])\npred_df = pd.concat([pred_df, test_predictions], axis=1)\npred_df.columns = ['Test True Y', 'Model Predictions']\n\nsns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)\n</code></pre> <p>Podemos calcular r\u00e1pidamente otros tipos de errores:</p> <pre><code>from sklearn.metrics import mean_absolute_error, mean_squared_error\n\nmean_absolute_error(pred_df['Test True Y'], pred_df['Model Predictions'])\n# Salida: aprox 4\n\ndf.describe()\n# mean is aprox 500, so having an error of 4 means we model is working fine\n\nmean_squared_error(pred_df['Test True Y'], pred_df['Model Predictions'])\n# Salida: aprox 24.97...\n</code></pre> <p>Si quisiesemos probar con datos de entrada totalmente nuevos:</p> <pre><code># Nuevos datos de entrada\nnew_gem = [[998, 1000]]\n# Es importante recordar que tenemos que escalar los datos de entrada\nnew_gem = scaler.transform(new_gem)\n# Predecir usando el modelo\nmodel.predict(new_gem)\n# Salida: aprox 419\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#evaluar-modelos-binarios","title":"Evaluar modelos binarios","text":"<pre><code>from sklearn.metrics import classification_report,confusion_matrix\n\npredictions = model.predict_classes(X_test)\n\n# https://en.wikipedia.org/wiki/Precision_and_recall\nprint(classification_report(y_test,predictions))\n'''\n              precision    recall  f1-score   support\n\n           0       0.96      0.98      0.97        55\n           1       0.99      0.98      0.98        88\n\n    accuracy                           0.98       143\n   macro avg       0.98      0.98      0.98       143\nweighted avg       0.98      0.98      0.98       143\n'''\n\nprint(confusion_matrix(y_test,predictions))\n'''\n[[54  1]\n [ 2 86]]\n'''\n</code></pre>"},{"location":"Python/Keras/01%20-%20intro/#guardar-y-cargar-modelos","title":"Guardar y cargar modelos","text":"<p>Si entrenamos un modelo muy grande que requiere mucho tiempo de entrenamiento es importante guardar el modelo para no tener que entrenarlo cada vez que queramos usarlo.</p> <pre><code>from tensorflow.keras.models import load_model\n\n# Guardar modelo en archivo 'my_gem_model.h5' \nmodel.save('my_gem_model.h5')\n\n# Cargar modelo\nlater_model = load_model('my_gem_model.h5')\nlater_model.predict(new_gem)\n</code></pre>"},{"location":"Python/Keras/02%20-%20tensorboard/","title":"TensorBoard","text":"<p>TensorBoard es una herramienta esencial para el flujo de trabajo de aprendizaje autom\u00e1tico, que ofrece mediciones y visualizaciones completas. Permite a los usuarios rastrear m\u00e9tricas de experimentos como la p\u00e9rdida y la precisi\u00f3n, visualizar el gr\u00e1fico del modelo, proyectar incrustaciones en espacios de menor dimensi\u00f3n y mucho m\u00e1s.</p> <p>Tutorial oficial: https://www.tensorflow.org/tensorboard/get_started</p> <pre><code>import pandas as pd\nimport numpy as np\n\n## Cargar datos de ejemplo\ndf = pd.read_csv('../DATA/cancer_classification.csv')\n\n## Dividir en datos de entrenamiento y testeo\nfrom sklearn.model_selection import train_test_split\n\nX = df.drop('benign_0__mal_1',axis=1).values\ny = df['benign_0__mal_1'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)\n\n## Escalar datos\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\n## Crear modelo\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Dropout\n\n# Esta vez importamos TensorBoard\nfrom tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n\nearly_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n\n# Preparamos TensorBoard\nlog_directory = 'logs/fit'\n\n# Opcional: ordenar carpetas por fecha\n# timestamp = datetime.now().strftime(\"%Y-%m-%d--%H%M\")\n# log_directory = log_directory + '/' + timestamp\n\nboard = TensorBoard(log_dir=log_directory,histogram_freq=1,\n    write_graph=True,\n    write_images=True,\n    update_freq='epoch',\n    profile_batch=2,\n    embeddings_freq=1)\n\n# Generamos modelo\nmodel = Sequential()\nmodel.add(Dense(units=30,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=15,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(units=1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam')\n\n## Entrenar modelo\nmodel.fit(x=X_train, \n          y=y_train, \n          epochs=600,\n          validation_data=(X_test, y_test), verbose=1,\n          callbacks=[early_stop,board]\n          )\n</code></pre> <p>Una vez completado el entrenamiento podremos lanzar la aplicaci\u00f3n de TensorBoard desde una terminal con el siguiente comando, lo que habilitar\u00e1 toda la informaci\u00f3n en <code>http://localhost:6006</code>.</p> <pre><code>tensorboard --logdir logs/fit   \n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/","title":"CNN en Keras","text":"<p>Como ya explicamos en la teor\u00eda de redes neuronales convolucionales (CNNs), estas redes neuronales son muy \u00fatil cuando necesitamos trabajar con im\u00e1genes.</p> <p>Teor\u00eda CNNs</p>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#cnn-con-imagenes-en-blanco-y-negro","title":"CNN con im\u00e1genes en blanco y negro","text":"<p>Para este caso vamos a usar el dataset de MNIST, que contiene im\u00e1genes 28x28 en blanco y negro (1 canal de color) de n\u00fameros escritos a mano.</p>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#cargar-datos","title":"Cargar datos","text":"<pre><code>import pandas as pd\nimport numpy as np\n\n## Cargar datos de ejemplo\n## MNIST es un dataset muy popular para entrenar con im\u00e1genes\nfrom tensorflow.keras.datasets import mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#comprobar-dataset-y-visualizar-imagen","title":"Comprobar dataset y visualizar imagen","text":"<pre><code>import matplotlib.pyplot as plt\n\nx_train.shape # (60000, 28, 28) -&gt; 60000 im\u00e1genes de 28x28 p\u00edxeles\n\nsingle_image = x_train[0]\nplt.imshow(single_image)\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#preprocesamiento-de-datos","title":"Preprocesamiento de datos","text":"<pre><code>### En este caso queremos categorizar 10 valores (n\u00fameros del 0 al 9).\nfrom tensorflow.keras.utils import to_categorical\n\ny_cat_test = to_categorical(y_test,10)\ny_cat_train = to_categorical(y_train,10)\n\n\n### Hay que verificar que los valores est\u00e9n normalizados entre 0 y 1,\n### normalmente nos viene en valores entre 0 y 255\nsingle_image.max() # 255\nsingle_image.min() # 0\n\nx_train = x_train/255\nx_test = x_test/255\n\nscaled_single = x_train[0]\nscaled_single.max() # 1\n\n\n### Reformatear canales\n### En este ejemplo nos falta el canal del color en el formato\n### (n\u00ba im\u00e1genes, ancho, alto, canales)\nx_train.shape # (60000, 28, 28)\n\nx_train = x_train.reshape(60000, 28, 28, 1)\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#preparar-modelo","title":"Preparar modelo","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n\nmodel = Sequential()\n\n# La primera capa siempre suele ser una capa convolucional\n# CONVOLUTIONAL LAYER\n### filters: A mayor n\u00famero de clasificaciones, mayor debe ser el n\u00famero de\n###     filtros, suele ser un exponente de 2.\n### kernel_size: Tama\u00f1o de matriz donde vamos a aplicar el kernel/filtro.\n###     Suele ser m\u00faltiplos de 2, empezar por (2,2) o (4,4) e ir subiendo.\n### strides: Cu\u00e1nto se mueve el kernel tras cada iteraci\u00f3n. En este ejemplo\n###     se usa valor por defecto (1,1). Para im\u00e1genes grandes es mejor aumentarlo.\n### padding: Valor para decidir si queremos a\u00f1adir padding o no. \n###     \"valid\" or \"same\" (default is \"valid\" == no padding).\n### input_shape: Tama\u00f1o imagen.\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(28, 28, 1), activation='relu',))\n\n# POOLING LAYER\n## Normalmente el par\u00e1metro pool_size sigue la misma regla que kernel_size de la capa\n##      convolucional.\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# FLATTEN IMAGES\n# Aplanar im\u00e1genes de 28x28 a 764 antes de la capa final\nmodel.add(Flatten())\n\n# Dense layer para disminuir el n\u00famero de neuronas, debe usarse un exponente de 2.\nmodel.add(Dense(128, activation='relu'))\n\n# La \u00faltima capa es la que se usa para clasificar, debe haber una neurona por clase.\n# En etse caso tenemos 10 clases posibles.\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']) # M\u00e1s m\u00e9tricas explicadas en https://keras.io/metrics/\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#entrenar-modelo","title":"Entrenar modelo","text":"<pre><code>from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)\n\nmodel.fit(x_train,y_cat_train,epochs=10,validation_data=(x_test,y_cat_test),callbacks=[early_stop])\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#evaluar-modelo","title":"Evaluar modelo","text":"<pre><code># Mostrar m\u00e9tricas del entrenamiento\nmodel.metrics_names # ['loss', 'accuracy']\n\nlosses = pd.DataFrame(model.history.history)\nlosses[['accuracy','val_accuracy']].plot()\nlosses[['loss','val_loss']].plot()\n\nmodel.evaluate(x_test,y_cat_test,verbose=0) # [0.04325260493150563, 0.9867]\n\n# Reporte de la classificaci\u00f3n y matriz de confusi\u00f3n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\npredictions = model.predict_classes(x_test)\npredictions[0] #7\nprint(classification_report(y_test,predictions))\n'''\nprecision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       980\n           1       0.99      1.00      0.99      1135\n           2       0.99      0.98      0.98      1032\n           3       0.99      0.99      0.99      1010\n           4       0.97      1.00      0.98       982\n           5       0.99      0.99      0.99       892\n           6       1.00      0.98      0.99       958\n           7       0.97      1.00      0.98      1028\n           8       0.99      0.98      0.98       974\n           9       0.99      0.96      0.98      1009\n\n    accuracy                           0.99     10000\n   macro avg       0.99      0.99      0.99     10000\nweighted avg       0.99      0.99      0.99     10000\n'''\n\nconfusion_matrix(y_test,predictions)\n'''\narray([[ 975,    0,    1,    0,    0,    0,    3,    1,    0,    0],\n       [   0, 1134,    0,    0,    0,    0,    0,    1,    0,    0],\n       [   1,    4, 1007,    1,    4,    0,    0,   13,    2,    0],\n       [   0,    0,    5, 1000,    0,    2,    0,    2,    1,    0],\n       [   0,    0,    0,    0,  979,    0,    0,    0,    0,    3],\n       [   0,    0,    0,    6,    0,  883,    1,    0,    2,    0],\n       [   4,    3,    0,    1,    5,    1,  943,    0,    1,    0],\n       [   0,    1,    2,    0,    0,    0,    0, 1024,    1,    0],\n       [   2,    1,    4,    4,    4,    0,    0,    5,  952,    2],\n       [   0,    3,    0,    1,   16,    4,    0,   14,    1,  970]],\n      dtype=int64)\n'''\n# visualizar confusion matrix\nimport seaborn as sns\nplt.figure(figsize=(10,6))\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True)\n\n# Usar modelo con una nueva imagen\nmy_number = x_test[0]\nplt.imshow(my_number.reshape(28,28)) # Comprobar que es un siete\n\n## Recordar hacer reshape --&gt; (num_images,width,height,color_channels)\nmodel.predict_classes(my_number.reshape(1,28,28,1)) # array([7], dtype=int64)\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#cnn-con-imagenes-a-color","title":"CNN con im\u00e1genes a color","text":"<p>Para este caso vamos a usar el dataset de CIFAR-10, que contiene im\u00e1genes 32x32 a color (3 canales de colores - RGB) de 10 clases de objetos diferentes como aviones, gatos, perros, etc.</p> <p>La forma de trabajar con la red neuronal desde keras es 90% id\u00e9ntica al ejemplo anterior cuando trabaj\u00e1bamos con im\u00e1genes en blanco y negro (1 canal de color).</p> <pre><code>import pandas as pd\nimport numpy as np\n\n# Cargar datos\nfrom tensorflow.keras.datasets import cifar10\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nx_train.shape # (50000, 32, 32, 3) = 50000 im\u00e1genes de 32x32 con 3 canales de colores\nx_train[0].shape # (32, 32, 3)\n\n\n# Normalizar im\u00e1genes (dividir entre 255 cada pixel) es igual que antes\n# (...)\n\n\n# Crear categor\u00edas es igual que antes\n# Nota: En este caso la categor\u00eda es s\u00f3lo un n\u00famero, por lo que tendremos que ir a la web oficial para ver qu\u00e9 objeto significa cada n\u00famero\n# (...)\n\n\n# Preparar modelo\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n\nmodel = Sequential()\n\n# En este caso input_shape es diferente porque el tama\u00f1o de la imagen es otro.\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n\n# POOLING LAYER\n## Normalmente el par\u00e1metro pool_size sigue la misma regla que kernel_size de la capa\n##      convolucional.\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n# NOTA: como en este caso tenemos m\u00e1s valores que ajustar (32x32x3 = 3072) es recomendable\n# a\u00f1adir m\u00e1s capas convolucionales y pool layers. Al a\u00f1adir m\u00e1s capas es recomendable cambiar\n# el valor de filters, pero en este ejemplo vamos a dejar el mismo.\nmodel.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))\n\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\n\n# FLATTEN IMAGES\n# Aplanar im\u00e1genes de 28x28 a 764 antes de la capa final\nmodel.add(Flatten())\n\n# Dense layer para disminuir el n\u00famero de neuronas, debe usarse un exponente de 2.\nmodel.add(Dense(128, activation='relu'))\n\n# La \u00faltima capa es la que se usa para clasificar, debe haber una neurona por clase.\n# En etse caso tenemos 10 clases posibles.\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']) # M\u00e1s m\u00e9tricas explicadas en https://keras.io/metrics/\n\n# Evaluar modelo\nmetrics = model.evaluate(x_test, y_cat_test)\nmetrics.columns\n\nmetrics[['accuracy','val_accuracy']].plot()\nmetrics[['loss','val_loss']].plot()\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\npredictions = model.predict_classes(x_test)\npredictions[0] #7\nprint(classification_report(y_test,predictions))\n\nconfusion_matrix(y_test,predictions)\n\nimport seaborn as sns\nplt.figure(figsize=(10,6))\nsns.heatmap(confusion_matrix(y_test,predictions),annot=True)\n\n# Usar modelo con una nueva imagen\nmy_image = x_test[0]\nplt.imshow(my_image) \n## Recordar hacer reshape --&gt; (num_images,width,height,color_channels)\nmodel.predict_classes(my_image.reshape(1,32,32,3)) # array([3], dtype=int64)\n</code></pre>"},{"location":"Python/Keras/03%20-%20CNN_with_keras/#otras-funciones-para-cnn","title":"Otras funciones para CNN","text":""},{"location":"Python/Keras/03%20-%20CNN_with_keras/#generar-datos-de-imagenes","title":"Generar datos de im\u00e1genes","text":"<p>Existe la clase <code>ImageDataGenerator</code> que permite generar datos de im\u00e1genes de manera din\u00e1mica, lo que permite aumentar el tama\u00f1o del dataset y ahorrar memoria al no tener que cargar todas las im\u00e1genes en memoria.</p> <pre><code>from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_gen = ImageDataGenerator(\n    rotation_range=10, # gira las im\u00e1genes\n    width_shift_range=0.1, # desplaza las im\u00e1genes horizontalmente\n    height_shift_range=0.1, # desplaza las im\u00e1genes verticalmente\n    shear_range=0.1, # distorsiona las im\u00e1genes\n    zoom_range=0.1, # zoom en las im\u00e1genes\n    horizontal_flip=True, # invierte las im\u00e1genes\n    fill_mode='nearest' # rellena las im\u00e1genes\n)\nimage_gen.random_transform(x_train[0]) # Aplica de forma random las transformaciones sobre la imagen seleccionada.\n\nimage_gen.flow_from_directory(train_path) # Genera datos de im\u00e1genes de manera din\u00e1mica. Para que funcione correctamente, el dataset debe estar organizado en carpetas con el nombre de la categor\u00eda.\n# Ejemplo:\n# train_path\n#     \u251c\u2500\u2500 cat\n#     \u2502   \u251c\u2500\u2500 cat.0.jpg\n#     \u2502   \u251c\u2500\u2500 cat.1.jpg\n#     \u2502   \u251c\u2500\u2500 cat.2.jpg\n#     \u2502   \u251c\u2500\u2500 cat.3.jpg\n#     \u2502   \u251c\u2500\u2500 cat.4.jpg\n#     \u2502   \u251c\u2500\u2500 cat.5.jpg\n#     \u2502   \u251c\u2500\u2500 cat.6.jpg\n#     \u2502   \u251c\u2500\u2500 cat.7.jpg\n#     \u2502   \u251c\u2500\u2500 cat.8.jpg\n#     \u2502   \u2514\u2500\u2500 cat.9.jpg\n#     \u2514\u2500\u2500 dog\n#         \u251c\u2500\u2500 dog.0.jpg\n#         \u251c\u2500\u2500 dog.1.jpg\n#         \u251c\u2500\u2500 dog.2.jpg\n#         \u251c\u2500\u2500 dog.3.jpg\n#         \u251c\u2500\u2500 dog.4.jpg\n#         \u251c\u2500\u2500 dog.5.jpg\n#         \u251c\u2500\u2500 dog.6.jpg\n#         \u251c\u2500\u2500 dog.7.jpg\n#         \u251c\u2500\u2500 dog.8.jpg\n#         \u2514\u2500\u2500 dog.9.jpg\n\n# Usar ImageDataGenerator para generar datos de pruebas y test de manera din\u00e1mica.\ntrain_image_gen = image_gen.flow_from_directory(\n    train_path,\n    target_size=image_shape[:2], # Tama\u00f1o de la imagen (ancho, alto, canales)\n    batch_size=16,\n    class_mode='binary', # Clasificaci\u00f3n binaria (otra opcion es 'categorical')\n    color_mode='rgb'\n)\ntest_image_gen = image_gen.flow_from_directory(\n    test_path,\n    target_size=image_shape[:2],\n    batch_size=16,\n    class_mode='binary',\n    color_mode='rgb',\n    shuffle=False # No se debe mezclar el test set\n)\n\n# Comprobar categor\u00edas del train set\ntest_image_gen.class_indices # {'cat': 0, 'dog': 1}\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/","title":"RNN en Keras","text":"<p>Como ya explicamos en la teor\u00eda de redes neuronales relacionales (RNNs), estas redes neuronales son muy \u00fatil cuando necesitamos trabajar con secuencias de datos.</p> <p>Teor\u00eda RNNs</p>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#ejemplo-rnn-con-una-onda-sinusoidal","title":"Ejemplo RNN con una onda sinusoidal","text":""},{"location":"Python/Keras/04%20-%20RNN_with_keras/#generar-datos","title":"Generar datos","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Generar datos\nx = np.linspace(0, 50, 501) # 501 puntos entre 0 y 50\ny = np.sin(x)\n\n'''\n# Mostrar Gr\u00e1fica \nplt.plot(x, y)\nplt.show()\n'''\n\n# Crear dataframe\ndf = pd.DataFrame(data=y, index=x, columns=['sin'])\n\n\n# Separar datos de entrenamiento y test\ntest_percent = 0.1 # 10%\ntest_point = np.round(len(df) * test_percent) # 50 son los n\u00fameros de valores de test\ntest_ind = int(len(df) - test_point) # \u00edndice donde empieza el test (451)\n\ntrain = df.iloc[:test_ind]\ntest = df.iloc[test_ind:]\n\n# Escalar datos\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(train)\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#crear-lotes-batches-de-datos","title":"Crear lotes (batches) de datos","text":"<pre><code>from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\nlength = 50\nbatch_size = 1\n\n# TimeseriesGenerator(x, y, length, batch_size) -&gt; Genera lotes de datos de una secuencia\n# x: Datos de entrada (En este caso scaled_train es un array de 2 dimensiones  que contiene x e y)\n# y: Datos de salida (En este caso scaled_train es un array de 2 dimensiones  que contiene x e y)\n# length: N\u00famero de pasos en el futuro que queremos predecir. Debe ser suficientemente grande o peque\u00f1o para predecir patrones en la serie de datos.\n# batch_size: N\u00famero de lotes que queremos que se generen en cada iteraci\u00f3n\n\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=batch_size)\n\n'''\nSi tenemos una serie de datos que sea [1,2,3,4,5,6,7,8,9,10]\nel generator generar\u00e1 los siguientes lotes:\n\nEntrada: [(1,2), (2,3), (3,4), (4,5), (5,6), (6,7), (7,8), (8,9), (9,10)]\nSalida: [3,4,5,6,7,8,9,10]\n\nX,y = generator[0]\nX = [1,2]  # 2 elementos porque length = 2\ny = [3]    # 1 elemento porque batch_size = 1\n\nX,y = generator[1]\nX = [2,3]\ny = [4]\n\n(...)\n'''\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#crear-y-entrenar-el-modelo","title":"Crear y entrenar el modelo","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n\nn_features = 1 # x\n\nmodel = Sequential()\n#units: n\u00famero de neuronas, debe ser igual al n\u00famero de batches (length)\nmodel.add(SimpleRNN(units=50, input_shape=(length, n_features)))\nmodel.add(Dense(1))\n\n# model.summary()\n\n# Compilar modelo\nmodel.compile(loss='mse', optimizer='adam')\n\n# Entrenar modelo\nmodel.fit_generator(generator, epochs=5, verbose=0)\n\n# Ver error\nlosses=pd.DataFrame(model.history.history)\nlosses.plot()\n\n# Predecir\nfirst_eval_batch = scaled_train[-length:]\nfirst_eval_batch = first_eval_batch.reshape((1, length, n_features))\ny_pred = model.predict(first_eval_batch) # [0.948267] -&gt; valor predicho\n\nscaled_test[0] # [0.94955134] -&gt; valor real\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#visualizar-resultados","title":"Visualizar resultados","text":"<pre><code>test_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\ncurrent_batch.shape # (1, 50, 1)\n\nfor i in range(len(test)):\n\n    # obtener predicci\u00f3n 1 tiempo adelante ([0] es para obtener solo el n\u00famero en lugar de [array])\n    current_pred = model.predict(current_batch)[0]\n\n    # almacenar predicci\u00f3n\n    test_predictions.append(current_pred) \n\n    # actualizar lote para incluir predicci\u00f3n y eliminar el primer valor\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n\n# Como los valores est\u00e1n escalador, tenemos que invertir el escalado\ntrue_predictions = scaler.inverse_transform(test_predictions)\n\n# IGNORE WARNINGS\ntest['Predictions'] = true_predictions\n\ntest.plot(figsize=(12,8))\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#early-stopping","title":"Early Stopping","text":"<pre><code>from tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss',patience=2)\n\nlength = 49\nbatch_size = 1\n\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=batch_size)\nvalidation_generator = TimeseriesGenerator(scaled_test, scaled_test, length=length, batch_size=batch_size)\n\nmodel = Sequential()\n#units: n\u00famero de neuronas, debe ser igual al n\u00famero de batches (length)\nmodel.add(LSTM(units=50, input_shape=(length, n_features)))\nmodel.add(Dense(1))\n\n# Compilar modelo\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.fit_generator(generator, epochs=20, verbose=0, validation_data=validation_generator, callbacks=[early_stop])\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#ejemplo-rnn-con-series-de-tiempo","title":"Ejemplo RNN con series de tiempo","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n## Cargar datos\n# Ejemplo de datos de precio dependiendo del d\u00eda\ndf = pd.read_csv('RSCCASN.csv', parse_dates=True, index_col='DATE') \n\n# df.info()\n# df.head()\n\ndf.columns = ['Precio']\n\ndf.plot(figsize=(12,8))\nplt.show()  \n\n## Preparar datos\n# En este ejemplo los precios son por meses, la longitud total es 334 meses, vamos a coger los \u00faltimos 18 meses para el testeo\n\ntest_size = 18 # 18 meses\ntest_ind = int(len(df) - test_size)\n\ntrain = df.iloc[:test_ind]\ntest = df.iloc[test_ind:]\n\n## Escalar datos\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(train)\nscaled_train = scaler.transform(train)\nscaled_test = scaler.transform(test)\n\n## Crear lotes de datos\nfrom tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n\n# Como vamos a querer a\u00f1adir un early stop es importante que en el generador la longitud sea menor que la l\u00f3ngitud de los datos de testeo\n\nlength = 12 # 12 meses &lt; test_size(18 meses)\nbatch_size = 1\n\n# TimeseriesGenerator(x, y, length, batch_size) -&gt; Genera lotes de datos de una secuencia\n# x: Datos de entrada (En este caso scaled_train es un array de 2 dimensiones  que contiene x e y)\n# y: Datos de salida (En este caso scaled_train es un array de 2 dimensiones  que contiene x e y)\n# length: N\u00famero de pasos en el futuro que queremos predecir. Debe ser suficientemente grande o peque\u00f1o para predecir patrones en la serie de datos.\n# batch_size: N\u00famero de lotes que queremos que se generen en cada iteraci\u00f3n\ngenerator = TimeseriesGenerator(scaled_train, scaled_train, length=length, batch_size=batch_size)\n\n## Crear modelo\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM\n\nn_features = 1 # x\n\nmodel = Sequential()\n#units: n\u00famero de neuronas, debe ser igual al n\u00famero de batches (length)\nmodel.add(LSTM(units=100, activation='relu', input_shape=(length, n_features)))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adam')\n\nmodel.summary()\n\n# early stop\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=2)\n\nvalidation_generator = TimeseriesGenerator(scaled_test, scaled_test, length=length, batch_size=batch_size)\n\nmodel.fit_generator(generator, epochs=20, verbose=0, validation_data=validation_generator, callbacks=[early_stop])\n\nlosses=pd.DataFrame(model.history.history)\nlosses.plot()\n\n# Predecir valores de testeo\ntest_predictions = []\n\nfirst_eval_batch = scaled_train[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(len(test)):\n\n    # obtener predicci\u00f3n 1 tiempo adelante ([0] es para obtener solo el n\u00famero en lugar de [array])\n    current_pred = model.predict(current_batch)[0]\n\n    # almacenar predicci\u00f3n\n    test_predictions.append(current_pred) \n\n    # actualizar lote para incluir predicci\u00f3n y eliminar el primer valor\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n\n# Como los valores est\u00e1n escalador, tenemos que invertir el escalado\ntrue_predictions = scaler.inverse_transform(test_predictions)\n\n# IGNORE WARNINGS\ntest['Predictions'] = true_predictions\n\ntest.plot(figsize=(12,8))\n</code></pre>"},{"location":"Python/Keras/04%20-%20RNN_with_keras/#predecir-valores-futuros-valores-tras-pruebas-de-testeo","title":"Predecir valores futuros (valores tras pruebas de testeo)","text":"<pre><code>full_scaler = MinMaxScaler()\nscaled_full_data = full_scaler.fit_transform(df)\n\nlength = 12\n\nfull_generator = TimeseriesGenerator(scaled_full_data, scaled_full_data, length=length, batch_size=1)\n\nmodel = Sequential()\n#units: n\u00famero de neuronas, debe ser igual al n\u00famero de batches (length)\nmodel.add(LSTM(units=100, activation='relu', input_shape=(length, n_features)))\nmodel.add(Dense(1))\nmodel.compile(loss='mse', optimizer='adam')\n\n# no podemos usar un early stop porque no tenemos datos de validaci\u00f3n, estamos prediciendo valores futuros\n# epochs = 8 porque es un valor que en el caso anterior (cuando valid\u00e1bamos con los muestras de testeo) vimos que ten\u00eda poco error\nmodel.fit_generator(full_generator, epochs=8)\n\nforecast = []\nperiods = 12\n\nfirst_eval_batch = scaled_full_data[-length:]\ncurrent_batch = first_eval_batch.reshape((1, length, n_features))\n\nfor i in range(periods):\n\n    # obtener predicci\u00f3n 1 tiempo adelante ([0] es para obtener solo el n\u00famero en lugar de [array])\n    current_pred = model.predict(current_batch)[0]\n\n    # almacenar predicci\u00f3n\n    forecast.append(current_pred) \n\n    # actualizar lote para incluir predicci\u00f3n y eliminar el primer valor\n    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n\n# Como los valores est\u00e1n escalador, tenemos que invertir el escalado\nforecast = full_scaler.inverse_transform(forecast)\n\n# Calcular Date time de las predicciones\nforecast_index = pd.date_range(start='2019-11-01', periods=periods, freq='MS') # 'MS' es Monthly Start\n#forecast_index = pd.date_range(start=df.index[-1], periods=periods, freq='M') # Otra forma autom\u00e1tica\n\nforecast_df = pd.DataFrame(data=forecast, index=forecast_index, columns=['Forecast'])\n\n# Mostrar gr\u00e1fica de predicci\u00f3n\nforecast_df.plot(figsize=(12,8))\n\n# Mostrar gr\u00e1fica de predicci\u00f3n + datos reales\nax = df.plot()\nforecast_df.plot(ax=ax)\n\n# Zoom in en la gr\u00e1fica\nplt.xlim('2018-01-01', '2020-12-01')\nplt.show()  \n</code></pre>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/","title":"NLP en Keras","text":"<p>Como ya explicamos en la teor\u00eda de redes para procesamiento de lenguaje natural, estas redes neuronales son muy \u00fatil cuando necesitamos generar texto.</p> <p>Teor\u00eda NLPs</p>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/#ejemplo-de-nlp-con-keras","title":"Ejemplo de NLP con Keras","text":""},{"location":"Python/Keras/05%20-%20NLP_with_keras/#preparacion-de-datos","title":"Preparaci\u00f3n de datos","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\n#Vamos a usar texto de Shakespeare para entrenar el modelo ya que posee caracteristicas especiales en su forma de escribir.\n\npath_to_file = \"shakespeare.txt\"\n\ntext = open(path_to_file, 'r').read()\n\n# Calculamos los caracteres unicos en el texto.\nvocab = sorted(set(text))\nprint(f\"{len(vocab)} caracteres unicos en el texto.\") # 84 caracteres unicos en el texto.\n\n# Transformamos cada caracter a un \u00edndice/n\u00famero\nchar_to_ind = {char:ind for ind,char in enumerate(vocab)}\n# Ejemplo: char_to_ind['H'] = 33\n\n# Ahora realizamos la operacion inversa\nind_to_char = np.array(vocab)\n# Ejemplo: ind_to_char[33] = 'H'\n\n# Pasamos el texto original a un array de n\u00fameros\nencoded_text = np.array([char_to_ind[c] for c in text])\nprint(encoded_text.shape) # (5445609,)\n</code></pre>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/#crear-batches","title":"Crear batches","text":"<pre><code># La forma de escribir de Shakespeare es con frases cortas, y relacionando frases con frases parecido a poes\u00eda.\n# Por lo que vamos a crear batches que contengan al menos 3 frases completas.\n# Si una frase tiene 40 caracteres aproximadamente, entonces vamos a coger 120 caracteres para cada batch.\nseq_length = 120\n\n# calculamos el n\u00famero total de secuencias\ntotal_num_seq = len(text) // (seq_length+1)  # 45005\n\n# Creamos un dataset de caracteres\nchar_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\ntype(char_dataset) # &lt;class 'tensorflow.python.data.ops.dataset_ops.TensorSliceDataset'&gt;\n\n'''\n# Mostramos los primeros 500 caracteres del texto en forma de dataset (entradas de la red).\nfor item in char_dataset.take(500):\n    print(ind_to_char[item.numpy()])\n'''\n\n# Creamos batches de secuencias (entradas de la red - igual que en el ejemplo anterior pero lo hace el m\u00e9todo automaticamente).\nsequence_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n\ndef create_seq_target(seq):\n    input_txt = seq[:-1] # Hello worl\n    target_txt = seq[1:] # ello world\n    return input_txt, target_txt\n\n# Creamos el dataset de secuencias\ndataset = sequence_dataset.map(create_seq_target)\n\n# Ejemplo\nfor input_txt, target_txt in dataset.take(1):\n    print(f\"Input: {''.join(ind_to_char[input_txt.numpy()])}\")\n    print(f\"Target: {''.join(ind_to_char[target_txt.numpy()])}\")\n\n# Parametros para crear el dataset\nbatch_size = 128\nbuffer_size = 10000\n\n# Mezclamos el dataset y lo dividimos en batches\ndataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n</code></pre>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/#crear-el-modelo","title":"Crear el modelo","text":"<pre><code>vocab_size = len(vocab) # 84 = n\u00famero de caracteres \u00fanicos en el texto.\nembedding_dim = 64 # Con este valor se puede jugar un poco, pero debe ser cercano a la cantidad de caracteres (vocab_size).\n\nrnn_neurons = 1026 # Con este valor se puede jugar un poco.\n\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy\n\n# Creamos la funci\u00f3n de p\u00e9rdida personalizada porque el from_logits=True es necesario\n#  para que la funci\u00f3n de p\u00e9rdida funcione correctamente en este caso.\ndef custom_sparse_cat_loss(y_true, y_pred): \n    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)    \n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, GRU, Dense\n\ndef create_model(vocab_size, embedding_dim, rnn_neurons, batch_size):\n    model = Sequential()\n    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, batch_input_shape=[batch_size, None]))\n    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n    model.add(Dense(vocab_size))\n\n    model.compile(optimizer='adam', loss=custom_sparse_cat_loss)\n\n    return model\n\nmodel = create_model(vocab_size, embedding_dim, rnn_neurons, batch_size)\n# model.summary()\n</code></pre>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/#entrenar-el-modelo","title":"Entrenar el modelo","text":"<pre><code># Para entrenar el modelo es exactamente igual que como vimos con RNN.\n# Por lo que en este caso vamos a cargar los pesos de un modelo ya entrenado.\n\nfrom tensorflow.keras.models import load_model\n\nbatch_size = 1\nmodel = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=batch_size)\n\nmodel.load_weights('&lt;file_name&gt;.h5')\n\nmodel.build(tf.TensorShape([batch_size, None]))\n</code></pre>"},{"location":"Python/Keras/05%20-%20NLP_with_keras/#generar-texto","title":"Generar texto","text":"<pre><code># Creamos una funci\u00f3n para generar texto.\ndef generate_text(model, start_seed, gen_size=500, temp = 1.0):\n\n    num_generate = gen_size\n\n    # Convertimos el string de inicio a n\u00fameros.\n    input_eval = [char_to_ind[s] for s in start_seed]\n\n    # Expandimos la dimensi\u00f3n del input_eval para que sea compatible con el modelo.\n    input_eval = tf.expand_dims(input_eval, 0)\n\n    text_generated = []\n\n    # Este es un par\u00e1metro que controla la aleatoriedad de las predicciones y podemos modificarlo para obtener diferentes resultados.\n    temperature = temp\n\n    model.reset_states()\n    for i in range(num_generate):\n        # predecimos la siguiente letra\n        predictions = model(input_eval)\n\n        # Quitamos la dimensi\u00f3n del batch\n        predictions = tf.squeeze(predictions, 0)\n\n        # Aplicamos la temperatura\n        predictions = predictions / temperature\n\n        # Categorizamos las predicciones\n        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n\n        # Actualizamos el input_eval\n        input_eval = tf.expand_dims([predicted_id], 0)\n\n        # Agregamos la letra predicha al texto generado\n        text_generated.append(ind_to_char[predicted_id])\n    return (start_seed + ''.join(text_generated))\n\n\n# Generamos texto\nprint(generate_text(model, start_seed=\"ROMEO: \", gen_size=1000, temp=1.0))\n</code></pre>"},{"location":"Python/Keras/06%20-%20Autoencoders/","title":"Autoencoders en Keras","text":"<p>Teor\u00eda Autoencoders</p>"},{"location":"Python/Keras/06%20-%20Autoencoders/#ejemplo-de-autoencoders-con-keras","title":"Ejemplo de Autoencoders con Keras","text":""},{"location":"Python/Keras/06%20-%20Autoencoders/#preparacion-de-datos","title":"Preparaci\u00f3n de datos","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_blobs\n\n# Esta nueva funcion sirve para crear datasets r\u00e1pidamente.\n## Centers = n\u00famero de clusters.\n## random_state = semilla para reproducibilidad.\ndata = make_blobs(n_samples=1000, n_features=2, centers=2, cluster_std=0.60, random_state=101)\n\nX,y = data\n# X = datos (valores de n_features)\n# y = etiquetas (valores de centers/clusters), 0 o 1 en este ejemplo.\n\n# Generamos nueva serie de valores que representan ruido\nnp.random.seed(seed=101)\nz_noise = np.random.normal(size=len(X))\nz_noise = pd.Series(z_noise)\n\n# A\u00f1adimos el ruido a los datos en una nueva columna\nfeat = pd.DataFrame(X)\nfeat = pd.concat([feat, z_noise], axis=1)\nfeat.columns = ['X1', 'X2', 'X3']\n\nplt.scatter(feat['X1'], feat['X2'], c=y)\nplt.show()\n# Aqu\u00ed veremos que los datos est\u00e1n bien separados.\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Para crear una gr\u00e1fica interactiva en notebook\n# %matplotlib notebook\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(feat['X1'], feat['X2'], feat['X3'], c=y)\nplt.show()\n# Aqu\u00ed veremos que los datos no est\u00e1n bien separados en el nuevo eje X3.\n</code></pre>"},{"location":"Python/Keras/06%20-%20Autoencoders/#crear-el-modelo","title":"Crear el modelo","text":"<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\n\n# Vamos a crear un autoencoder 3 -&gt; 2 -&gt; 3\n\n# Creamos el encoder\nencoder = Sequential()\nencoder.add(Dense(units=2, input_shape=[3], activation='relu'))\n\n# Creamos el decoder\ndecoder = Sequential()\ndecoder.add(Dense(units=3, input_shape=[2], activation='relu'))\n\n# Creamos el autoencoder uniendo encoder y decoder\nautoencoder = Sequential([encoder, decoder])\n\n# lr = learning_rate\nautoencoder.compile(optimizer=SGD(lr=1.5), loss='mse')\n</code></pre>"},{"location":"Python/Keras/06%20-%20Autoencoders/#escalar-los-datos","title":"Escalar los datos","text":"<pre><code>from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(feat)\n</code></pre>"},{"location":"Python/Keras/06%20-%20Autoencoders/#predecir-datos","title":"Predecir datos","text":"<pre><code>autoencoder.fit(scaled_data, scaled_data, epochs=5)\n\nencoded_2dim = encoder.predict(scaled_data)\n\nencoded_2dim.shape # (300, 2)\nscaled_data.shape # (300, 3)\n\n# Ver datos codificados\nplt.scatter(encoded_2dim[:,0], encoded_2dim[:,1], c=y)\nplt.show()\n# Aqu\u00ed veremos que los datos est\u00e1n bien separados.\n</code></pre>"},{"location":"Python/NumPy/01%20-%20basic/","title":"NumPy","text":"<p>NumPy es una poderosa biblioteca de \u00e1lgebra lineal para Python. Su importancia radica en que casi todas las bibliotecas del ecosistema PyData (pandas, scipy, scikit-learn, etc.) se basan en NumPy como uno de sus pilares fundamentales.</p> <p>NumPy tambi\u00e9n es incre\u00edblemente r\u00e1pido, ya que por debajo corre bibliotecas en C.</p>"},{"location":"Python/NumPy/01%20-%20basic/#importar-numpy","title":"Importar NumPy","text":"<p>Una vez que tengas instalada la librer\u00eda de NumPy la a\u00f1adiremos al script con un import. Es bastante usual a\u00f1adir la librer\u00eda con el nombre \"np\".</p> <pre><code>import numpy as np\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/","title":"Arrays","text":""},{"location":"Python/NumPy/02%20-%20arrays/#conceptos-basicos-sobre-arrays","title":"Conceptos b\u00e1sicos sobre Arrays","text":"<p>Un array en la librer\u00eda NumPy es una estructura de datos fundamental para trabajar con conjuntos de n\u00fameros. Imagina una lista muy organizada y eficiente, dise\u00f1ada espec\u00edficamente para realizar c\u00e1lculos num\u00e9ricos de manera r\u00e1pida.</p> <p>Se pueden crear NumPy arrays directamente desde una lista de Python.</p> <pre><code>my_list = [1,2,3,4]\nnp.array(my_list) # array([1, 2, 3])\n</code></pre> <p>NumPy array tambi\u00e9n puede trabajar con m\u00e1s de una dimensi\u00f3n.</p> <pre><code>my_matrix = [[1,2,3],[4,5,6],[7,8,9]]\nnp.array(my_matrix) \n'''\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#arrange","title":"Arrange","text":"<p>Sirve para generar un array con valores igualmente espaciados dentro de un rango definido.</p> <pre><code>np.arange(15)\n# array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])\nnp.arange(5,10)\n#array([5, 6, 7, 8, 9])\nnp.arange(0,12,3)\n# array([0, 3, 6, 9])\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#ceros-y-unos","title":"Ceros y Unos","text":"<p>Para tema de machine learning es muy importante poder generar un array o matriz de ceros o unos, por lo que NumPy ofrece directamente un m\u00e9todo para ello.</p> <pre><code>np.zeros(3) \n# array([0., 0., 0.])\nnp.zeros((2,5,5)) # 2 matrices de 5x5 \n'''\narray([[[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]],\n\n       [[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]]])\n'''\nnp.ones(3)\n# array([1., 1., 1.])\nnp.ones((3,3))\n'''\narray([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#linspace","title":"Linspace","text":"<p>Devuelve n\u00fameros espaciados uniformemente en un intervalo especificado.</p> <pre><code>np.linspace(0,10,3) \n# array([ 0.,  5., 10.])\nnp.linspace(0,10,20) # 20 valores x-espaciados entre 0 y 10\n'''\narray([ 0.        ,  0.52631579,  1.05263158,  1.57894737,  2.10526316,\n        2.63157895,  3.15789474,  3.68421053,  4.21052632,  4.73684211,\n        5.26315789,  5.78947368,  6.31578947,  6.84210526,  7.36842105,\n        7.89473684,  8.42105263,  8.94736842,  9.47368421, 10.        ])\n'''\nnp.linspace(0,10,21) # 21 valores x-espaciados entre 0 y 10\n'''\narray([ 0. ,  0.5,  1. ,  1.5,  2. ,  2.5,  3. ,  3.5,  4. ,  4.5,  5. ,\n        5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#eye","title":"Eye","text":"<p>Devuelve la matriz identidad de la dimensi\u00f3n que se le indique.</p> <pre><code>np.eye(6)\n'''\narray([[1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 1.]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#random","title":"Random","text":"<p>Paquete dentro de la librer\u00eda NumPy que se encarga de generar arrays aleatorios.</p>"},{"location":"Python/NumPy/02%20-%20arrays/#rand","title":"rand","text":"<p>Genera n\u00fameros aleatorios siguiendo una distribuci\u00f3n uniforme. Los valores generados se encuentran en el intervalo <code>[0, 1)</code>, es decir, desde 0 (inclusive) hasta 1 (exclusivo).</p> <pre><code>np.random.rand(3)\n# array([0.36113539, 0.88446185, 0.48074398])\nnp.random.rand(2,3,5) # 2 matrices de 3x5\n\n'''\narray([[[0.04633713, 0.53137266, 0.74117606, 0.20512219, 0.6168586 ],\n        [0.06443939, 0.34243107, 0.3059021 , 0.20598129, 0.47033699],\n        [0.9692372 , 0.41828453, 0.74705593, 0.57757702, 0.30476353]],\n\n       [[0.49879649, 0.42105791, 0.51103856, 0.45574341, 0.798533  ],\n        [0.79231305, 0.08936987, 0.68506619, 0.93837446, 0.02559339],\n        [0.83318277, 0.40604363, 0.69039322, 0.68334075, 0.93850892]]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#randn","title":"randn","text":"<p>Genera n\u00fameros aleatorios siguiendo una distribuci\u00f3n normal est\u00e1ndar. Los valores generados pueden ser cualquier n\u00famero real, pero la mayor\u00eda se concentrar\u00e1 alrededor de 0.</p> <pre><code>np.random.randn(2)\n# array([ 0.18584968, -0.1794187 ])\nnp.random.randn(5,5)\n\n'''\narray([[-0.20626407,  1.16792749, -0.4729137 ,  1.13940936, -0.59339953],\n       [-0.99356095, -0.14937524,  1.55929908, -3.18371919,  0.66314423],\n       [ 0.73271548, -0.59890564,  0.36802319,  0.63084196,  0.59189165],\n       [-2.00064426,  0.14159769, -1.36269102,  1.52719339, -0.70780552],\n       [ 0.18033592, -0.12497444, -0.40132878,  1.67288472,  0.45831362]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#randint","title":"randint","text":"<p>Genera n\u00fameros aleatorios enteros entre el rango de valores definido.</p> <pre><code>np.random.randint(1,100) # Valor entre 1 y 100\n# 88\nnp.random.randint(1,100,10) # 10 valores entre 1 y 100\n'''\narray([39, 50, 72, 18, 27, 59, 15, 97, 11, 14])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#seed","title":"seed","text":"<p>Sirve para cambiar la semilla utilizada para generar n\u00fameros aleatorios, usando la misma semilla se generar\u00e1n los mismos n\u00fameros aleatorios.</p> <pre><code>np.random.seed(42)\nnp.random.rand(4)\n# array([0.37454012, 0.95071431, 0.73199394, 0.59865848])\nnp.random.seed(42)\nnp.random.rand(4)\n# array([0.37454012, 0.95071431, 0.73199394, 0.59865848])\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#metodos-y-atributos-de-los-arrays","title":"M\u00e9todos y atributos de los arrays","text":""},{"location":"Python/NumPy/02%20-%20arrays/#reshape","title":"Reshape","text":"<p>Cambia la dimensi\u00f3n de un array.</p> <pre><code>arr = np.arange(25)\n# arr = array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\narr.reshape(5,5)\n'''\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n'''\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#max-min-argmax-argmin","title":"max, min, argmax, argmin","text":"<p>Estos son m\u00e9todos \u00fatiles para encontrar valores m\u00e1ximos o m\u00ednimos. O para encontrar las ubicaciones de sus \u00edndices usando argmin o argmax.</p> <pre><code>ranarr = np.random.rand(4)\n# ranarr = array([0.37454012, 0.95071431, 0.73199394, 0.59865848])\nranarr.max() # 0.9507143064099162 - Valor max\nranarr.argmax() # 1 - Posici\u00f3n del primer valor max\nranarr.min() # 0.3745401188473625 - Valor min\nranarr.argmin() # 0 - Posici\u00f3n del valor min\nranarr.dtype # dtype('float64') - Tipo de datos dentro del array\n</code></pre>"},{"location":"Python/NumPy/02%20-%20arrays/#shape","title":"shape","text":"<p>Devuelve la dimensi\u00f3n del array <pre><code>ranarr = np.random.rand(4)\n# ranarr = array([0.37454012, 0.95071431, 0.73199394, 0.59865848])\nranarr.shape\n# (4,)\nnew= ranarr.reshape(2,2)\nnew.shape\n# (2, 2)\n</code></pre></p>"},{"location":"Python/NumPy/03%20-%20index/","title":"\u00cdndices","text":""},{"location":"Python/NumPy/03%20-%20index/#usar-indices-en-arrays","title":"Usar \u00edndices en arrays","text":"<p>\u00cdndices se utulizan para indicar la posici\u00f3n de un valor dentro de un array.</p> <pre><code>arr = np.arange(0,11)\n# array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\narr[8] # Coger el valor del array en la posici\u00f3n 8\n# 8\narr[1:5] # Coger array entre las posiciones 1 y 5\n# array([1, 2, 3, 4])\narr[:5]  # Coger array desde el inicio hasta la posici\u00f3n indicada\n# array([0, 1, 2, 3, 4])\narr[5:]  # Coger array desde la posici\u00f3n indicada hasta el final\n# array([ 5,  6,  7,  8,  9, 10])\n</code></pre> <p></p>"},{"location":"Python/NumPy/03%20-%20index/#indices-en-matrices-2d-arrays","title":"\u00cdndices en matrices (2D arrays)","text":"<pre><code>arr_2d = np.array(([5,10,15],[20,25,30],[35,40,45]))\narr_2d\n'''\narray([[ 5, 10, 15],\n       [20, 25, 30],\n       [35, 40, 45]])\n'''\narr_2d.shape\n# (3, 3) = (fila, columna)\narr_2d[1] # Coger fila 1\n# array([20, 25, 30])\narr_2d[1][0] # Coger elemento (1,0)\n# 20\narr_2d[:2,1:] # Coger una parte de la matriz\n'''\narray([[10, 15],\n       [25, 30]])\n'''\narr_2d[2,:]\n# array([35, 40, 45])\n</code></pre>"},{"location":"Python/NumPy/03%20-%20index/#broadcasting-transmision","title":"Broadcasting (transmisi\u00f3n)","text":"<p>Los arrays NumPy difieren de las listas normales de Python debido a su capacidad de broadcasting (transmisi\u00f3n). Con las listas, solo puedes reasignar partes de una lista con nuevas partes del mismo tama\u00f1o y forma. Es decir, si quisieras reemplazar los primeros 5 elementos de una lista con un nuevo valor, tendr\u00edas que pasar una nueva lista de 5 elementos. Con los arrays NumPy, puedes transmitir un solo valor a trav\u00e9s de un conjunto m\u00e1s grande de valores.</p> <pre><code>arr = np.arange(0,11)\n# array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\narr[0:5]=100 # sobreescribe los primeros 5 valores con el valor definido\narr\n# array([100, 100, 100, 100, 100,   5,   6,   7,   8,   9,  10])\n\nseg_array = arr[6:] # seleccionar parte del array\nseg_array\n# array([ 6,  7,  8,  9, 10])\n\nseg_array[:] = 99 # sobreescribir todo el array\nseg_array\n# array([99, 99, 99, 99, 99])\n\n## IMPORTANTE: ESTOS CAMBIOS TAMBI\u00c9N AFECTAN AL ARRAY PRINCIPAL, SI NO QUEREMOS QUE SEA AS\u00cd, DEBEMOS COPIAR EL ARRAY\narr\n# array([100, 100, 100, 100, 100,   5,  99,  99,  99,  99,  99])\n\narr_copy = arr.copy() # Copiando el array podemos trabajar en ambos de forma independiente\n</code></pre>"},{"location":"Python/NumPy/03%20-%20index/#condicionales-de-seleccion","title":"Condicionales de selecci\u00f3n","text":"<pre><code>arr = np.arange(0,11)\n# array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n\nbool_arr = arr&gt;4\nbool_arr\n# array([False, False, False, False,  True,  True,  True,  True,  True, True])\n\narr[bool_arr] # Coger s\u00f3lo elementos que cumplan la condici\u00f3n\n# array([ 5,  6,  7,  8,  9, 10])\n\nx = 2\narr[arr&gt;x]\n# array([ 3,  4,  5,  6,  7,  8,  9, 10])\n</code></pre>"},{"location":"Python/NumPy/04%20-%20operations/","title":"Operaciones","text":""},{"location":"Python/NumPy/04%20-%20operations/#operaciones-aritmeticas","title":"Operaciones aritm\u00e9ticas","text":"<pre><code>arr = np.arange(0,11)\n# array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n\narr + arr\n# array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20])\narr * arr\n# array([ 0,  1,  4,  9, 16, 25, 36, 49, 64, 81])\narr - arr\n# array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\narr/arr\n# Warning ya que en uno de los casos dividimos entre cero, entonces en ese caso el resultado es nan.\n# RuntimeWarning: invalid value encountered in divide\n# array([nan,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])\n1/arr\n# Warning ya que en en uno de los casos obtenemos infinito\n# RuntimeWarning: divide by zero encountered in true_divide\n# array([       inf, 1.        , 0.5       , 0.33333333, 0.25      , 0.2       , 0.16666667, 0.14285714, 0.125     , 0.11111111])\narr**3\n# array([  0,   1,   8,  27,  64, 125, 216, 343, 512, 729], dtype=int32)\n</code></pre>"},{"location":"Python/NumPy/04%20-%20operations/#metodos-para-operaciones","title":"M\u00e9todos para operaciones","text":"<pre><code>np.sqrt(arr)\n'''\narray([0.        , 1.        , 1.41421356, 1.73205081, 2.        , \n2.23606798, 2.44948974, 2.64575131, 2.82842712, 3.        ])\n'''\nnp.exp(arr)\n'''\narray([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01,\n       5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03,\n       2.98095799e+03, 8.10308393e+03])\n'''\nnp.sin(arr)\n'''\narray([ 0.        ,  0.84147098,  0.90929743,  0.14112001, -0.7568025 ,\n       -0.95892427, -0.2794155 ,  0.6569866 ,  0.98935825,  0.41211849])\n'''\nnp.log(arr)\n'''\narray([      -inf, 0.        , 0.69314718, 1.09861229, 1.38629436,\n       1.60943791, 1.79175947, 1.94591015, 2.07944154, 2.19722458])\n'''\n</code></pre>"},{"location":"Python/NumPy/04%20-%20operations/#estadisticas","title":"Estad\u00edsticas","text":"<pre><code>arr = np.arange(0,10)\n# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\narr.sum()\n# 45\nnp.mean()\n# 4.5\narr.max()\n# 9\narr.min()\n# 0\narr.var() # Varianza\n# 8.25\narr.std() # \n# 2.8722813232690143\n</code></pre>"},{"location":"Python/NumPy/04%20-%20operations/#logica-de-ejes","title":"L\u00f3gica de ejes","text":"<pre><code>arr_2d = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n'''\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n'''\narr_2d.sum(axis=0)\n# array([15, 18, 21, 24])\narr_2d.sum(axis=1)\n# array([10, 26, 42])\n</code></pre>"},{"location":"Python/Pandas/01%20-%20basic/","title":"Pandas","text":"<p>Pandas es una librer\u00eda de Python de c\u00f3digo abierto, extremadamente popular en el \u00e1mbito de la ciencia de datos y el machine learning. Ofrece estructuras de datos flexibles y eficientes, dise\u00f1adas espec\u00edficamente para manipular y analizar grandes conjuntos de datos.</p>"},{"location":"Python/Pandas/01%20-%20basic/#importar-pandas","title":"Importar Pandas","text":"<p>Una vez que tengas instalada la librer\u00eda de Pandas la a\u00f1adiremos al script con un import. Es bastante usual a\u00f1adir la librer\u00eda con el nombre \"pd\".</p> <pre><code>import pandas as pd\n</code></pre>"},{"location":"Python/Pandas/02%20-%20series/","title":"Series","text":"<p>Pandas Series es un tipo de dato muy similar a los arrays de NumPy, de hecho, es un tipo de de variable creado a partir de a\u00f1adir nuevas funcionaliades al tipo array de NumPy.</p> <p>Lo que diferencia a un array de NumPy de una Serie es que una Serie puede tener etiquetas de eje, lo que significa que puede ser indexada por una etiqueta, en lugar de solo una ubicaci\u00f3n num\u00e9rica. Adem\u00e1s, no necesita contener datos num\u00e9ricos, puede contener cualquier objeto arbitrario de Python.</p>"},{"location":"Python/Pandas/02%20-%20series/#crear-series","title":"Crear series","text":"<p>Una vez que tengas instalada la librer\u00eda de Pandas la a\u00f1adiremos al script con un import. Es bastante usual a\u00f1adir la librer\u00eda con el nombre \"pd\".</p> <pre><code>labels = ['a','b','c']\nmy_list = [10,20,30]\narr = np.array([10,20,30])\nd = {'a':10,'b':20,'c':30}\n\n# USANDO LISTAS\npd.Series(data=my_list)\n'''\n0    10\n1    20\n2    30\ndtype: int64\n'''\n\npd.Series(data=my_list,index=labels)\n# pd.Series(my_list,labels) # lo mismo\n'''\na    10\nb    20\nc    30\ndtype: int64\n'''\n\n\n# USANDO NUMPY ARRAYS\npd.Series(arr)\n'''\n0    10\n1    20\n2    30\ndtype: int32\n'''\npd.Series(arr,labels)\n'''\na    10\nb    20\nc    30\ndtype: int32\n'''\n\n# USANDO DICCIONARIOS\npd.Series(d)\n'''\na    10\nb    20\nc    30\ndtype: int64\n'''\n\n\n# TIPOS DE DATOS EN SERIES\npd.Series(data=labels)\n'''\n0    a\n1    b\n2    c\ndtype: object\n'''\npd.Series([sum,print,len])\n'''\n0      &lt;built-in function sum&gt;\n1    &lt;built-in function print&gt;\n2      &lt;built-in function len&gt;\ndtype: object\n'''\n</code></pre>"},{"location":"Python/Pandas/02%20-%20series/#indices","title":"\u00cdndices","text":"<p>La clave para usar una Serie es comprender su \u00edndice. Pandas utiliza estos nombres o n\u00fameros de \u00edndice para permitir b\u00fasquedas r\u00e1pidas de informaci\u00f3n (funciona como una tabla hash o un diccionario).</p> <pre><code>ventas = pd.Series(data=[250,450,200,150],index = ['USA', 'China','India', 'Brazil'])\n\nventas\n'''\nUSA       250\nChina     450\nIndia     200\nBrazil    150\ndtype: int64\n'''\n\nnuevas_ventas = pd.Series([260,500,210,100],index = ['USA', 'China','India', 'Japan'])  \n\nnuevas_ventas\n'''\nUSA      260\nChina    500\nIndia    210\nJapan    100\ndtype: int64\n'''\n\nventas['USA']\n# 250\n\n# KEY ERROR!\n#ventas['Russia'] # Nombre no existe en la serie\n#ventas['USA '] #Incorrecto espacio en el nombre\n\nventas + nuevas_ventas\n'''\nBrazil      NaN\nChina     950.0\nIndia     410.0\nJapan       NaN\nUSA       510.0\ndtype: float64\n'''\n# M\u00e1s adelante explicaremos como solucionar este problema si los \u00edndices no coinciden.\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/","title":"DataFrames","text":"<p>Los DataFrames es de las piezas m\u00e1s importante de pandas y est\u00e1n directamente inspirados en el lenguaje de programaci\u00f3n R. Podemos pensar en un DataFrame como un conjunto de objetos Serie unidos para compartir el mismo \u00edndice.</p>"},{"location":"Python/Pandas/03%20-%20dataframes/#crear-dataframe","title":"Crear DataFrame","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom numpy.random import randint\n\ncolumns= ['W', 'X', 'Y', 'Z'] # four columns\nindex= ['A', 'B', 'C', 'D', 'E'] # five rows\n\nnp.random.seed(42)\ndata = randint(-100,100,(5,4))\ndata\n'''\narray([[  2,  79,  -8, -86],\n       [  6, -29,  88, -80],\n       [  2,  21, -26, -13],\n       [ 16,  -1,   3,  51],\n       [ 30,  49, -48, -99]])\n'''\n\ndf = pd.DataFrame(data,index,columns)\ndf\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#recolectar-datos","title":"Recolectar datos","text":""},{"location":"Python/Pandas/03%20-%20dataframes/#coger-columnas","title":"Coger columnas","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf['W']\n'''\nA     2\nB     6\nC     2\nD    16\nE    30\nName: W, dtype: int32\n'''\n\ntype(df['W'])\n# pandas.core.series.Series\n\ndf[['W','Z']]\n'''\n    W   Z\nA   2 -86\nB   6 -80\nC   2 -13\nD  16  51\nE  30 -99\n'''\n\ndf['new'] = df['W'] + df['Y']\ndf\n'''\n    W   X   Y   Z  new\nA   2  79  -8 -86   -6\nB   6 -29  88 -80   94\nC   2  21 -26 -13  -24\nD  16  -1   3  51   19\nE  30  49 -48 -99  -18\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#borrar-columna","title":"Borrar columna","text":"<pre><code>df\n'''\n    W   X   Y   Z  new\nA   2  79  -8 -86   -6\nB   6 -29  88 -80   94\nC   2  21 -26 -13  -24\nD  16  -1   3  51   19\nE  30  49 -48 -99  -18\n'''\n\n# axis=1 porque estamos trabajando con columnas\ndf.drop('new',axis=1)\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\n# Los cambios no se aplican si no se reasigna la variable\ndf\n'''\n    W   X   Y   Z  new\nA   2  79  -8 -86   -6\nB   6 -29  88 -80   94\nC   2  21 -26 -13  -24\nD  16  -1   3  51   19\nE  30  49 -48 -99  -18\n'''\nnew_df = df.drop('new',axis=1)\nnew_df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#coger-fila","title":"Coger fila","text":""},{"location":"Python/Pandas/03%20-%20dataframes/#usando-nombre","title":"Usando nombre","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf.loc['A']\n'''\nW     2\nX    79\nY    -8\nZ   -86\nName: A, dtype: int32\n'''\n\ndf.loc[['A','C']]\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nC   2  21 -26 -13\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#usando-indice","title":"Usando \u00edndice","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf.iloc[0]\n'''\nW     2\nX    79\nY    -8\nZ   -86\nName: A, dtype: int32\n'''\n\ndf.iloc[0:2]\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#borrar-fila","title":"Borrar fila","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\n# axis=0 porque estamos trabajando con filas\ndf.drop('C',axis=0)\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\n# No se guardan los cambios si no reasignamos el valor\ndf\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#seleccionar-subconjunto","title":"Seleccionar subconjunto","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf.loc[['A','C'],['W','Y']]\n'''\n    W   Y\nA   2  -8\nC   2 -26\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#condicionales","title":"Condicionales","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf&gt;0 #Valores del dataframe &gt;0\n'''\n     W   X     Y     Z\nA True True False False\nB True False True False\nC True True False False\nD True False True True\nE True True False False\n'''\n\ndf[df&gt;0] #Muestra los valores del dataframe cuyo valor &gt;0 (si no lo cumple muestra NaN)\n'''\n   W      X     Y     Z\nA   2   79.0   NaN   NaN\nB   6    NaN   88.0   NaN\nC   2   21.0   NaN   NaN\nD  16    NaN   3.0  51.0\nE  30   49.0   NaN   NaN\n'''\n\ndf['X']&gt;0 #Valores de la columna X cuyo valor &gt;0\n'''\nA     True\nB    False\nC     True\nD    False\nE     True\nName: X, dtype: bool\n'''\n\ndf[df['X']&gt;0] #Muestra valores del dataframe cuyo valor de la columna X &gt;0\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nC   2  21 -26 -13\nE  30  49 -48 -99\n'''\n\ndf[df['X']&gt;0]['Y'] #Igual que el caso anterior pero muestra s\u00f3lo columna Y\n'''\nA    -8\nC   -26\nE   -48\nName: Y, dtype: int32\n'''\n\ndf[df['X']&gt;0][['Y','Z']] #Igual que el caso anterior pero muestra s\u00f3lo columnas Y Z\n'''\n     Y   Z\nA   -8 -86\nC  -26 -13\nE  -48 -99\n'''\n\ndf[(df['W']&gt;0) &amp; (df['Y'] &gt; 1)] #Muestra dataframe que cumple valor de W &gt;0 y valor de Y &gt;1\n'''\n    W     X   Y     Z\nB   6   -29   88 -80\nD  16   -1   3    51\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#otras-operaciones-con-indices","title":"Otras operaciones con \u00edndices","text":""},{"location":"Python/Pandas/03%20-%20dataframes/#resetear-indice","title":"Resetear \u00edndice","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf.reset_index()\n'''\n index   W   X   Y   Z\n0     A   2  79  -8 -86\n1     B   6 -29  88 -80\n2     C   2  21 -26 -13\n3     D  16  -1   3  51\n4     E  30  49 -48 -99\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#reasignar-indice","title":"Reasignar \u00edndice","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\nnewind = 'CA NY WY OR OO'.split()\n# ['CA', 'NY', 'WY', 'OR', 'OO']\n\ndf['States'] = newind\n'''\n    W   X   Y   Z States\nA   2  79  -8 -86   CA\nB   6 -29  88 -80   NY\nC   2  21 -26 -13   WY\nD  16  -1   3  51   OR\nE  30  49 -48 -99   OO\n'''\n\ndf = df.set_index('States')\n'''\n       W   X   Y   Z\nStates    \nCA     2  79  -8 -86\nNY     6 -29  88 -80\nWY     2  21 -26 -13\nOR    16  -1   3  51\nOO    30  49 -48 -99\n'''\n\ndf.columns\n# Index(['W', 'X', 'Y', 'Z'], dtype='object')\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#obtener-resumen-del-dataframe","title":"Obtener resumen del dataframe","text":"<pre><code>df\n'''\n    W   X   Y   Z\nA   2  79  -8 -86\nB   6 -29  88 -80\nC   2  21 -26 -13\nD  16  -1   3  51\nE  30  49 -48 -99\n'''\n\ndf.describe()\n'''\n      W         X           Y           Z\ncount 5.00000   5.000000   5.000000   5.000000\nmean 11.20000 23.800000   1.800000   -45.400000\nstd   11.96662 42.109381   51.915316   63.366395\nmin   2.00000   -29.000000 -48.000000 -99.000000\n25%   2.00000   -1.000000   -26.000000 -86.000000\n50%   6.00000   21.000000   -8.000000   -80.000000\n75%   16.00000 49.000000   3.000000   -13.000000\nmax   30.00000 79.000000   88.000000   51.000000\n'''\n\ndf.dtypes\n'''\nW    int32\nX    int32\nY    int32\nZ    int32\ndtype: object\n'''\n\ndf.info()\n'''\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 5 entries, CA to OO\nData columns (total 4 columns):\nW    5 non-null int32\nX    5 non-null int32\nY    5 non-null int32\nZ    5 non-null int32\ndtypes: int32(4)\nmemory usage: 120.0+ bytes\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#celdas-sin-definir","title":"Celdas sin definir","text":"<p>Podemos encontrarnos en un escenario donde un dataframe no tenga algunas celdas definidas, para estos casos tenemos 3 opciones para trabajar con dichas celdas:</p> <ol> <li>Dejar la celda sin definir.</li> <li>Eliminar las celdas sin definir.</li> <li>Sobreescribir las celdas sin definir.</li> </ol> <pre><code>df = pd.DataFrame({'A':[1,2,np.nan,4],\n                  'B':[5,np.nan,np.nan,8],\n                  'C':[10,20,30,40]})\n\n# 1. Dejar celdas sin definir\ndf\n'''\n A     B     C\n0 1.0     5.0     10\n1 2.0     NaN     20\n2 NaN     NaN     30\n3 4.0     8.0     40\n'''\n\n# 2. Eliminar las celdas sin definir.\ndf.dropna() # Elimina todas las filas/columnas que tengan al menos un valor sin definir.\n'''\n A     B     C\n0 1.0     5.0     10\n3 4.0     8.0     40\n'''\n\ndf.dropna(axis=1) # Elimina todas las columnas que tengan al menos un valor sin definir.\n'''\n    C\n0 10\n1 20\n2 30\n3 40\n'''\n\ndf.dropna(thresh=2) # Elimina todas las filas/columnas que tengan al menos 2 valor sin definir.\n'''\n A     B     C\n0 1.0     5.0     10\n1 2.0     NaN     20\n3 4.0     8.0     40\n'''\n\n# 3. Sobreescribir las celdas sin definir.\ndf.fillna(value='FILL VALUE') # Este comando no sobrescribe el dataframe original. \n'''\n    A         B         C\n0 1         5         10\n1 2         FILL VALUE 20\n2 FILL VALUE FILL VALUE 30\n3 4         8         40\n'''\n\ndf['A'].fillna(value=0) # Modificar s\u00f3lo columna A.\n'''\n0    1.0\n1    2.0\n2    0.0\n3    4.0\nName: A, dtype: float64\n'''\n\ndf.fillna(df.mean()) # Modificar celdas sin definir por la media de cada columna.\n'''\n A         B     C\n0 1.000000 5.0     10\n1 2.000000 6.5     20\n2 2.333333 6.5     30\n3 4.000000 8.0     40\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#agrupar-valores","title":"Agrupar valores","text":"<p>Podemos encontrarnos con tablas que tengan valores en com\u00fan, por ejemplo una tabla con informaci\u00f3n de alumnos, con una columna que especifique el a\u00f1o de nacimiento, y queremos agrupar los alumnos por el a\u00f1o de nacimiento. Usando agrupaciones podemos sacar datos de grupos de alumnos que tengan el mismo a\u00f1o de nacimiento.</p> <pre><code>df\n'''\n    Col1    Col2\n0   A       4\n1   B       3\n2   A       6\n3   C       2       \n4   C       1\n'''\n\ndf.groupby('Col1').sum() # Sumar valores agrupados por Col1\n'''\n     Col2\nCol1 \nA     10\nB     3\nC     3\n'''\n</code></pre> <p>Tambi\u00e9n se pueden crear grupos usando m\u00e1s de una key.</p> <pre><code>df.groupby(['Year','Country']).mean()\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#funciones-de-agregacion","title":"Funciones de agregaci\u00f3n","text":"countNumber of non-null observationssumSum of valuesmeanMean of valuesmadMean absolute deviationmedianArithmetic median of valuesminMinimummaxMaximummodeModeabsAbsolute ValueprodProduct of valuesstdUnbiased standard deviationvarUnbiased variancesemUnbiased standard error of the meanskewUnbiased skewness (3rd moment)kurtUnbiased kurtosis (4th moment)quantileSample quantile (value at %)cumsumCumulative sumcumprodCumulative productcummaxCumulative maximumcumminCumulative minimum"},{"location":"Python/Pandas/03%20-%20dataframes/#operaciones","title":"Operaciones","text":"<pre><code>df_one = pd.DataFrame({'k1':['A','A','B','B','C','C'],\n                      'col1':[100,200,300,300,400,500],\n                      'col2':['NY','CA','WA','WA','AK','NV']})\n\n'''\n k1 col1 col2\n0 A 100     NY\n1 A 200     CA\n2 B 300     WA\n3 B 300     WA\n4 C 400     AK\n5 C 500     NV\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#valores-unicos","title":"Valores \u00fanicos","text":"<pre><code># Devuelve valores \u00fanicos de la columna col2\ndf_one['col2'].unique() \n# array(['NY', 'CA', 'WA', 'AK', 'NV'], dtype=object)\n\n# Devuelve n\u00famero valores \u00fanicos de la columna col2\ndf_one['col2'].nunique()\n# 5\n\n# Devuelve tabla con cuenta de cada valor \u00fanico\ndf_one['col2'].value_counts()\n'''\nWA    2\nCA    1\nNV    1\nNY    1\nAK    1\nName: col2, dtype: int64\n'''\n\n# Eliminar filas duplicadas\ndf_one.drop_duplicates()\n'''\n k1 col1 col2\n0 A 100     NY\n1 A 200     CA\n2 B 300     WA\n4 C 400     AK\n5 C 500     NV\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#crear-nueva-columna-con-operaciones-y-funciones","title":"Crear nueva columna con operaciones y funciones","text":"<pre><code>df_one\n'''\n k1 col1 col2\n0 A 100     NY\n1 A 200     CA\n2 B 300     WA\n3 B 300     WA\n4 C 400     AK\n5 C 500     NV\n'''\n\n# nueva columna 'New col' dependiente de 'col1'\ndf_one['New Col'] = df_one['col1'] * 10\n\ndf_one\n'''\n k1 col1 col2 New Col\n0 A 100     NY     1000\n1 A 200     CA     2000\n2 B 300     WA     3000\n3 B 300     WA     3000\n4 C 400     AK     4000\n5 C 500     NV     5000\n'''\n\n# Aplicar funciones a una columna\ndef grab_first_letter(state):\n    # Devuelve primera letra del valor\n    return state[0]\n\ndf_one['col2'].apply(grab_first_letter)\n'''\n0    N\n1    C\n2    W\n3    W\n4    A\n5    N\nName: col2, dtype: object\n'''\n\ndf_one['first letter'] = df_one['col2'].apply(grab_first_letter)\n'''\n k1 col1 col2 New Col     first letter\n0 A 100     NY     1000     N\n1 A 200     CA     2000     C\n2 B 300     WA     3000     W\n3 B 300     WA     3000     W\n4 C 400     AK     4000     A\n5 C 500     NV     5000     N\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#mapas","title":"Mapas","text":"<pre><code>df_one['k1']\n'''\n0    A\n1    A\n2    B\n3    B\n4    C\n5    C\nName: k1, dtype: object\n'''\n\ndf_one['k1'].map({'A':1,'B':2,'C':3})\n'''\n0    1\n1    1\n2    2\n3    2\n4    3\n5    3\nName: k1, dtype: int64\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#localizar-maximos-y-minimos","title":"Localizar maximos y m\u00ednimos","text":"<pre><code># Valor m\u00e1ximo de una columna\ndf_one['col1'].max()\n# 500\n\n# Valor m\u00ednimo de una columna\ndf_one['col1'].min()\n# 100\n\n# \u00cdndice con valor m\u00e1ximo de una columna\ndf_one['col1'].idxmax()\n# 500\n\n# V\u00cdndice con valor m\u00ednimo de una columna\ndf_one['col1'].idxmin()\n# 100\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#conseguir-nombres-de-columnas-e-indices","title":"Conseguir nombres de columnas e \u00edndices","text":"<pre><code># Conseguir nombres de columnas\ndf_one.columns\n# Index(['k1', 'col1', 'col2', 'New Col', ... ], dtype='object')\n\n# \u00cdndices\ndf_one.index\n# RangeIndex(start=0, stop=6, step=1)\n\n# Cambiar nombres de columnas\ndf_one.columns = ['C1','C2','C3', 'C4']\n'''\n C1 C2     C3     C4 \n0 A 100     NY     1000\n1 A 200     CA     2000\n2 B 300     WA     3000\n3 B 300     WA     3000\n4 C 400     AK     4000\n5 C 500     NV     500\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#ordenar-tabla-con-valores-de-una-columna","title":"Ordenar tabla con valores de una columna","text":"<pre><code>df_one\n'''\n    C1  C2     C3     C4 \n0   A   100     NY     1000\n1   A   200     CA     2000\n2   B   300     WA     3000\n3   B   300     WA     3000\n4   C   400     AK     4000\n5   C   500     NV     500\n'''\n\ndf_one.sort_values('C3')\n'''\n C1 C2     C3     C4 \n4 C 400     AK     4000\n1 A 200     CA     2000\n5 C 500     NV     5000\n0 A 100     NY     1000\n2 B 300     WA     3000\n3 B 300     WA     3000\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#concatenar-tablas","title":"Concatenar tablas","text":"<pre><code>features = pd.DataFrame({'A':[100,200,300,400,500],\n                        'B':[12,13,14,15,16]})\npredictions = pd.DataFrame({'pred':[0,1,1,0,1]})\n\nfeatures\n'''\n    A     B\n0 100     12\n1 200     13\n2 300     14\n3 400     15\n4 500     16\n'''\n\npredictions\n'''\n pred\n0 0\n1 1\n2 1\n3 0\n4 1\n'''\n\n# Concatenar = Unir tablas\npd.concat([features,predictions]) # Atenci\u00f3n con los ejes\n'''\n A     B     pred\n0 100.0 12.0 NaN\n1 200.0 13.0 NaN\n2 300.0 14.0 NaN\n3 400.0 15.0 NaN\n4 500.0 16.0 NaN\n0 NaN     NaN     0.0\n1 NaN     NaN     1.0\n2 NaN     NaN     1.0\n3 NaN     NaN     0.0\n4 NaN     NaN     1.0\n'''\n\npd.concat([features,predictions],axis=1) # Atenci\u00f3n con los ejes\n'''\n A     B     pred\n0 100     12     0\n1 200     13     1\n2 300     14     1\n3 400     15     0\n4 500     16     1\n'''\n</code></pre>"},{"location":"Python/Pandas/03%20-%20dataframes/#crear-variable-dummy","title":"Crear variable dummy","text":"<pre><code>df_one['C1']\n'''\n0    A\n1    A\n2    B\n3    B\n4    C\n5    C\nName: C1, dtype: object\n'''\n\npd.get_dummies(df_one['C1'])\n'''\n A B C\n0 1 0 0\n1 1 0 0\n2 0 1 0\n3 0 1 0\n4 0 0 1\n5 0 0 1\n'''\n</code></pre>"},{"location":"Python/Pandas/04%20-%20input_output/","title":"Lectura y escritura","text":"<p>Se pueden leer tablas desde muchas fuentes diferentes como archivos csv, p\u00e1gias web, etc.</p>"},{"location":"Python/Pandas/04%20-%20input_output/#leer-archivo-csv","title":"Leer archivo csv","text":"<pre><code>import numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('example.csv')\n'''\ndf\n a b c d\n0 0 1 2 3\n1 4 5 6 7\n2 8 9 10 11\n3 12 13 14 15\n'''\n</code></pre>"},{"location":"Python/Pandas/04%20-%20input_output/#escribir-arhicvo-csv","title":"Escribir arhicvo csv","text":"<pre><code>df.to_csv('example.csv',index=False)\n</code></pre>"},{"location":"Python/Pandas/04%20-%20input_output/#leer-tabla-de-pagina-web-html","title":"Leer tabla de p\u00e1gina web (HTML)","text":"<p>Para ser capaz de leer una tabla de una p\u00e1gina web (archivo HTML) es importante comprobar que el firewall de tu m\u00e1quina no bloquee la librer\u00eda pandas para acceder a internet.</p> <p>Puede ser necesario instalar librerias extras como <code>lxml</code>, <code>html5lib</code>, <code>beautifulsoup4</code>.</p> <pre><code>tables = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')\n\n# Mostras primeros 5 elementos de la tabla\ntables[0].head()\n</code></pre>"},{"location":"Python/basic/01%20-%20Fundamentos%20del%20lenguaje/","title":"Tipos de Datos","text":"<p>Python tiene varios tipos de datos b\u00e1sicos, incluyendo enteros, flotantes, cadenas de texto y booleanos.</p>"},{"location":"Python/basic/01%20-%20Fundamentos%20del%20lenguaje/#enteros-int-numeros-sin-decimales","title":"Enteros (int): N\u00fameros sin decimales","text":"integer.py<pre><code>numero_entero = 10\nprint(numero_entero)  # Imprime: 10\n</code></pre>"},{"location":"Python/basic/01%20-%20Fundamentos%20del%20lenguaje/#flotantes-float-numeros-con-decimales","title":"Flotantes (float): N\u00fameros con decimales","text":"<pre><code>numero_flotante = 10.5\nprint(numero_flotante)  # Imprime: 10.5\n</code></pre>"},{"location":"Python/basic/01%20-%20Fundamentos%20del%20lenguaje/#cadenas-de-texto-str-texto-encerrado-en-comillas-simples-o-dobles","title":"Cadenas de texto (str): Texto encerrado en comillas simples o dobles","text":"<pre><code>cadena = \"Hola, mundo!\"\nprint(cadena)  # Imprime: Hola, mundo!\n</code></pre>"},{"location":"Python/basic/01%20-%20Fundamentos%20del%20lenguaje/#booleanos-bool-valores-true-o-false","title":"Booleanos (bool): Valores True o False","text":"<pre><code>es_verdadero = True\nprint(es_verdadero)  # Imprime: True\n</code></pre>"},{"location":"Python/basic/02%20-%20Operadores/","title":"Operadores","text":"<p>Los operadores se usan para realizar operaciones con valores.</p>"},{"location":"Python/basic/02%20-%20Operadores/#operadores-aritmeticos","title":"Operadores Aritm\u00e9ticos","text":"<pre><code>a = 5\nb = 2\n\nsuma = a + b          # Suma: 7\nresta = a - b         # Resta: 3\nmultiplicacion = a * b  # Multiplicaci\u00f3n: 10\ndivision = a / b      # Divisi\u00f3n: 2.5\nmodulo = a % b        # M\u00f3dulo: 1\npotencia = a ** b     # Exponente: 25\n</code></pre>"},{"location":"Python/basic/02%20-%20Operadores/#operadores-comparativos","title":"Operadores Comparativos","text":"<pre><code>x = 10\ny = 20\n\nigual = x == y         # Igual: False\ndiferente = x != y     # Diferente: True\nmayor = x &gt; y          # Mayor: False\nmenor = x &lt; y          # Menor: True\nmayor_o_igual = x &gt;= y # Mayor o igual: False\nmenor_o_igual = x &lt;= y # Menor o igual: True\n</code></pre>"},{"location":"Python/basic/02%20-%20Operadores/#operadores-logicos","title":"Operadores L\u00f3gicos","text":"<pre><code>a = True\nb = False\n\nand_op = a and b      # and: False\nor_op = a or b        # or: True\nnot_op = not a        # not: False\n</code></pre>"},{"location":"Python/basic/03%20-%20Estructuras%20Condicionales/","title":"Estructuras Condicionales","text":"<p>Las estructuras condicionales (<code>if</code>) permiten tomar decisiones en el c\u00f3digo.</p> <pre><code>x = 10\n\nif x &gt; 5:\n    print(\"x es mayor que 5\")\nelif x == 5:\n    print(\"x es igual a 5\")\nelse:\n    print(\"x es menor que 5\")\n</code></pre>"},{"location":"Python/basic/04%20-%20Bucles/","title":"Bucles","text":"<p>Los bucles permiten repetir un bloque de c\u00f3digo varias veces.</p>"},{"location":"Python/basic/04%20-%20Bucles/#bucle-for","title":"Bucle for","text":"<pre><code>for i in range(5):  # Itera sobre una secuencia de n\u00fameros del 0 al 4\n    print(i)\n</code></pre>"},{"location":"Python/basic/04%20-%20Bucles/#bucle-while","title":"Bucle while","text":"<pre><code>contador = 0\nwhile contador &lt; 5:\n    print(contador)\n    contador += 1\n</code></pre>"},{"location":"Python/basic/04%20-%20Bucles/#control-de-bucles","title":"Control de bucles","text":"<p>Estos comandos permiten modificar el flujo de los bucles.</p> <ul> <li>break: Sale del bucle.</li> </ul> <pre><code>for i in range(10):\n    if i == 5:\n        break\n    print(i)\n# Imprime: 0, 1, 2, 3, 4\n</code></pre> <ul> <li>continue: Salta la iteraci\u00f3n actual y contin\u00faa con la siguiente.</li> </ul> <pre><code>for i in range(5):\n    if i == 3:\n        continue\n    print(i)\n# Imprime: 0, 1, 2, 4\n</code></pre> <ul> <li>pass: No hace nada, se usa como marcador de posici\u00f3n.</li> </ul> <pre><code>for i in range(5):\n    if i == 2:\n        pass  # Aqu\u00ed no hacemos nada\n    print(i)\n# Imprime: 0, 1, 2, 3, 4\n</code></pre>"},{"location":"Python/basic/05%20-%20Funciones/","title":"Funciones","text":"<p>Las funciones te permiten agrupar c\u00f3digo que realiza una tarea espec\u00edfica y reutilizarlo.</p> <p>Estas funciones pueden recibir variables de entrada (par\u00e1metros) desde el c\u00f3digo que llama a dicha funci\u00f3n para as\u00ed utilizar dicho valor en la l\u00f3gica de la funci\u00f3n.</p> <p>Ejemplo:</p> <pre><code>def saludar(nombre):\n    \"\"\"Esta funci\u00f3n saluda a la persona cuyo nombre se pasa como argumento.\"\"\"\n    print(f\"Hola, {nombre}!\")\n\nsaludar(\"Juan\")  # Imprime: Hola, Juan!\n</code></pre> <p>Tambi\u00e9n se pueden definir funciones con valor de retorno:</p> <pre><code>def suma(a, b):\n    return a + b\n\nresultado = suma(3, 5)\nprint(resultado)  # Imprime: 8\n</code></pre>"},{"location":"Python/basic/06%20-%20Ambito%20de%20variables/","title":"\u00c1mbito de Variables","text":"<p>Las variables definidas dentro de una funci\u00f3n tienen un \u00e1mbito local, mientras que las variables definidas fuera de las funciones tienen un \u00e1mbito global.</p> <p>Ejemplo:</p> <pre><code>x = 10  # Variable global\n\ndef funcion():\n    y = 5  # Variable local\n    print(x)  # Accede a la variable global\n    print(y)  # Accede a la variable local\n\nfuncion()\nprint(x)  # Imprime: 10\n# print(y)  # Esto causar\u00e1 un error porque y no est\u00e1 definida en el \u00e1mbito global\n</code></pre>"},{"location":"Python/basic/07%20-%20Conjuntos%20de%20datos/","title":"Conjuntos de datos","text":"<p>Cada uno de los conjuntos de datos tiene sus propias ventajas y desventajas. Las listas son ideales para colecciones ordenadas y mutables, las tuplas para datos inmutables, los sets para colecciones de elementos \u00fanicos y los diccionarios para pares clave-valor. Conocer cu\u00e1ndo y c\u00f3mo usar cada uno te ayudar\u00e1 a escribir c\u00f3digo m\u00e1s eficiente y claro en Python.</p>"},{"location":"Python/basic/07%20-%20Conjuntos%20de%20datos/#lista","title":"Lista","text":"<p>Las listas son colecciones ordenadas y mutables, lo que significa que puedes cambiar sus elementos despu\u00e9s de haberlas creado. Se definen utilizando corchetes [].</p> <pre><code># Crear una lista inicial\nfrutas = [\"manzana\", \"banana\", \"cereza\"]\nprint(\"Lista inicial:\", frutas)  \n# Salida: ['manzana', 'banana', 'cereza']\n\n# Leer un elemento de la lista\nprint(\"Primer elemento de la lista:\", frutas[0])  \n# Salida: 'manzana'\n\n# A\u00f1adir un elemento al final de la lista\nfrutas.append(\"naranja\")\nprint(\"Despu\u00e9s de append:\", frutas)  \n# Salida: ['manzana', 'banana', 'cereza', 'naranja']\n\n# A\u00f1adir todos los elementos de otra lista\nfrutas.extend([\"kiwi\", \"mango\"])\nprint(\"Despu\u00e9s de extend:\", frutas)  \n# Salida: ['manzana', 'banana', 'cereza', 'naranja', 'kiwi', 'mango']\n\n# Insertar un elemento en una posici\u00f3n espec\u00edfica\nfrutas.insert(1, \"fresa\")\nprint(\"Despu\u00e9s de insert:\", frutas)  \n# Salida: ['manzana', 'fresa', 'banana', 'cereza', 'naranja', 'kiwi', 'mango']\n\n# Eliminar el primer elemento con el valor especificado\nfrutas.remove(\"banana\")\nprint(\"Despu\u00e9s de remove:\", frutas)  \n# Salida: ['manzana', 'fresa', 'cereza', 'naranja', 'kiwi', 'mango']\n\n# Eliminar el elemento en la posici\u00f3n especificada y devolverlo\nfruta_eliminada = frutas.pop(2)\nprint(\"Elemento eliminado con pop:\", fruta_eliminada)  \n# Salida: cereza\nprint(\"Despu\u00e9s de pop:\", frutas)  \n# Salida: ['manzana', 'fresa', 'naranja', 'kiwi', 'mango']\n\n# Eliminar todos los elementos de la lista\nfrutas.clear()\nprint(\"Despu\u00e9s de clear:\", frutas)  \n# Salida: []\n\n# Crear una nueva lista para los siguientes ejemplos\nfrutas = [\"manzana\", \"banana\", \"cereza\", \"banana\"]\n\n# Obtener tama\u00f1o de la lista\nprint(\"Tama\u00f1o de la lista:\", len(frutas))  \n# Salida: 4\n\n# Obtener el \u00edndice del primer elemento con el valor especificado\nindice = frutas.index(\"banana\")\nprint(\"\u00cdndice de 'banana':\", indice)  \n# Salida: 1\n\n# Contar el n\u00famero de elementos con el valor especificado\nconteo = frutas.count(\"banana\")\nprint(\"Conteo de 'banana':\", conteo)  \n# Salida: 2\n\n# Ordenar los elementos de la lista en orden ascendente\nnumeros = [3, 1, 4, 1, 5, 9]\nnumeros.sort()\nprint(\"Despu\u00e9s de sort:\", numeros)  \n# Salida: [1, 1, 3, 4, 5, 9]\n\n# Invertir el orden de los elementos en la lista\nfrutas.reverse()\nprint(\"Despu\u00e9s de reverse:\", frutas)  \n# Salida: ['banana', 'cereza', 'banana', 'manzana']\n\n# Devolver una copia superficial de la lista\ncopia_frutas = frutas.copy()\nprint(\"Copia de la lista:\", copia_frutas)  \n# Salida: ['banana', 'cereza', 'banana', 'manzana']\n\n# Coger s\u00f3lo un subconjunto de valores de la lista\nL = range(10) # [0, 1, 2, ... , 9]\nprint(L[1:-1]) # [1, 2, ... , 8]\nprint(L[::2]) # [0, 2, 4, 6, 8]\nprint(L[::-1]) # [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n</code></pre>"},{"location":"Python/basic/07%20-%20Conjuntos%20de%20datos/#tupla","title":"Tupla","text":"<p>Las tuplas son similares a las listas, pero son inmutables, lo que significa que no puedes cambiar sus elementos despu\u00e9s de haberlas creado. Se definen utilizando par\u00e9ntesis ().</p> <pre><code># Ejemplo de tupla\ncolores = (\"rojo\", \"verde\", \"azul\")\nprint(colores)  \n# Salida: ('rojo', 'verde', 'azul')\n\n# Intentar cambiar un elemento (esto causar\u00e1 un error)\n# colores[1] = \"amarillo\"  # TypeError: 'tuple' object does not support item assignment\n\n# Acceder a un elemento por su \u00edndice\nprint(\"Elemento en el \u00edndice 1:\", colores[1])  \n# Salida: verde\n\n# Intentar cambiar un elemento (esto causar\u00e1 un error)\n# colores[1] = \"amarillo\"  # TypeError: 'tuple' object does not support item assignment\n\n# Crear una nueva tupla combinando dos tuplas\nnuevos_colores = colores + (\"amarillo\", \"morado\")\nprint(\"Tupla combinada:\", nuevos_colores)  \n# Salida: ('rojo', 'verde', 'azul', 'amarillo', 'morado')\n\n# Repetir elementos de una tupla\nrepetidos = colores * 2\nprint(\"Tupla repetida:\", repetidos)  \n# Salida: ('rojo', 'verde', 'azul', 'rojo', 'verde', 'azul')\n\n# Verificar si un elemento est\u00e1 en la tupla\nexiste = \"verde\" in colores\nprint(\"\u00bf'verde' est\u00e1 en la tupla?:\", existe)  \n# Salida: True\n\n# Obtener la longitud de la tupla\nlongitud = len(colores)\nprint(\"Longitud de la tupla:\", longitud)  \n# Salida: 3\n\n# Contar el n\u00famero de veces que un elemento aparece en la tupla\nconteo = colores.count(\"rojo\")\nprint(\"Conteo de 'rojo':\", conteo)  \n# Salida: 1\n\n# Obtener el \u00edndice del primer elemento con el valor especificado\nindice = colores.index(\"azul\")\nprint(\"\u00cdndice de 'azul':\", indice)  \n# Salida: 2\n\n# Desempaquetar una tupla en variables individuales\nrojo, verde, azul = colores\nprint(\"Desempaquetado:\", rojo, verde, azul)  \n# Salida: rojo verde azul\n\n# Desempaquetar una tupla con m\u00e1s elementos en una lista\ncolores_extendidos = (\"rojo\", \"verde\", \"azul\", \"amarillo\", \"morado\")\nrojo, verde, azul, *otros_colores = colores_extendidos\nprint(\"Desempaquetado extendido:\", rojo, verde, azul, otros_colores)  \n# Salida: rojo verde azul ['amarillo', 'morado']\n</code></pre>"},{"location":"Python/basic/07%20-%20Conjuntos%20de%20datos/#set","title":"Set","text":"<p>Los sets son colecciones desordenadas de elementos \u00fanicos. Se definen utilizando llaves {}.</p> <pre><code># Crear un set inicial\nnumeros = {1, 2, 3, 4, 5}\nprint(\"Set inicial:\", numeros)  \n# Salida: {1, 2, 3, 4, 5}\n\n# A\u00f1adir un elemento al set\nnumeros.add(6)\nprint(\"Despu\u00e9s de add:\", numeros)  \n# Salida: {1, 2, 3, 4, 5, 6}\n\n# Intentar a\u00f1adir un elemento duplicado (no tendr\u00e1 efecto)\nnumeros.add(3)\nprint(\"Despu\u00e9s de a\u00f1adir un duplicado:\", numeros)  \n# Salida: {1, 2, 3, 4, 5, 6}\n\n# Eliminar un elemento del set\nnumeros.remove(4)\nprint(\"Despu\u00e9s de remove:\", numeros)  \n# Salida: {1, 2, 3, 5, 6}\n\n# Eliminar un elemento con discard (no causa error si el elemento no existe)\nnumeros.discard(10)\nprint(\"Despu\u00e9s de discard:\", numeros)  \n# Salida: {1, 2, 3, 5, 6}\n\n# Eliminar y devolver un elemento aleatorio del set\nelemento_eliminado = numeros.pop()\nprint(\"Elemento eliminado con pop:\", elemento_eliminado)\nprint(\"Despu\u00e9s de pop:\", numeros)\n\n# Limpiar todos los elementos del set\nnumeros.clear()\nprint(\"Despu\u00e9s de clear:\", numeros)  \n# Salida: set()\n\n# Crear dos sets para operaciones de conjuntos\nset_a = {1, 2, 3}\nset_b = {3, 4, 5}\n\n# Uni\u00f3n de dos sets\nunion = set_a.union(set_b)\nprint(\"Uni\u00f3n de set_a y set_b:\", union)  \n# Salida: {1, 2, 3, 4, 5}\n\n# Intersecci\u00f3n de dos sets\ninterseccion = set_a.intersection(set_b)\nprint(\"Intersecci\u00f3n de set_a y set_b:\", interseccion)  \n# Salida: {3}\n\n# Diferencia de dos sets\ndiferencia = set_a.difference(set_b)\nprint(\"Diferencia de set_a y set_b:\", diferencia)  \n# Salida: {1, 2}\n\n# Diferencia sim\u00e9trica de dos sets\ndiferencia_simetrica = set_a.symmetric_difference(set_b)\nprint(\"Diferencia sim\u00e9trica de set_a y set_b:\", diferencia_simetrica)  \n# Salida: {1, 2, 4, 5}\n\n# Verificar si un set es subconjunto de otro\nes_subconjunto = set_a.issubset({1, 2, 3, 4, 5})\nprint(\"\u00bfset_a es subconjunto?:\", es_subconjunto)  \n# Salida: True\n\n# Verificar si un set es superconjunto de otro\nes_superconjunto = set_a.issuperset({1, 2})\nprint(\"\u00bfset_a es superconjunto?:\", es_superconjunto)  \n# Salida: True\n\n# Verificar si dos sets son disjuntos\nson_disjuntos = set_a.isdisjoint({4, 5, 6})\nprint(\"\u00bfset_a y {4, 5, 6} son disjuntos?:\", son_disjuntos)  \n# Salida: True\n</code></pre>"},{"location":"Python/basic/07%20-%20Conjuntos%20de%20datos/#diccionarios","title":"Diccionarios","text":"<p>Los diccionarios son colecciones desordenadas de pares clave-valor. Se definen utilizando llaves {} y los pares clave-valor se separan con dos puntos :.</p> <pre><code># Crear un diccionario inicial\nestudiante = {\n    \"nombre\": \"Juan\",\n    \"edad\": 21,\n    \"carrera\": \"Ingenier\u00eda\"\n}\nprint(\"Diccionario inicial:\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 21, 'carrera': 'Ingenier\u00eda'}\n\n# Acceder a un valor por su clave\nprint(\"Nombre del estudiante:\", estudiante[\"nombre\"])  \n# Salida: Juan\n\n# A\u00f1adir un nuevo par clave-valor\nestudiante[\"promedio\"] = 8.5\nprint(\"Despu\u00e9s de a\u00f1adir 'promedio':\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 21, 'carrera': 'Ingenier\u00eda', 'promedio': 8.5}\n\n# Modificar un valor existente\nestudiante[\"edad\"] = 22\nprint(\"Despu\u00e9s de modificar 'edad':\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 22, 'carrera': 'Ingenier\u00eda', 'promedio': 8.5}\n\n# Eliminar un par clave-valor con pop\npromedio = estudiante.pop(\"promedio\")\nprint(\"Valor eliminado con pop:\", promedio)  \n# Salida: 8.5\nprint(\"Despu\u00e9s de pop:\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 22, 'carrera': 'Ingenier\u00eda'}\n\n# Eliminar el \u00faltimo par clave-valor a\u00f1adido con popitem\nultimo_elemento = estudiante.popitem()\nprint(\"\u00daltimo elemento eliminado con popitem:\", ultimo_elemento)  \n# Salida: ('carrera', 'Ingenier\u00eda')\nprint(\"Despu\u00e9s de popitem:\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 22}\n\n# Obtener un valor con get\nedad = estudiante.get(\"edad\")\nprint(\"Edad del estudiante con get:\", edad)  \n# Salida: 22\n\n# Intentar obtener un valor que no existe con get (devuelve None)\npromedio = estudiante.get(\"promedio\")\nprint(\"Promedio del estudiante con get:\", promedio)  \n# Salida: None\n\n# Verificar si una clave existe en el diccionario\nexiste_nombre = \"nombre\" in estudiante\nprint(\"\u00bf'nombre' est\u00e1 en el diccionario?:\", existe_nombre)  \n# Salida: True\n\n# Obtener todas las claves del diccionario\nclaves = estudiante.keys()\nprint(\"Claves del diccionario:\", claves)  \n# Salida: dict_keys(['nombre', 'edad'])\n\n# Obtener todos los valores del diccionario\nvalores = estudiante.values()\nprint(\"Valores del diccionario:\", valores)  \n# Salida: dict_values(['Juan', 22])\n\n# Obtener todos los pares clave-valor del diccionario\nitems = estudiante.items()\nprint(\"Pares clave-valor del diccionario:\", items)  \n# Salida: dict_items([('nombre', 'Juan'), ('edad', 22)])\n\n# Actualizar el diccionario con otro diccionario\nestudiante.update({\"carrera\": \"Matem\u00e1ticas\", \"promedio\": 9.0})\nprint(\"Despu\u00e9s de update:\", estudiante)  \n# Salida: {'nombre': 'Juan', 'edad': 22, 'carrera': 'Matem\u00e1ticas', 'promedio': 9.0}\n\n# Limpiar todos los elementos del diccionario\nestudiante.clear()\nprint(\"Despu\u00e9s de clear:\", estudiante)  \n# Salida: {}\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/","title":"Excepciones","text":"<p>Las excepciones en Python son una forma de manejar errores que pueden ocurrir durante la ejecuci\u00f3n de un programa. Cuando ocurre un error, Python genera una excepci\u00f3n que puede ser capturada y manejada para evitar que el programa se detenga abruptamente.</p> <p>Ejemplo b\u00e1sico:</p> <pre><code>try:\n    # C\u00f3digo que puede causar una excepci\u00f3n\n    resultado = 10 / 0\nexcept ZeroDivisionError:\n    # C\u00f3digo que se ejecuta si ocurre una excepci\u00f3n de tipo ZeroDivisionError\n    print(\"No se puede dividir por cero.\")\nelse:\n    # C\u00f3digo que se ejecuta si no ocurre ninguna excepci\u00f3n\n    print(\"El resultado es:\", resultado)\nfinally:\n    # C\u00f3digo que se ejecuta siempre, ocurra o no una excepci\u00f3n\n    print(\"Fin del bloque try-except.\")\n</code></pre> <p>En este ejemplo:</p> <ol> <li>try: Contiene el c\u00f3digo que puede causar una excepci\u00f3n.</li> <li>except: Captura y maneja la excepci\u00f3n espec\u00edfica (en este caso, ZeroDivisionError).</li> <li>else: Se ejecuta si no ocurre ninguna excepci\u00f3n.</li> <li>finally: Se ejecuta siempre, independientemente de si ocurri\u00f3 una excepci\u00f3n o no.</li> </ol>"},{"location":"Python/basic/08%20-%20Excepciones/#manejo-de-multiples-excepciones","title":"Manejo de m\u00faltiples excepciones","text":"<pre><code>try:\n    # Intentar acceder a un \u00edndice fuera del rango\n    lista = [1, 2, 3]\n    elemento = lista[5]\nexcept IndexError as e:\n    print(\"Error: \u00cdndice fuera del rango.\")  \n    # Salida: Error: \u00cdndice fuera del rango.\n    print(\"Detalles del error:\", e)  \n    # Salida: list index out of range\nexcept Exception as e:\n    print(\"Error gen\u00e9rico:\", e)\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/#uso-de-else-y-finally-en-el-manejo-de-excepciones","title":"Uso de else y finally en el manejo de excepciones","text":"<pre><code>try:\n    # Intentar convertir una cadena a entero\n    numero = int(\"123\")\nexcept ValueError as e:\n    print(\"Error: No se puede convertir la cadena a entero.\")\nelse:\n    print(\"Conversi\u00f3n exitosa:\", numero)  \n    # Salida: Conversi\u00f3n exitosa: 123\nfinally:\n    print(\"Bloque finally ejecutado.\")  \n    # Salida: Bloque finally ejecutado.\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/#manejar-varios-tipos-de-errores-en-la-misma-excepcion","title":"Manejar varios tipos de errores en la misma excepci\u00f3n","text":"<pre><code>try:\n    # C\u00f3digo que puede causar m\u00faltiples excepciones\n    numero = int(input(\"Introduce un n\u00famero: \"))\n    resultado = 10 / numero\nexcept (ValueError, ZeroDivisionError) as e:\n    # Maneja tanto ValueError como ZeroDivisionError\n    print(f\"Ocurri\u00f3 un error: {e}\")\nelse:\n    print(f\"El resultado es: {resultado}\")\nfinally:\n    print(\"Fin del bloque try-except.\")\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/#lanzar-una-excepcion-personalizada","title":"Lanzar una excepci\u00f3n personalizada","text":"<pre><code>try:\n    # Definir una funci\u00f3n que lanza una excepci\u00f3n personalizada\n    def verificar_edad(edad):\n        if edad &lt; 18:\n            raise ValueError(\"La edad debe ser mayor o igual a 18.\")\n        return True\n\n    # Llamar a la funci\u00f3n con una edad inv\u00e1lida\n    verificar_edad(16)\nexcept ValueError as e:\n    print(\"Error personalizado:\", e)  \n    # Salida: Error personalizado: La edad debe ser mayor o igual a 18.\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/#manejo-de-excepciones-anidadas","title":"Manejo de excepciones anidadas","text":"<pre><code>try:\n    try:\n        # Intentar abrir un archivo que no existe\n        with open(\"archivo_inexistente.txt\", \"r\") as archivo:\n            contenido = archivo.read()\n    except FileNotFoundError as e:\n        print(\"Error: Archivo no encontrado.\")  \n        # Salida: Error: Archivo no encontrado.\n        print(\"Detalles del error:\", e)  \n        # Salida: [Errno 2] No such file or directory: 'archivo_inexistente.txt'\n        raise  # Re-lanzar la excepci\u00f3n\nexcept Exception as e:\n    print(\"Excepci\u00f3n capturada en el bloque externo:\", e)\n</code></pre>"},{"location":"Python/basic/08%20-%20Excepciones/#uso-de-assert-para-lanzar-una-excepcion","title":"Uso de assert para lanzar una excepci\u00f3n","text":"<pre><code>try:\n    # Verificar una condici\u00f3n con assert\n    x = 10\n    assert x &gt; 20, \"x debe ser mayor que 20\"\nexcept AssertionError as e:\n    print(\"Error de aserci\u00f3n:\", e)  \n    # Salida: Error de aserci\u00f3n: x debe ser mayor que 20\n</code></pre>"},{"location":"Python/basic/09%20-%20Orientada%20a%20objetos/","title":"Programaci\u00f3n orientada a objetos","text":"<p>La Programaci\u00f3n Orientada a Objetos (POO) - en ingl\u00e9s \"Object-Oriented Programming (OOP)\" - es un paradigma de programaci\u00f3n que utiliza \"objetos\" y sus interacciones para dise\u00f1ar aplicaciones y programas. Python es un lenguaje que soporta POO, lo que permite crear programas m\u00e1s estructurados y reutilizables. Esto permite crear programas m\u00e1s organizados y f\u00e1ciles de mantener.</p>"},{"location":"Python/basic/09%20-%20Orientada%20a%20objetos/#clases-y-objetos","title":"Clases y Objetos","text":"<ul> <li>Clase: Es un plano o plantilla para crear objetos. Define un conjunto de atributos y m\u00e9todos que los objetos creados a partir de la clase tendr\u00e1n.</li> <li>Objeto: Es una instancia de una clase. Es la entidad real que se crea utilizando la clase como plantilla.</li> </ul> <pre><code>class Persona:\n    def __init__(self, nombre, edad):\n        self.nombre = nombre\n        self.edad = edad\n\n    def saludar(self):\n        print(f\"Hola, mi nombre es {self.nombre} y tengo {self.edad} a\u00f1os.\")\n\n# Crear un objeto de la clase Persona\npersona1 = Persona(\"Juan\", 30)\npersona1.saludar()\n</code></pre>"},{"location":"Python/basic/09%20-%20Orientada%20a%20objetos/#herencia","title":"Herencia","text":"<p>La herencia permite crear una nueva clase que es una modificaci\u00f3n de una clase existente. La nueva clase hereda los atributos y m\u00e9todos de la clase base.</p> <pre><code>class Empleado(Persona):\n    def __init__(self, nombre, edad, salario):\n        super().__init__(nombre, edad)\n        self.salario = salario\n\n    def mostrar_salario(self):\n        print(f\"Mi salario es {self.salario}.\")\n\n# Crear un objeto de la clase Empleado\nempleado1 = Empleado(\"Ana\", 28, 50000)\nempleado1.saludar()\nempleado1.mostrar_salario()\n</code></pre>"},{"location":"Python/basic/09%20-%20Orientada%20a%20objetos/#encapsulamiento","title":"Encapsulamiento","text":"<p>El encapsulamiento es el mecanismo que restringe el acceso directo a algunos de los componentes de un objeto. En Python, se puede usar un guion bajo (_) para indicar que un atributo o m\u00e9todo es privado.</p> <pre><code>class CuentaBancaria:\n    def __init__(self, titular, saldo):\n        self.titular = titular\n        self.__saldo = saldo\n\n    def mostrar_saldo(self):\n        print(f\"El saldo de {self.titular} es {self.__saldo}.\")\n\n    def depositar(self, cantidad):\n        self.__saldo += cantidad\n\n# Crear un objeto de la clase CuentaBancaria\ncuenta1 = CuentaBancaria(\"Carlos\", 1000)\ncuenta1.mostrar_saldo()\ncuenta1.depositar(500)\ncuenta1.mostrar_saldo()\n</code></pre>"},{"location":"Python/basic/09%20-%20Orientada%20a%20objetos/#polimorfismo","title":"Polimorfismo","text":"<p>El polimorfismo permite que diferentes clases puedan ser tratadas como instancias de una misma clase a trav\u00e9s de una interfaz com\u00fan. Esto es \u00fatil para funciones que pueden recibir objetos de diferentes clases y tratarlos de manera uniforme.</p> <pre><code>class Animal:\n    def hacer_sonido(self):\n        pass\n\nclass Perro(Animal):\n    def hacer_sonido(self):\n        print(\"Guau\")\n\nclass Gato(Animal):\n    def hacer_sonido(self):\n        print(\"Miau\")\n\ndef hacer_sonido_animal(animal):\n    animal.hacer_sonido()\n\n# Crear objetos de las clases Perro y Gato\nperro = Perro()\ngato = Gato()\n\nhacer_sonido_animal(perro)\nhacer_sonido_animal(gato)\n</code></pre>"},{"location":"Python/basic/10%20-%20Decoradores/","title":"Decoradores","text":"<p>WIP</p>"},{"location":"Python/basic/11%20-%20Entorno%20virtual/","title":"Entorno virtual","text":"<p>WIP</p>"},{"location":"Python/basic/12%20-%20Algoritmos/","title":"Algoritmos","text":"<p>En python hay muchos algoritmos que nos pueden ayudar a realizar operaciones de forma m\u00e1s sencilla.</p> <p>Links: - LeetCode Algoritmos - NeetCode Algoritmos</p>"},{"location":"Python/basic/12%20-%20Algoritmos/#algoritmo-de-kadane","title":"Algoritmo de Kadane","text":"<p>La idea del algoritmo de Kadane es recorrer la matriz de izquierda a derecha y, para cada elemento, encontrar la suma m\u00e1xima entre todas las submatrices que terminan en ese elemento . El resultado ser\u00e1 el m\u00e1ximo de todos estos valores.</p> <pre><code>def maxSubarraySum(arr):\n\n    res = arr[0]\n    maxEnding = arr[0]\n\n    for i in range(1, len(arr)):\n\n        # Encuentra el mayor valor entre:\n        #  - Sumar el nuevo valor al sub-array actual\n        #  - Empezar un nuevo sub-array\n        maxEnding = max(maxEnding + arr[i], arr[i])\n\n        # Actualizar resultado si la suma del nuevo\n        #  sub-array es el nuevo mayor valor.\n        res = max(res, maxEnding)\n\n    return res\n\narr = [2, 3, -8, 7, -1, 2, 3]\nprint(maxSubarraySum(arr))\n# Salida: 11 --&gt; Generado por sub-array {7, -1, 2, 3}\n</code></pre>"},{"location":"Python/matplotlib/01%20-%20basic/","title":"Matplotlib","text":"<p>Matplotlib es una biblioteca de Python utilizada para crear gr\u00e1ficos y visualizaciones de datos. Es especialmente popular en la comunidad cient\u00edfica y de an\u00e1lisis de datos por su capacidad para generar una amplia variedad de gr\u00e1ficos, como gr\u00e1ficos de l\u00edneas, barras, histogramas y dispersi\u00f3n. Adem\u00e1s, permite personalizar los gr\u00e1ficos de manera detallada, lo que la hace muy vers\u00e1til para diferentes tipos de proyectos.</p>"},{"location":"Python/matplotlib/01%20-%20basic/#visualizar-graficas","title":"Visualizar gr\u00e1ficas","text":"<p>Para visualizar la gr\u00e1fica hay que definir los valores para cada eje y luego unir ambas listas en una tabla.</p> <pre><code>import matplotlib.pyplot as plt\n\nx = [0, 1, 2]\ny = [100, 200, 300]\n\nplt.plot(x, y) # Si a\u00f1adimos ';' al final de esta l\u00ednea no se mostrar\u00e1 el texto en el output del comando.\nplt.show() # Esta l\u00ednea es necesaria en archivos '.py' para crear la nueva ventana donde mostrar la gr\u00e1fica. \n</code></pre>"},{"location":"Python/matplotlib/01%20-%20basic/#herramientas-basicas","title":"Herramientas b\u00e1sicas","text":"<pre><code>import numpy as np\nimport pandas as pd\n\nhousing = pd.DataFrame({'rooms':[1,1,2,2,2,3,3,3],\n                       'price':[100,120,190,200,230,310,330,305]})\n\n'''\n    rooms price\n0   1     100\n1   1     120\n2   2     190\n3   2     200\n4   2     230\n5   3     310\n6   3     330\n7   3     305\n'''\n</code></pre> <p>Mostrando esta gr\u00e1fica por defecto no se muestra demasiado bien. Debido a que los valores no tiene  demasiada relaci\u00f3n entre ellos.</p> <pre><code>plt.plot(housing['rooms'],housing['price'])\n</code></pre> <p></p> <p>Por ello, podemos elegir otro typo de gr\u00e1fica donde los valores se vean m\u00e1s claros.</p> <pre><code>plt.scatter(housing['rooms'],housing['price'])\n</code></pre> <p></p>"},{"location":"Python/matplotlib/01%20-%20basic/#anadir-estilo","title":"A\u00f1adir estilo","text":"<p>Se puede costumizar la gr\u00e1fica de muchas maneras, como a\u00f1adir l\u00edmites a los ejes, a\u00f1adir nombre a los ejes, usar otro tipo de l\u00ednea, etc.</p> <pre><code>import matplotlib.pyplot as plt\n\nx = [0, 1, 2]\ny = [100, 200, 300]\n\n# Cambiar tipo de l\u00ednea y puntos.\nplt.plot(x,y,color='red',marker='o',markersize=20,linestyle='--')\n\n# A\u00f1adir l\u00edmite a los ejes\nplt.xlim(0,2)\nplt.ylim(100,300)\n\n\n# A\u00f1adir t\u00edtulo y nombres a los ejes\nplt.title('Title')\nplt.xlabel('X Label')\nplt.ylabel('Y Label')\nplt.show();\n</code></pre> <p></p>"},{"location":"Python/matplotlib/02%20-%20seaborn/","title":"Seaborn","text":"<p>Seaborn es una biblioteca de visualizaci\u00f3n de datos en Python que se basa en Matplotlib. Proporciona una interfaz de alto nivel para crear gr\u00e1ficos estad\u00edsticos atractivos y f\u00e1ciles de interpretar. Seaborn se integra estrechamente con las estructuras de datos de pandas, lo que facilita la exploraci\u00f3n y comprensi\u00f3n de los datos</p>"},{"location":"Python/matplotlib/02%20-%20seaborn/#visualizar-graficas","title":"Visualizar gr\u00e1ficas","text":"<p>Para visualizar la gr\u00e1fica hay que definir los valores para cada eje y luego unir ambas listas en una tabla.</p> <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\ndf = pd.read_csv('../DATA/heart.csv')\n\ndf.head()\n</code></pre> <p></p>"},{"location":"Python/matplotlib/02%20-%20seaborn/#graficas-de-distribucion","title":"Graficas de distribuci\u00f3n","text":"<pre><code>sns.distplot(df['age'])\n</code></pre>"},{"location":"Python/matplotlib/02%20-%20seaborn/#cambios-en-la-grafica","title":"Cambios en la gr\u00e1fica","text":"<pre><code>plt.figure(figsize=(12, 8))\nsns.distplot(df['age'], kde=False, bins=40, color='red')\n# kde=False -&gt; Disable kernel density estimate line\n# bins=40 -&gt; Change nums of columns\n# color='red' -&gt; Select main color\n\n# L\u00edmites en el eje x\n# plt.xlim(50,60)\n</code></pre>"},{"location":"Python/matplotlib/02%20-%20seaborn/#graficos-de-cuentas","title":"Gr\u00e1ficos de cuentas","text":"<p>Gr\u00e1ficos de cuentas (count plot). Por ejemplo si en una tabla queremos contar n\u00famero de hombres y mujeres.</p> <pre><code>sns.countplot(x='sex',data=df)\n</code></pre> <p></p> <pre><code>sns.countplot(x='cp',data=df)\n</code></pre> <p></p> <p>A su misma vez podemos unir las dos gr\u00e1ficas anteriores y contar los datos por sexo.</p> <pre><code>sns.countplot(x='cp',data=df,hue='sex')\n</code></pre> <p></p> <p>Tambi\u00e9n podemos cambiar la paleta de colores.</p> <p>https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html</p> <pre><code>sns.countplot(x='cp',data=df,palette='terrain')\n</code></pre> <p></p>"},{"location":"Python/matplotlib/02%20-%20seaborn/#diagrama-de-cajas","title":"Diagrama de cajas","text":"<p>Diagrama de cajas (Box plot). Este tipo de gr\u00e1fica nos ayuda a mostrar la distribuci\u00f3n de los valores.</p> <p></p> <pre><code>sns.boxplot(x='sex',y='age',data=df)\n</code></pre> <p></p> <pre><code>sns.boxplot(x='target',y='thalach',data=df,hue='sex')\n</code></pre> <p></p>"},{"location":"Python/matplotlib/02%20-%20seaborn/#diagramas-de-dispersion","title":"Diagramas de dispersi\u00f3n","text":"<p>Diagramas de dispersi\u00f3n (Scatter  Plots).</p> <pre><code>sns.scatterplot(x='chol',y='trestbps',data=df)\n</code></pre> <p></p> <pre><code>sns.scatterplot(x='chol',y='trestbps',data=df,hue='sex',palette='Dark2')\n</code></pre> <p></p> <pre><code>sns.scatterplot(x='chol',y='trestbps',data=df,hue='sex',size='age')\n</code></pre> <p></p>"},{"location":"Python/matplotlib/02%20-%20seaborn/#diagramas-de-pares","title":"Diagramas de pares","text":"<p>Diagramas de pares (Pairplots).</p> <pre><code>iris = pd.read_csv('../DATA/iris.csv')\niris.head()\n</code></pre> <p></p> <pre><code>sns.pairplot(iris)\n</code></pre> <p></p> <p>Nota: Hay que destacar que las gr\u00e1ficas est\u00e1n diplicados en modo espejo con la diagonal.</p> <pre><code>sns.pairplot(iris, hue=\"species\")\n</code></pre> <p></p>"},{"location":"Python/pydantic/01%20-%20modelos/","title":"Modelos","text":"<p>modelos de pydantic</p>"},{"location":"Terraform/basic/01%20-%20Introduction/","title":"Terraform","text":"<p>Terraform is an open-source infrastructure as code (IaC) tool developed by HashiCorp. It enables users to define and provision infrastructure resources in a declarative configuration language. With Terraform, you can describe the desired state of your infrastructure, and the tool will automatically create and manage the necessary resources to achieve that state, whether they are in the cloud, on-premises, or in a hybrid environment. This helps automate the process of infrastructure deployment and management, making it more scalable, repeatable, and efficient.</p>"},{"location":"Terraform/basic/01%20-%20Introduction/#comments","title":"Comments","text":"<pre><code># this is a comment \n### and so is this\n\n/* this is a multi-line comment just like\n   in many common programming languages */\n</code></pre>"},{"location":"Terraform/basic/01%20-%20Introduction/#variables","title":"Variables","text":"<pre><code># variables definition\nvariable \"aws_access_key\" {}\nvariable \"aws_secret_key\" {}\nvariable \"private_key_path\" {}\nvariable \"key_name\" {default = \"ubuntu1\"}\n\n# values are assigned using key = value\n# strings are in double quotes \" \"\n# strings can interpolate using syntax wrapped in ${ }\n\n# variable types\nvariable \"&lt;var_name&gt;\" {\n type = \"&lt;var_type&gt;\" //it can be: string, list, map\n default = \"...\" \n /*\n -&gt; example list\n default = [\"val1\", \"val2\"]\n\n -&gt; example map\n default = {\n  key1 = \"val1\"\n  key2 = \"val2\"\n }\n /*\n}\n</code></pre>"},{"location":"Terraform/basic/01%20-%20Introduction/#providers","title":"Providers","text":"<pre><code># providers definition\nprovider \"aws\" {\n  access_key = \"${var.aws_access_key}\"\n  secret_key = \"${var.aws_secret_key}\"\n  region     = \"us-west-1\"\n}\n</code></pre>"},{"location":"Terraform/basic/01%20-%20Introduction/#resource","title":"Resource","text":"<pre><code># resources definition\nresource \"aws_instance\" \"ubuntu\" {\n  ami           = \"ami-b2527ad2\"\n  instance_type = \"t2.micro\"\n  key_name        = \"${var.key_name}\"\n\n  # shell-stype 'here doc' syntax for multiline strings\n  user_data = &lt;&lt;-EOF\n              #!/bin/bash\n              echo \"Hello, World!\" &gt; index.html\n              nohup busybox httpd -f -p 8800 &amp;\n              EOF\n}\n</code></pre>"},{"location":"Terraform/basic/01%20-%20Introduction/#values-types","title":"Values types","text":"<pre><code>/* numbers are assumed to be base 10 but if you prefix a number\n   with 0x that number is then treated as a hexadecimal value */\n\n# boolean values are either true or false\n\n/* lists of primitive types are possible with square brackets ([])\n   for example [false, true, true] */\n\n/* maps can be made with curly braces { } and colons :\n   for example {\"label1\":true, \"label2\":false} */\n</code></pre>"},{"location":"Terraform/basic/01%20-%20Introduction/#conditionals","title":"Conditionals","text":"<pre><code># you can also use conditionals to determine a value based on logic\n# the syntax uses the ternary operator '?'\n# (some condition) ? (true value) : (false value)\nresource \"aws_instance\" \"webserver\" {\n  subnet = \"${var.env == \"production\" ? var.prod_subnet : var.dev_subnet}\"\n}\n\n# support operators\n# for equality you can use == and !=\n# numerical comparators include &gt;,  &lt;,  &gt;=,  &lt;=\n# booleans &amp;&amp;, ||, unary !\n\n# typical use case\nresource \"aws_instance\" \"webserver\" {\n  count = \"${var.evaluation ? 1 : 0}\"\n}\n</code></pre>"},{"location":"Terraform/basic/02%20-%20Configurations/","title":"Configurations","text":""},{"location":"Terraform/basic/02%20-%20Configurations/#load-order","title":"Load Order","text":"<ul> <li>Terraform loads all configs (<code>.tf</code> or <code>.tf.json</code> files) in the directory, using alphabetical order.</li> <li>Override files are loaded after non-override files, using alpabetical order.</li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#overrides","title":"Overrides","text":"<ul> <li>Need to have the key work <code>override</code> in the name of the <code>.tf</code> file.</li> <li>Example below.</li> </ul> <p>Having a <code>config.tf</code> file like:</p> <pre><code># ...\nresource \"aws_instance\" \"web_server\" {\n  ami           = \"ami-aaa\"\n  instance_type = \"t2.medium\"\n# ...\n</code></pre> <p>And an <code>override.tf</code> file like:</p> <pre><code>resource \"aws_instance\" \"web_server\" {\n  ami           = \"ami-bbb\"\n  instance_type = \"t2.micro\"\n}\n</code></pre> <p>The output will be:</p> <p><code>c  ami           = \"ami-bbb\"  instance_type = \"t2.micro\"</code></p>"},{"location":"Terraform/basic/02%20-%20Configurations/#output","title":"Output","text":"<ul> <li>Help us to extract info.</li> </ul> <pre><code># output definitions\n/* syntax:\noutput NAME {\n  value = VALUE\n}\n*/\noutput \"aws_instance_public_dns\" {\n  value = \"${aws_instance.webserver.public_dns}\"\n}\n\n/*\nparameters that can be used:\no   value (required), the value of the output, could be a string, list, or map. \n    Typically includes an interpolation (static outputs generally aren't that helpful).\n\no   description (optional), a human-friendly description for the output. This is\n    primarily to pass on documentation for those using your Terraform configuration.\n\no   depends_on (list of strings), these are explicit dependencies that the output has, and these\n    dependencies are created before the output value is processed. Dependencies are expresed with \n    the format of TYPE.NAME, for example aws_instance.webserver\n\no   sensitive (optional), a boolean value indicating sensitive information. When displaying outputs\n    in terminal following a terraform apply or refresh operation, sensitive outputs are redacted,\n    with &lt;sensitive&gt; displayed instead of the output actual values\n*/\n\n### setting the sensitive attribute = true:\noutput \"sensitive_aws_instance_public_dns\" {\n  sensitive = true\n  value = \"${aws_instance.webserver.public_dns}\"\n}\n\n/*\nThis is going to show in the \"terraform apply\" command:\nsensitive_aws_instance_public_dns = &lt;sensitive&gt;\n\nBut if we execute \"terraform output\" command, we can see the sensitive value:\nsensitive_aws_instance_public_dns = aaaaa\n*/\n</code></pre>"},{"location":"Terraform/basic/02%20-%20Configurations/#providers","title":"Providers","text":"<ul> <li>Providers are executed in the init command, and it downloads the provider plugins.</li> <li>You ca have more than one provider from the same type using alias field.</li> <li>Plugins are stored in <code>terraform.d/plugins</code> , then inside each workspace the plugins are duplicated inside <code>.terraform/plugins</code>.</li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#modules","title":"Modules","text":"<ul> <li>Folder with terraform files with reusable components.  That folder should contain the following files:<ul> <li><code>main.tf</code> - Can be empty.</li> <li><code>variables.tf</code> - Defining the params of the module.</li> <li><code>outputs.tf</code> - Defining the output of the module.</li> <li><code>Readme.mf</code> - Optional</li> <li><code>LICENSE</code> - Optional</li> </ul> </li> <li>Then you can use the module in your main terraform file.</li> </ul> <pre><code># Define a custom module\nmodule &lt;custom_module_name&gt; {\n source = &lt;folder_path_to_module&gt;\n\n # Define module variables\n &lt;module_variable_name&gt; = value1\n}\n\n# You can see outputs from the module\noutput &lt;custom_output&gt; {\n value = \"${module.&lt;custom_module_name&gt;.&lt;module_output_name&gt;}\"\n}\n</code></pre> <ul> <li>Need to use <code>terraform get</code> in order to look for modules.</li> <li>If you modify any module after the first \"get\" command, you need to specify to terraform to update the module with <code>terraform get -update=true</code>.</li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#local-values","title":"Local values","text":"<ul> <li>Give a name to an expression. Only works inside a module. Define a local:</li> </ul> <pre><code>locals {\n default_prefix = ${&lt;expression&gt;}\n}\n</code></pre> <p>Use local:</p> <pre><code>output &lt;what_ever&gt; {\n value = ${\"local.default_prefix\"}\n}\n</code></pre>"},{"location":"Terraform/basic/02%20-%20Configurations/#resource-configuration","title":"Resource configuration","text":"<ul> <li>Resources are part of the infrastructure.</li> </ul> <pre><code>resource &lt;resource_type&gt; &lt;custom_name&gt; {\n\n}\n</code></pre> <ul> <li>Combination of <code>&lt;resource_type&gt;</code> and <code>&lt;custom_name&gt;</code> must be unique.</li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#meta-parameters","title":"Meta-parameters","text":"<ul> <li> <p>Meta-parameters available to all resources:</p> <ul> <li>count (int)    The number of identical resources to create. This doesn't apply to all resources.</li> <li>Note: modules does not currently support count meta-parameter.</li> <li> <p>Example:  <pre><code>variable \"instance_ips\" {\n default = {\n  \"0\" = \"10.1.1.10\"\n  \"1\" = \"10.1.1.11\"\n  \"2\" = \"10.1.1.12\"\n }\n}\n\n# ...\n\nresource \"aws_instance\" \"webserver\" {\n # ...\n count         = \"3\"\n private_ip    = \"${lookup(var.instance_ips, count.index)}\"\n # ...\n}\n</code></pre></p> </li> <li> <p>depends_on (list of strings)    Explicit dependencies that the current resource has. These dependencies will be created before    this resource.</p> </li> <li>provider (string)    The name of a specific provider to use for the current resource.</li> <li>lifecycle (configuration block)    Customizes the lifecycle behavior of the current resource.</li> </ul> </li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#lifecycle-block","title":"Lifecycle block","text":"<p>Using the lifecycle configuration block, you can customize the lifecycle behavior of a resource. There are specific keys that the lifecycle block exposes for our use:</p> <ul> <li>create_before_destroy (bool)   When this key is set, it ensures that the replacement of a resource is created before the original   instance is destroyed.</li> <li>Note: resources that use this create_before_destroy key can only depend on other resources     that also use the create_before_destroy key.</li> <li>prevent_destroy (bool)   Using this flag provides some additional protection against the accidental destruction of a resource.   When this is set, any plan including a destroy of this resource will return an error.</li> <li>ignore_changes (list of strings)   This key allows us to customize how 'diffs' are evaluated for resources. It allows individual   attributes to be ignored through changes.</li> <li>Note: ignored attribute names can be matched by their name but not by state ID.     eg: if an aws_route_table has two routes defined and the ignore_changes list contains \"route\",     both routes will be ignored. You can also use a single entry with a wildcard (eg: \"*\") which     matches all attribute names, however you cannot use a partial string together with a wildcard     (eg: \"rout*\").</li> </ul>"},{"location":"Terraform/basic/02%20-%20Configurations/#timeouts","title":"Timeouts","text":"<ul> <li>By default, each resource has his own timeouts, but we can modify them.</li> </ul> <pre><code>/*\nThe aws_instance provides these timeouts by default:\n - create (default 10m) for creating instances\n - update (default 10m) for updating instances\n - delete (default 10m) for destroying instances\n*/\nresource \"aws_instance\" \"webserver\" {\n # ...\n timeouts {\n  create = \"2s\"\n  update = \"20m\"\n  delete = \"1h\"\n }\n # ...\n}\n</code></pre>"},{"location":"Terraform/basic/02%20-%20Configurations/#data-sources","title":"Data Sources","text":"<ul> <li>Data that needs to be <code>Fetched</code> or <code>Computed</code> for use in terraform configuration.</li> <li>Example</li> </ul> <pre><code>/*\nwe'll fetch the availability zones mapped to the aws provider.\n  - this is a list of zones from aws which we'll use later\n  - this data source is of the form: data TYPE NAME where:\n    TYPE = \"aws_availability_zones\"\n    NAME = \"available\"\n  - TYPE + NAME combination must be unique\n*/\ndata \"aws_availability_zones\" \"available\" {}\n</code></pre>"},{"location":"Terraform/basic/02%20-%20Configurations/#variables","title":"Variables","text":"<ul> <li>Few variables that can be defined after apply command.</li> <li>Example</li> </ul> <pre><code>variable \"aws_access_key\" {}\n</code></pre> <p>After a <code>terraform apply</code> command we need to set those variables manually.</p> <pre><code>var.aws_access_key\n Enter a value:_\n</code></pre> <ul> <li> <p>We can offer a file with variables values:</p> <ul> <li> <p><code>terraform.tfvars</code> <pre><code>aws_access_key = \"aaa\"\n</code></pre></p> </li> <li> <p>Execute apply command with var file:  <pre><code>terraform apply -var-file='../terraform.tfvars'\n</code></pre></p> </li> </ul> </li> </ul>"},{"location":"Terraform/basic/03%20-%20Infrastructure/","title":"Infrastructure","text":""},{"location":"Terraform/basic/03%20-%20Infrastructure/#implicit-dependencies","title":"Implicit dependencies","text":"<ul> <li>Terraform can detect automatically dependencies between resources.</li> <li>In the example below, terraform detects that <code>webserver</code> resource must be created before <code>ip</code> resource.</li> </ul> <pre><code># resources definition\n# instances\nresource \"aws_instance\" \"webserver\" {\n  ami           = \"ami-1c1d217c\"\n  instance_type = \"t2.micro\"\n  key_name      = \"${var.key_name}\"\n}\n\n# elastic IPs\nresource \"aws_eip\" \"ip\" {\n  instance = \"${aws_instance.webserver.id}\"\n}\n</code></pre>"},{"location":"Terraform/basic/03%20-%20Infrastructure/#explicit-dependencies","title":"Explicit dependencies","text":"<ul> <li>Terraform cannot detect internal dependencies between resources. In these cases we can use <code>depends_on</code> argument, to define the dependencies between resources.</li> <li>In the example below, <code>mys3bucket</code> resource will be generated before <code>webserver</code> resource.</li> </ul> <pre><code># resources definition\n# instances\nresource \"aws_instance\" \"webserver\" {\n  ami           = \"ami-1c1d217c\"\n  instance_type = \"t2.micro\"\n  key_name      = \"${var.key_name}\"\n  # we can use the depends_on argument to inform Terraform that this \n  # EC2 instance must only be created after the S3 bucket has been created\n  depends_on = [\"aws_s3_bucket.mys3bucket\"]\n}\n\n### elastic IPs\nresource \"aws_eip\" \"ip\" {\n  instance = \"${aws_instance.webserver.id}\"\n}\n\n# S3 storage\n# this represent the S3 bucket our application expects to use\nresource \"aws_s3_bucket\" \"mys3bucket\" {\n  # notice the seemingly long name for the bucket. This is because S3 bucket names have to\n  # be unique across ALL AWS accounts, so this name is used to hopefully avoid any conflicts\n  # keep this in mind when you are writing code to follow along with this demo\n  bucket = \"sd-terr-terraform101-bucket\"\n  acl    = \"private\"\n}\n\n# output definitions\noutput \"aws_instance_public_dns\" {\n  value = \"${aws_instance.webserver.public_dns}\"\n}\n</code></pre>"},{"location":"Terraform/basic/03%20-%20Infrastructure/#nondependent-resources","title":"Nondependent resources","text":"<ul> <li>If there's no dependencies between resources, terraform will create them in parallel.</li> </ul>"},{"location":"notes/beautiful_terminal/","title":"Mejorar la apariencia de la terminal","text":"<p>Enlace al video</p> <ol> <li> <p>Instala <code>iterm2</code> desde la p\u00e1gina web: enlace</p> </li> <li> <p>Configura zsh como la terminal predeterminada</p> </li> </ol> <pre><code># Verifica si zsh est\u00e1 instalado\nwhich zsh\n\n# Si no est\u00e1 instalado, inst\u00e1lalo  \n# ...\n\n# Asigna zsh como la terminal predeterminada\nchsh -s $(which zsh)\n\n# Despu\u00e9s de abrir una nueva terminal, la predeterminada deber\u00eda ser zsh\necho $0\n</code></pre> <ol> <li>Configura los colores para la terminal</li> </ol> <pre><code>nano ~/gruvbox.itermcolors\n</code></pre> <p>con el texto del enlace</p> <ol> <li>Instala oh my zsh</li> </ol> <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <ol> <li>Descarga la fuente que deseas desde enlace</li> </ol> <ul> <li>Hack Nerd Font</li> <li>Haz doble clic e instala una fuente</li> </ul> <ol> <li> <p>En la configuraci\u00f3n de la nueva terminal, ve a profiles &gt; text y selecciona la fuente.</p> </li> <li> <p>Instala Powerlevel 10K -&gt; enlace</p> </li> </ol> <pre><code>git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n</code></pre> <ol> <li> <p>Configura\u00a0ZSH_THEME=\"powerlevel10k/powerlevel10k\"\u00a0en\u00a0~/.zshrc.</p> </li> <li> <p>Recarga la terminal</p> </li> </ol> <pre><code>source `~/.zshrc`\n</code></pre> <ol> <li>Configura la terminal a tu gusto.</li> <li>Instala algunos plugins extras</li> <li><code>zsh-syntax-highlighting</code>  -&gt; link</li> </ol> <pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n</code></pre> <ol> <li><code>zsh-autosuggestions</code> -&gt; link</li> </ol> <pre><code>git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n</code></pre> <ol> <li>Agrega los nuevos plugins dentro de zsh</li> </ol> <pre><code>nano ~/.zshrc\n</code></pre> <p>y modifica la l\u00ednea de plugins:</p> <pre><code>plugins=(git zsh-syntax-highlighting zsh-autosuggestions)\n</code></pre> <ol> <li>Recarga la terminal</li> </ol> <pre><code>source `~/.zshrc`\n</code></pre>"},{"location":"notes/powershell_custom_shortcuts/","title":"Powershell Alias y funciones","text":"<p>Es posible modificar el perfil de powershell para agregar alias y funciones personalizadas.</p> <pre><code>notepad $PROFILE\n</code></pre> <p>Aqui podemos a\u00f1adir alias y funciones personalizadas que queremos cargar cada vez que abrimos powershell.</p> <pre><code>Set-Alias python G:\\Programs\\Python3_13\\python.exe\n\nfunction pip {\n    &amp; \"G:\\Programs\\Python3_13\\python.exe\" -m pip @args\n}\n\nSet-Alias uv G:\\Programs\\python_tools\\uv\\bin\\uv.exe\n\nSet-Alias ruff G:\\Programs\\python_tools\\ruff\\ruff.exe\n\nSet-Alias oh-my-posh C:\\Users\\&lt;username&gt;\\AppData\\Local\\Programs\\oh-my-posh\\bin\\oh-my-posh.exe\noh-my-posh init pwsh --config \"$env:POSH_THEMES_PATH/cloud-native-azure.omp.json\" | Invoke-Expression\n\nImport-Module -Name Terminal-Icons\n</code></pre>"},{"location":"notes/VSCode/devcontainer/","title":"DevContainer","text":"<p>DevContainer es una herramienta que nos permite crear un entorno virtual de trabajo dentro de docker.</p> <p>S\u00f3lo hace falta tener instalado docker engine.</p>"},{"location":"notes/VSCode/devcontainer/#pre-requisitos","title":"Pre-requisitos","text":"<p>Si estamos usando VSCode hay que instalar la extension <code>Dev Containers</code>.</p>"},{"location":"notes/VSCode/devcontainer/#crear-configuracion-para-devcontainer","title":"Crear configuraci\u00f3n para devcontainer","text":"<ol> <li>Abrir buscador de VSCode y buscar <code>Add Dev Container Configuration Files</code>.</li> <li>Lo normal es selecionar <code>Add configuration to workspace</code>.</li> <li>Seleccionamos la plantilla que queramos utilizar.</li> </ol> <p>Tras este punto, al esperar unos segundos, deber\u00eda aparecer un nuevo archivo de configuraci\u00f3n con el nombre <code>.devcontainer/devcontainer.json</code>.</p>"},{"location":"notes/VSCode/devcontainer/#iniciar-contenedor","title":"Iniciar contenedor","text":"<ol> <li>Abajo a la izquierda (bot\u00f3n con s\u00edmbolo <code>&gt;&lt;</code>), o desde el buscador de VSCode, ejecutar <code>Reopen in container</code>.</li> <li>Tras unos segundos se abrir\u00e1 una nueva ventana donde estar\u00e1s ya dentro del contenedor, dentro de tu entorno virtual.</li> </ol>"},{"location":"notes/VSCode/devcontainer/#otras-curiosidades-de-devcontainer","title":"Otras curiosidades de devcontainer","text":"<ul> <li>Cada cambio que se haga dentro del archivo de configuraci\u00f3n de devcontainer necesitar\u00e1 que se reinicie el contenedor para aplicar los cambios.</li> <li>Puedes instalar extensiones VSCode dentro del contenedor de devcontainer. Esto a\u00f1adir\u00e1 dicha extensi\u00f3n al archivo de configuraci\u00f3n.</li> <li> <p>Cada vez que se quiera habilitar un puerto del contenedor aparecer\u00e1 una ventana para dar el permiso, pero tambi\u00e9n se puede hacer directamente desde el archivo de configuraci\u00f3n.</p> <pre><code>{\n    \"name\": \"Python 3 - Test devcontainer\",\n    //(...)\n    // Use 'forwardPorts' to make a list of ports inside the container available locally.\n    \"forwardPorts\": [8000, 5001],\n    \"portsAttributes\": {\n        \"8000\": {\n            \"label\": \"API Port\",\n            \"protocol\": \"https\"\n        }\n    }\n}\n</code></pre> </li> <li> <p>Ejecutar comando justo al lanzar el contenedor.</p> <pre><code>{\n    \"name\": \"Python 3 - Test devcontainer\",\n    //(...)\n    \"postStartCommand\": \"python app/main.py\"\n}\n</code></pre> </li> <li> <p>Es posible usar otros archivos DockerFile o docker-compose propios para crear el contenedor.</p> <pre><code>{\n    \"name\": \"Python 3 - Test devcontainer\",\n    //\"image\": \"mcr.microsoft.com/devcontainers/python:1-3.12-bullseye\",\n    \"build\":{\n        \"dockerfile\": \"Dockerfile\"\n    }\n    //(...)\n}\n</code></pre> <pre><code>{\n    \"name\": \"Python 3 - Test devcontainer\",\n    //\"image\": \"mcr.microsoft.com/devcontainers/python:1-3.12-bullseye\",\n    \"dockerComposeFile\": \"docker-compose.yml\"\n    //(...)\n}\n</code></pre> </li> <li> <p>Se pueden tener m\u00faltiples configuraciones para un mismo repo, por ejemplo una configuraci\u00f3n para dev y otra para debug. Por lo que al tratar de iniciar el contenedor nos preguntar\u00e1 cu\u00e1l queremos iniciar.</p> <pre><code>.\n\u2514\u2500\u2500 .devcontainer\n    \u251c\u2500\u2500 debug\n    \u2502   \u2514\u2500\u2500 devcontainer.json\n    \u2514\u2500\u2500 dev\n        \u2514\u2500\u2500 devcontainer.json\n</code></pre> </li> </ul>"},{"location":"notes/VSCode/ruff/","title":"Ruff","text":"<p>Ruff es una herramienta de linting y formateo para Python, escrita en Rust, que destaca por su velocidad y eficiencia. Unifica m\u00faltiples funcionalidades (como Flake8, isort, pyupgrade, entre otras) en una sola CLI, permitiendo escribir c\u00f3digo m\u00e1s limpio, consistente y libre de errores, y es hasta 100 veces m\u00e1s r\u00e1pida que alternativas tradicionales.</p> <p>Caracter\u00edsticas principales:</p> <ul> <li>Velocidad: Su mayor ventaja. Realiza el linting y formateo en segundos, incluso en grandes bases de c\u00f3digo.</li> <li>Todo en uno: Reemplaza a un gran conjunto de linters y formateadores (Flake8, isort, pydocstyle, pyupgrade, autoflake, etc.).</li> <li>Compatible con Flake8: Implementa la mayor\u00eda de las reglas de Flake8 y sus plugins m\u00e1s populares.</li> <li>Autocorrecci\u00f3n (Autofix): Puede corregir autom\u00e1ticamente muchos de los errores que detecta.</li> <li>Configuraci\u00f3n sencilla: Utiliza <code>pyproject.toml</code> para la configuraci\u00f3n, aline\u00e1ndose con los est\u00e1ndares modernos de Python.</li> <li>Integraci\u00f3n con editores: Se integra f\u00e1cilmente con editores de c\u00f3digo populares como VS Code, PyCharm, etc.</li> <li>Cach\u00e9 Inteligente: Guarda los resultados del linting para evitar re-analizar archivos no modificados, acelerando a\u00fan m\u00e1s las ejecuciones subsecuentes.</li> </ul>"},{"location":"notes/VSCode/ruff/#por-que-es-beneficioso-usar-ruff","title":"\u00bfPor qu\u00e9 es beneficioso usar Ruff?","text":"<p>Integrar Ruff en tu flujo de trabajo de Python aporta numerosas ventajas:</p> <ol> <li> <p>Rendimiento Excepcional:</p> <ul> <li>Reduce dr\u00e1sticamente el tiempo de espera en los procesos de Integraci\u00f3n Continua/Despliegue Continuo (CI/CD) y en el desarrollo local.</li> <li>Permite ejecutar el linter con m\u00e1s frecuencia sin interrumpir el flujo de trabajo.</li> </ul> </li> <li> <p>Simplificaci\u00f3n del Herramental (Tooling):</p> <ul> <li>En lugar de gestionar m\u00faltiples dependencias y configuraciones para diferentes linters y formateadores, solo necesitas Ruff.</li> <li>Esto simplifica el archivo <code>pyproject.toml</code> o <code>requirements.txt</code> y reduce la complejidad del entorno de desarrollo.</li> </ul> </li> <li> <p>Consistencia del C\u00f3digo Mejorada:</p> <ul> <li>Al aplicar un conjunto unificado de reglas de linting y formateo, Ruff asegura que el c\u00f3digo sea m\u00e1s homog\u00e9neo en todo el proyecto, facilitando la lectura y el mantenimiento.</li> </ul> </li> <li> <p>Detecci\u00f3n Temprana de Errores y \"Code Smells\":</p> <ul> <li>Ayuda a identificar errores comunes, posibles bugs y malas pr\u00e1cticas de programaci\u00f3n antes de que lleguen a producci\u00f3n.</li> </ul> </li> <li> <p>Modernizaci\u00f3n del C\u00f3digo:</p> <ul> <li>Incluye reglas y autocorrecciones para actualizar la sintaxis de Python a versiones m\u00e1s modernas (similar a <code>pyupgrade</code>).</li> </ul> </li> <li> <p>Mejora de la Productividad del Desarrollador:</p> <ul> <li>La velocidad y la capacidad de autocorrecci\u00f3n permiten a los desarrolladores centrarse m\u00e1s en la l\u00f3gica de negocio y menos en el formato y los errores triviales.</li> <li>Reduce la fricci\u00f3n durante las revisiones de c\u00f3digo, ya que muchos problemas de estilo se resuelven autom\u00e1ticamente.</li> </ul> </li> <li> <p>F\u00e1cil Adopci\u00f3n:</p> <ul> <li>Su compatibilidad con Flake8 facilita la migraci\u00f3n desde configuraciones existentes.</li> <li>La configuraci\u00f3n es intuitiva y bien documentada.</li> </ul> </li> <li> <p>Comunidad Activa y Desarrollo Continuo:</p> <ul> <li>Ruff es un proyecto de c\u00f3digo abierto con una comunidad creciente y un desarrollo muy activo, lo que asegura la incorporaci\u00f3n de nuevas funcionalidades y la correcci\u00f3n de errores de forma r\u00e1pida.</li> </ul> </li> </ol>"},{"location":"notes/VSCode/ruff/#instalacion","title":"Instalaci\u00f3n","text":"<pre><code>pip install ruff\n</code></pre>"},{"location":"notes/VSCode/ruff/#instalacion-desde-uv","title":"Instalaci\u00f3n desde uv","text":"<p><code>uv</code> es un gestor de herramientas, similar a <code>pip</code>, pero para r\u00e1pido y que ayuda a manejar m\u00f3dulos de python de una manera m\u00e1s sencilla.</p> <pre><code>uv tool install ruff\n</code></pre>"},{"location":"notes/VSCode/ruff/#usos","title":"Usos","text":""},{"location":"notes/VSCode/ruff/#check","title":"check","text":"<p>Comprueba el c\u00f3digo y devuelve por consola los errores.</p> <pre><code>ruff check &lt;file or path&gt;\n</code></pre> <p>Algunos argumentos \u00fatiles:</p> <ul> <li><code>--fix</code> para corregir los errores.</li> <li><code>--diff</code> para mostrar los cambios que se van a hacer.</li> <li><code>--show-source</code> para mostrar el c\u00f3digo fuente.</li> <li><code>--show-position</code> para mostrar la posici\u00f3n del error.</li> </ul>"},{"location":"notes/VSCode/ruff/#format","title":"format","text":"<pre><code>ruff format &lt;file or path&gt;\n</code></pre> <p>Algunos argumentos \u00fatiles:</p> <ul> <li><code>--check</code> para comprobar si el c\u00f3digo est\u00e1 formateado.</li> <li><code>--diff</code> para mostrar los cambios que se van a hacer.</li> <li><code>--watch</code> para vigilar los cambios en el archivo y formatearlos autom\u00e1ticamente.</li> </ul>"},{"location":"notes/VSCode/ruff/#configuracion","title":"Configuraci\u00f3n","text":"<p>Se puede configurar Ruff para cada proyecto a trav\u00e9s de un archivo <code>pyproject.toml</code> en el directorio ra\u00edz del proyecto.</p> <pre><code>(...)\n\n[tool.ruff]\nline-length = 120\nlint.extend-ignore = [\"E501\"]\nlint.extend-select = [\"PTH\"]\n</code></pre> <p>Por defecto ruff utilizar\u00e1 la configuraci\u00f3n que se encuentra en el archivo <code>ruff.toml</code>. Que se puede encontrar por defecto en:</p> <p>Linux: <pre><code>~/.config/ruff/ruff.toml\n</code></pre></p> <p>Windows: <pre><code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\ruff\\ruff.toml\n</code></pre></p>"},{"location":"notes/VSCode/ruff/#integracion-con-vscode","title":"Integraci\u00f3n con VSCode","text":"<p>Se puede integrar Ruff con VSCode para que se ejecute autom\u00e1ticamente al guardar el archivo.</p> <ol> <li>Instalar ruff extension en VSCode.</li> <li>A\u00f1adir la siguiente configuraci\u00f3n en el archivo <code>settings.json</code> de VSCode.</li> </ol> <pre><code>{\n    \"[python]\": {\n        \"editor.formatOnSave\": true,\n        \"editor.defaultFormatter\": \"charliermarsh.ruff\",\n        \"editor.formatOnSave\": true,\n        \"editor.codeActionsOnSave\": {\n            \"source.organizeImports\": \"explicit\"\n            //\"source.fixAll\": \"explicit\" // better to see errores\n        }\n    },\n    \"python.linting.enabled\": true, // not tested\n    \"python.linting.provider\": \"ruff\", // not tested\n    \"python.analysis.inlayHints\": {\n        \"variableTypes\": true,\n        \"parameterTypes\": true, // not tested\n        \"parameterName\": true, // not tested\n        \"functionReturnType\": true\n    }\n}\n</code></pre>"},{"location":"notes/VSCode/ruff/#referencias","title":"Referencias","text":"<ul> <li>Ruff Documentation</li> <li>Ruff Rules</li> <li>Ruff GitHub</li> <li>Ruff Video Tutorial </li> </ul>"}]}